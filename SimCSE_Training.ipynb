{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copy of SimCSEVenki.ipynb","provenance":[],"collapsed_sections":["waixVZkkg0Dq","Ju1hyZWHdDZs","Eb0FTjwYdXxj","P9aAY_MJNzsM","EQgF5Xc1hC6G","beJqkyTVvofo","XotekNFD1D2k","cvC2S6Whyvb8","lTlcqmg_TJ8V","alqwVnA_gm1-","ENpMrKTNxSaQ","vSLsgReEHZ1h","LjTBXkJN7Kxj"],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"75654a58e9004b90a9e60f18498ee66c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d76954a5bfc24824a3e16af8de8f9598","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0de2125378754f0981d6fe1fded42692","IPY_MODEL_a0fe4f6c87dd42f5a1114e3db1163c24"]}},"d76954a5bfc24824a3e16af8de8f9598":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0de2125378754f0981d6fe1fded42692":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_06c22d0a59fe4f5cb288fde85e59796b","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":689,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":689,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7aa6498cf3094b34ab4a53e6300d84c8"}},"a0fe4f6c87dd42f5a1114e3db1163c24":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_53418231bd344aadb0a7b0cc81841ca9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 689/689 [00:06&lt;00:00, 101B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dc11dc86f44247368761cca553904069"}},"06c22d0a59fe4f5cb288fde85e59796b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7aa6498cf3094b34ab4a53e6300d84c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"53418231bd344aadb0a7b0cc81841ca9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dc11dc86f44247368761cca553904069":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f19594687712477985c327deafc8cd2d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e10a21222898407d957c461f81e12872","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3dcba4b2dd69430691a71c6584cba1fb","IPY_MODEL_26e3d6293fe148699bc15129a517e280"]}},"e10a21222898407d957c461f81e12872":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3dcba4b2dd69430691a71c6584cba1fb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_861a2258a60641f0af32415c909fab1e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7034af5885f3489090adf56f0df982b0"}},"26e3d6293fe148699bc15129a517e280":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d4897dd0cc424e86bd42a159ebc0e605","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:04&lt;00:00, 50.4kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f2538541b45841d892911d920ae149e9"}},"861a2258a60641f0af32415c909fab1e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7034af5885f3489090adf56f0df982b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d4897dd0cc424e86bd42a159ebc0e605":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f2538541b45841d892911d920ae149e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ebf1d8f63f454e75a6a28e8c66627934":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7120b4f7358f4f4eb3a82a7da4b502ec","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f25fa7cee4a74484a380f1b289208dc6","IPY_MODEL_3e3560b4261f4b84a4cd8ac341e51124"]}},"7120b4f7358f4f4eb3a82a7da4b502ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f25fa7cee4a74484a380f1b289208dc6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4b627df38e1f4cfc8dcd952f09c2b6ff","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":112,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":112,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b78bda9bc1764b89a9496860e401ba6c"}},"3e3560b4261f4b84a4cd8ac341e51124":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_21e7078695004472882fedef353d7791","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 112/112 [00:00&lt;00:00, 131B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f1c7a3e65fa04960b508e309adf3fe90"}},"4b627df38e1f4cfc8dcd952f09c2b6ff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b78bda9bc1764b89a9496860e401ba6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"21e7078695004472882fedef353d7791":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f1c7a3e65fa04960b508e309adf3fe90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"83737fc064bd461e98116d4b51c33298":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c861321bfda242e093db05917029a6fe","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b9cdf704f6d044008d321288d0b55dc9","IPY_MODEL_db9de24454a442f5a36b2eae05116a89"]}},"c861321bfda242e093db05917029a6fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b9cdf704f6d044008d321288d0b55dc9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_262745fcbd814d4bbf6ce8123af4cf66","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":252,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":252,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_717531ee1c80469b8501a6d936939d4f"}},"db9de24454a442f5a36b2eae05116a89":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c386c0e2708d41ba84bd2fc4fbcc6093","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 252/252 [00:00&lt;00:00, 4.75kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4ef6d7d419b946a9959e65c255f0483c"}},"262745fcbd814d4bbf6ce8123af4cf66":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"717531ee1c80469b8501a6d936939d4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c386c0e2708d41ba84bd2fc4fbcc6093":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4ef6d7d419b946a9959e65c255f0483c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2c95b7e23e834864979be99f201a46a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1854a68fa2934d97bb8f2849fa811c81","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_aeaff771cba94151ac61e95e6f76ba97","IPY_MODEL_e409c0571a5f4cfe8547ca3775e748ed"]}},"1854a68fa2934d97bb8f2849fa811c81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aeaff771cba94151ac61e95e6f76ba97":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_90d1ee759fe34ad487807c6fdbf115b3","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":437998343,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":437998343,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_018e8f6dc2184b84b0fe74754876632e"}},"e409c0571a5f4cfe8547ca3775e748ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bc4fba7f868740b69d42a0caa7469dbe","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 438M/438M [00:08&lt;00:00, 54.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_592648634c69461586675a8101004a65"}},"90d1ee759fe34ad487807c6fdbf115b3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"018e8f6dc2184b84b0fe74754876632e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bc4fba7f868740b69d42a0caa7469dbe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"592648634c69461586675a8101004a65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"88ff17c99dcf4143bad2bb49cb817d27":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_972618cbe1d24dfd9af1f7f4029b9e97","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_39e1661e8cd84f429d08a937cce4a927","IPY_MODEL_225162709373480795a83430a27e8c22"]}},"972618cbe1d24dfd9af1f7f4029b9e97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"39e1661e8cd84f429d08a937cce4a927":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4f61a1c8471b4c87b26fc3414ef65635","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":664,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":664,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_01dcefc9d2394526b1f6ef567240c1cf"}},"225162709373480795a83430a27e8c22":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_58fb109b208f4420943869b8b56d7b9e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 664/664 [00:09&lt;00:00, 70.3B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4fd4d5d3729846f3b6fafb9d7944a7bc"}},"4f61a1c8471b4c87b26fc3414ef65635":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"01dcefc9d2394526b1f6ef567240c1cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"58fb109b208f4420943869b8b56d7b9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4fd4d5d3729846f3b6fafb9d7944a7bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c40e91da11f746a6bcd6feff48e75c1f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4dffacafdba84a1eb3475cd343b7af0d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3a8392ff7b2048f3b513d5fce5168a13","IPY_MODEL_8a2996c820d047ea994a32c56621df56"]}},"4dffacafdba84a1eb3475cd343b7af0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3a8392ff7b2048f3b513d5fce5168a13":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_978dcdf1c3544472a46a1d9a041993b8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":798293,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":798293,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_68d35d789d8c4652bb157967ea6844ec"}},"8a2996c820d047ea994a32c56621df56":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_67a6d908ebdb48b2b8320078d35fe29c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 798k/798k [00:06&lt;00:00, 126kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4ab53a6963804f1e8d91ba4f971d700d"}},"978dcdf1c3544472a46a1d9a041993b8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"68d35d789d8c4652bb157967ea6844ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"67a6d908ebdb48b2b8320078d35fe29c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4ab53a6963804f1e8d91ba4f971d700d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"08bb817c04074f79baea77e6f93c5086":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_67b64987f4f049fc8d2576d3e7780495","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2df7bc2468cc425d8871bfe366ce49b9","IPY_MODEL_5ddcdb813feb49728058351ce80d4be1"]}},"67b64987f4f049fc8d2576d3e7780495":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2df7bc2468cc425d8871bfe366ce49b9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0cb9773f6a944ceaac3e27933e4a6fe2","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456356,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456356,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1db141382f5646889e2842c985f93441"}},"5ddcdb813feb49728058351ce80d4be1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8675f48bde694cd6bc0583a2ddb7ceff","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:03&lt;00:00, 117kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_157ccb556bd04bebb72ceb9925e68326"}},"0cb9773f6a944ceaac3e27933e4a6fe2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1db141382f5646889e2842c985f93441":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8675f48bde694cd6bc0583a2ddb7ceff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"157ccb556bd04bebb72ceb9925e68326":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9666f9574f244cffab8aa2b4aae63091":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7ab9cb808aed49449850cf09f2fe0fa9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_452f8d7bfb7f448187fdab6b5d7ed811","IPY_MODEL_680d11d24053496a87c42b295ff1b378"]}},"7ab9cb808aed49449850cf09f2fe0fa9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"452f8d7bfb7f448187fdab6b5d7ed811":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_829682c03cec41e4b939bf8b452bba4c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":239,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":239,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_25e60ce148874cee837a738cb4d2c4f6"}},"680d11d24053496a87c42b295ff1b378":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_729c0a88ef3449f7b19aa5dd363c0e30","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 239/239 [00:01&lt;00:00, 151B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dca1bfcec7a6429595c39e0c7b91f077"}},"829682c03cec41e4b939bf8b452bba4c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"25e60ce148874cee837a738cb4d2c4f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"729c0a88ef3449f7b19aa5dd363c0e30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dca1bfcec7a6429595c39e0c7b91f077":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a5b0b2ffc7974a76a91ecc0dccab7221":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d0cc54ebaef64dd88d6c8743ad90226c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d3cbc93da116424bb66fa89e25ea0863","IPY_MODEL_e54530c4e7c940c3933a4bea72d41e67"]}},"d0cc54ebaef64dd88d6c8743ad90226c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d3cbc93da116424bb66fa89e25ea0863":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_81b0d91a30ff4cb2b6882281136ea771","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":256,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":256,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6a2cce141b4f414d8f78cd8cff40e7f9"}},"e54530c4e7c940c3933a4bea72d41e67":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_57d6b2cbb53f4183b47682af44017f53","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 256/256 [00:00&lt;00:00, 3.65kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8f79677445a8411cac5cceecae76722f"}},"81b0d91a30ff4cb2b6882281136ea771":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6a2cce141b4f414d8f78cd8cff40e7f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"57d6b2cbb53f4183b47682af44017f53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8f79677445a8411cac5cceecae76722f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2edec5e2b30f478284c048ff18fa887d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ebb5fa7afc414c20bfca63d42477df31","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_35f7566d4b9040a381997ca1764627f4","IPY_MODEL_e86a373c54ec478b933aee1d4a3a84f9"]}},"ebb5fa7afc414c20bfca63d42477df31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"35f7566d4b9040a381997ca1764627f4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_56d982976c4345a49a97b73f8b41a807","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1421571527,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1421571527,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fbc598b75b5d4a3eb232215874cae820"}},"e86a373c54ec478b933aee1d4a3a84f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_510d7a85b38440a985e97c66ad12e447","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.42G/1.42G [00:25&lt;00:00, 55.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0611c62128a6410d9fad435166a769b8"}},"56d982976c4345a49a97b73f8b41a807":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fbc598b75b5d4a3eb232215874cae820":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"510d7a85b38440a985e97c66ad12e447":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0611c62128a6410d9fad435166a769b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"fQHQFs1ZFt1v","executionInfo":{"status":"ok","timestamp":1638236354858,"user_tz":480,"elapsed":27713,"user":{"displayName":"Venkatesh Madi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjEBVZrlTFNDzPSl7eB4CL2YPLP-bfPlNxWSqr0tEc=s64","userId":"10204830288063877139"}},"outputId":"f3950003-a4bb-4f9c-d2bb-2f4affd814f9"},"source":["pip install simcse transformers==4.2.1 scipy==1.5.4 datasets==1.2.1 pandas==1.1.5 scikit-learn==0.24.0 prettytable==2.1.0 gradio torch setuptools==49.3.0"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting simcse\n","  Downloading simcse-0.4.tar.gz (18 kB)\n","Collecting transformers==4.2.1\n","  Downloading transformers-4.2.1-py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 5.3 MB/s \n","\u001b[?25hCollecting scipy==1.5.4\n","  Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n","\u001b[K     |████████████████████████████████| 25.9 MB 1.2 MB/s \n","\u001b[?25hCollecting datasets==1.2.1\n","  Downloading datasets-1.2.1-py3-none-any.whl (159 kB)\n","\u001b[K     |████████████████████████████████| 159 kB 61.7 MB/s \n","\u001b[?25hRequirement already satisfied: pandas==1.1.5 in /usr/local/lib/python3.7/dist-packages (1.1.5)\n","Collecting scikit-learn==0.24.0\n","  Downloading scikit_learn-0.24.0-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n","\u001b[K     |████████████████████████████████| 22.3 MB 1.2 MB/s \n","\u001b[?25hCollecting prettytable==2.1.0\n","  Downloading prettytable-2.1.0-py3-none-any.whl (22 kB)\n","Collecting gradio\n","  Downloading gradio-2.4.6-py3-none-any.whl (979 kB)\n","\u001b[K     |████████████████████████████████| 979 kB 81.1 MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n","Collecting setuptools==49.3.0\n","  Downloading setuptools-49.3.0-py3-none-any.whl (790 kB)\n","\u001b[K     |████████████████████████████████| 790 kB 79.1 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 88.7 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (4.8.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (1.19.5)\n","Collecting tokenizers==0.9.4\n","  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 60.4 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (3.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (4.62.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (21.3)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (0.3.4)\n","Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (3.0.0)\n","Collecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 78.1 MB/s \n","\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1) (0.70.12.2)\n","Collecting tqdm>=4.27\n","  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n","\u001b[K     |████████████████████████████████| 69 kB 8.0 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5) (2018.9)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.0) (3.0.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.0) (1.1.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable==2.1.0) (0.2.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.1.5) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1) (2021.10.8)\n","Collecting analytics-python\n","  Downloading analytics_python-1.4.0-py2.py3-none-any.whl (15 kB)\n","Collecting paramiko\n","  Downloading paramiko-2.8.1-py2.py3-none-any.whl (206 kB)\n","\u001b[K     |████████████████████████████████| 206 kB 83.9 MB/s \n","\u001b[?25hCollecting ffmpy\n","  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n","Collecting markdown2\n","  Downloading markdown2-2.4.1-py2.py3-none-any.whl (34 kB)\n","Requirement already satisfied: Flask>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from gradio) (1.1.4)\n","Collecting Flask-Login\n","  Downloading Flask_Login-0.5.0-py2.py3-none-any.whl (16 kB)\n","Collecting flask-cachebuster\n","  Downloading Flask-CacheBuster-1.0.0.tar.gz (3.1 kB)\n","Collecting pycryptodome\n","  Downloading pycryptodome-3.11.0-cp35-abi3-manylinux2010_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 74.4 MB/s \n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from gradio) (7.1.2)\n","Collecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gradio) (3.2.2)\n","Collecting Flask-Cors>=3.0.8\n","  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (1.1.0)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (1.0.1)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (7.1.2)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (2.11.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=1.1.1->gradio) (2.0.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n","Collecting monotonic>=1.5\n","  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Collecting backoff==1.10.0\n","  Downloading backoff-1.10.0-py2.py3-none-any.whl (31 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.2.1) (3.6.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (3.0.6)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (0.11.0)\n","Collecting pynacl>=1.0.1\n","  Downloading PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961 kB)\n","\u001b[K     |████████████████████████████████| 961 kB 38.0 MB/s \n","\u001b[?25hCollecting bcrypt>=3.1.3\n","  Downloading bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.6 MB/s \n","\u001b[?25hCollecting cryptography>=2.5\n","  Downloading cryptography-36.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n","\u001b[K     |████████████████████████████████| 3.6 MB 74.2 MB/s \n","\u001b[?25hRequirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko->gradio) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko->gradio) (2.21)\n","Building wheels for collected packages: simcse, ffmpy, flask-cachebuster\n","  Building wheel for simcse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for simcse: filename=simcse-0.4-py3-none-any.whl size=15032 sha256=7c5592174912e07168b423d6f776d11ad88b01c2dc12f5cdd53109dc154efa62\n","  Stored in directory: /root/.cache/pip/wheels/29/b0/58/448de751ccbe2a0e75c054e34416e7a5a1aead371d5d163450\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4710 sha256=28455c86149f5566bdf5f1f20579412a4f56fd25e93b3d1315bedb03a92107cd\n","  Stored in directory: /root/.cache/pip/wheels/13/e4/6c/e8059816e86796a597c6e6b0d4c880630f51a1fcfa0befd5e6\n","  Building wheel for flask-cachebuster (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for flask-cachebuster: filename=Flask_CacheBuster-1.0.0-py3-none-any.whl size=3371 sha256=6168f16f013f3847e5baa04403bf6c682bfef04523314713f0a7e4d069ea871d\n","  Stored in directory: /root/.cache/pip/wheels/28/c0/c4/44687421dab41455be93112bd1b0dee1f3c5a9aa27bee63708\n","Successfully built simcse ffmpy flask-cachebuster\n","Installing collected packages: tqdm, tokenizers, scipy, sacremoses, pynacl, monotonic, cryptography, bcrypt, backoff, xxhash, transformers, setuptools, scikit-learn, pydub, pycryptodome, paramiko, markdown2, Flask-Login, Flask-Cors, flask-cachebuster, ffmpy, analytics-python, simcse, prettytable, gradio, datasets\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.62.3\n","    Uninstalling tqdm-4.62.3:\n","      Successfully uninstalled tqdm-4.62.3\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.4.1\n","    Uninstalling scipy-1.4.1:\n","      Successfully uninstalled scipy-1.4.1\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 57.4.0\n","    Uninstalling setuptools-57.4.0:\n","      Successfully uninstalled setuptools-57.4.0\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.0.1\n","    Uninstalling scikit-learn-1.0.1:\n","      Successfully uninstalled scikit-learn-1.0.1\n","  Attempting uninstall: prettytable\n","    Found existing installation: prettytable 2.4.0\n","    Uninstalling prettytable-2.4.0:\n","      Successfully uninstalled prettytable-2.4.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed Flask-Cors-3.0.10 Flask-Login-0.5.0 analytics-python-1.4.0 backoff-1.10.0 bcrypt-3.2.0 cryptography-36.0.0 datasets-1.2.1 ffmpy-0.3.0 flask-cachebuster-1.0.0 gradio-2.4.6 markdown2-2.4.1 monotonic-1.6 paramiko-2.8.1 prettytable-2.1.0 pycryptodome-3.11.0 pydub-0.25.1 pynacl-1.4.0 sacremoses-0.0.46 scikit-learn-0.24.0 scipy-1.5.4 setuptools-49.3.0 simcse-0.4 tokenizers-0.9.4 tqdm-4.49.0 transformers-4.2.1 xxhash-2.0.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pkg_resources"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"_D36n4TMePzA"},"source":["import torch\n","import pandas as pd\n","from transformers import AutoModelForSequenceClassification, DistilBertForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer\n","import numpy as np\n","from datasets import load_metric\n","from simcse import SimCSE\n","import torch\n","\n","torch.cuda.is_available()\n","dtype = torch.cuda.FloatTensor"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-VE_kGEdVa04","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638236391366,"user_tz":480,"elapsed":15866,"user":{"displayName":"Venkatesh Madi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjEBVZrlTFNDzPSl7eB4CL2YPLP-bfPlNxWSqr0tEc=s64","userId":"10204830288063877139"}},"outputId":"fdce3a69-ff2d-4945-c23e-ec6efebe3c7b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"UOvIP1QwNxnw"},"source":["data_folder = 'drive/MyDrive/CSCI_544_NLP_Project/Twitter_Bot_Detection/Data/'\n","train_path = data_folder+\"train_triplets.csv\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4vLUYueamc_F"},"source":["# Exploring"]},{"cell_type":"code","metadata":{"id":"VegOl_OlF6uZ","colab":{"base_uri":"https://localhost:8080/","height":264,"referenced_widgets":["75654a58e9004b90a9e60f18498ee66c","d76954a5bfc24824a3e16af8de8f9598","0de2125378754f0981d6fe1fded42692","a0fe4f6c87dd42f5a1114e3db1163c24","06c22d0a59fe4f5cb288fde85e59796b","7aa6498cf3094b34ab4a53e6300d84c8","53418231bd344aadb0a7b0cc81841ca9","dc11dc86f44247368761cca553904069","f19594687712477985c327deafc8cd2d","e10a21222898407d957c461f81e12872","3dcba4b2dd69430691a71c6584cba1fb","26e3d6293fe148699bc15129a517e280","861a2258a60641f0af32415c909fab1e","7034af5885f3489090adf56f0df982b0","d4897dd0cc424e86bd42a159ebc0e605","f2538541b45841d892911d920ae149e9","ebf1d8f63f454e75a6a28e8c66627934","7120b4f7358f4f4eb3a82a7da4b502ec","f25fa7cee4a74484a380f1b289208dc6","3e3560b4261f4b84a4cd8ac341e51124","4b627df38e1f4cfc8dcd952f09c2b6ff","b78bda9bc1764b89a9496860e401ba6c","21e7078695004472882fedef353d7791","f1c7a3e65fa04960b508e309adf3fe90","83737fc064bd461e98116d4b51c33298","c861321bfda242e093db05917029a6fe","b9cdf704f6d044008d321288d0b55dc9","db9de24454a442f5a36b2eae05116a89","262745fcbd814d4bbf6ce8123af4cf66","717531ee1c80469b8501a6d936939d4f","c386c0e2708d41ba84bd2fc4fbcc6093","4ef6d7d419b946a9959e65c255f0483c","2c95b7e23e834864979be99f201a46a9","1854a68fa2934d97bb8f2849fa811c81","aeaff771cba94151ac61e95e6f76ba97","e409c0571a5f4cfe8547ca3775e748ed","90d1ee759fe34ad487807c6fdbf115b3","018e8f6dc2184b84b0fe74754876632e","bc4fba7f868740b69d42a0caa7469dbe","592648634c69461586675a8101004a65"]},"executionInfo":{"status":"ok","timestamp":1638047373389,"user_tz":480,"elapsed":21654,"user":{"displayName":"Shilpa Nair","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14689458463016539498"}},"outputId":"93278aa9-1292-470d-bacf-c5b8fc246e97"},"source":["from simcse import SimCSE\n","model = SimCSE(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n","## is supervised and case insensitive"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"75654a58e9004b90a9e60f18498ee66c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=689.0, style=ProgressStyle(description_…"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f19594687712477985c327deafc8cd2d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ebf1d8f63f454e75a6a28e8c66627934","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"83737fc064bd461e98116d4b51c33298","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=252.0, style=ProgressStyle(description_…"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c95b7e23e834864979be99f201a46a9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=437998343.0, style=ProgressStyle(descri…"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jq9hdUHlZhwd","executionInfo":{"status":"ok","timestamp":1638021719836,"user_tz":480,"elapsed":49,"user":{"displayName":"zeeshan ahmad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15348670853435150367"}},"outputId":"60e95a6e-a8b2-4500-c608-b9bbf6e05552"},"source":["print(model)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<simcse.tool.SimCSE object at 0x7fbb99d1bc90>\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3eDGEoHsF7zL","executionInfo":{"status":"ok","timestamp":1638047531597,"user_tz":480,"elapsed":838,"user":{"displayName":"Shilpa Nair","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14689458463016539498"}},"outputId":"4d798183-f680-4012-c669-f7d8734e7a8e"},"source":["embeddings = model.encode(\"A WOMAN IS READING.\")\n","embeddings1 = model.encode(\"A Woman Is Reading.\")\n","embeddings2 = model.encode(\"a woman is reading.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 104.47it/s]\n","100%|██████████| 1/1 [00:00<00:00, 107.70it/s]\n","100%|██████████| 1/1 [00:00<00:00, 112.67it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uoAKiybjaUTe","executionInfo":{"status":"ok","timestamp":1638050658800,"user_tz":480,"elapsed":5171,"user":{"displayName":"Shilpa Nair","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14689458463016539498"}},"outputId":"4517f1d5-7b32-484e-fe36-49cf3a4008b5"},"source":["\n","tokenizer = AutoTokenizer.from_pretrained(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n","\n","tokens = tokenizer.tokenize(\"What <extended> happened!\")\n","print(tokens)\n","ids = tokenizer.convert_tokens_to_ids(tokens)\n","print(ids)\n","\n","# ['hello', 'tensor', '##flow', '!']\n","# [7592, 23435, 12314, 999]"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['what', '<', 'extended', '>', 'happened', '!']\n","[2054, 1026, 3668, 1028, 3047, 999]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vT06Hv-8SwhN","executionInfo":{"status":"ok","timestamp":1638049719170,"user_tz":480,"elapsed":803,"user":{"displayName":"Shilpa Nair","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14689458463016539498"}},"outputId":"01ab2dcb-05c7-40a7-c679-b09bb407ba72"},"source":["model.similarity(['whaaaaaaaaatttttt'], ['whaaaattttttttttt'])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 53.72it/s]\n","100%|██████████| 1/1 [00:00<00:00, 54.18it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[0.9895264]], dtype=float32)"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365,"referenced_widgets":["88ff17c99dcf4143bad2bb49cb817d27","972618cbe1d24dfd9af1f7f4029b9e97","39e1661e8cd84f429d08a937cce4a927","225162709373480795a83430a27e8c22","4f61a1c8471b4c87b26fc3414ef65635","01dcefc9d2394526b1f6ef567240c1cf","58fb109b208f4420943869b8b56d7b9e","4fd4d5d3729846f3b6fafb9d7944a7bc","c40e91da11f746a6bcd6feff48e75c1f","4dffacafdba84a1eb3475cd343b7af0d","3a8392ff7b2048f3b513d5fce5168a13","8a2996c820d047ea994a32c56621df56","978dcdf1c3544472a46a1d9a041993b8","68d35d789d8c4652bb157967ea6844ec","67a6d908ebdb48b2b8320078d35fe29c","4ab53a6963804f1e8d91ba4f971d700d","08bb817c04074f79baea77e6f93c5086","67b64987f4f049fc8d2576d3e7780495","2df7bc2468cc425d8871bfe366ce49b9","5ddcdb813feb49728058351ce80d4be1","0cb9773f6a944ceaac3e27933e4a6fe2","1db141382f5646889e2842c985f93441","8675f48bde694cd6bc0583a2ddb7ceff","157ccb556bd04bebb72ceb9925e68326","9666f9574f244cffab8aa2b4aae63091","7ab9cb808aed49449850cf09f2fe0fa9","452f8d7bfb7f448187fdab6b5d7ed811","680d11d24053496a87c42b295ff1b378","829682c03cec41e4b939bf8b452bba4c","25e60ce148874cee837a738cb4d2c4f6","729c0a88ef3449f7b19aa5dd363c0e30","dca1bfcec7a6429595c39e0c7b91f077","a5b0b2ffc7974a76a91ecc0dccab7221","d0cc54ebaef64dd88d6c8743ad90226c","d3cbc93da116424bb66fa89e25ea0863","e54530c4e7c940c3933a4bea72d41e67","81b0d91a30ff4cb2b6882281136ea771","6a2cce141b4f414d8f78cd8cff40e7f9","57d6b2cbb53f4183b47682af44017f53","8f79677445a8411cac5cceecae76722f","2edec5e2b30f478284c048ff18fa887d","ebb5fa7afc414c20bfca63d42477df31","35f7566d4b9040a381997ca1764627f4","e86a373c54ec478b933aee1d4a3a84f9","56d982976c4345a49a97b73f8b41a807","fbc598b75b5d4a3eb232215874cae820","510d7a85b38440a985e97c66ad12e447","0611c62128a6410d9fad435166a769b8"]},"id":"huPnEbi_Prj-","executionInfo":{"status":"ok","timestamp":1638047689388,"user_tz":480,"elapsed":44773,"user":{"displayName":"Shilpa Nair","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14689458463016539498"}},"outputId":"80b85992-5ffa-4428-c381-8d6b91a5f2b7"},"source":["model = SimCSE(\"princeton-nlp/sup-simcse-roberta-large\")\n","embeddings = model.encode(\"A WOMAN IS READING.\")\n","embeddings1 = model.encode(\"A Woman Is Reading.\")\n","embeddings2 = model.encode(\"a woman is reading.\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"88ff17c99dcf4143bad2bb49cb817d27","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=664.0, style=ProgressStyle(description_…"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c40e91da11f746a6bcd6feff48e75c1f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=798293.0, style=ProgressStyle(descripti…"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"08bb817c04074f79baea77e6f93c5086","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456356.0, style=ProgressStyle(descripti…"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9666f9574f244cffab8aa2b4aae63091","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=239.0, style=ProgressStyle(description_…"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a5b0b2ffc7974a76a91ecc0dccab7221","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=256.0, style=ProgressStyle(description_…"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2edec5e2b30f478284c048ff18fa887d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1421571527.0, style=ProgressStyle(descr…"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 45.44it/s]\n","100%|██████████| 1/1 [00:00<00:00, 55.92it/s]\n","100%|██████████| 1/1 [00:00<00:00, 66.51it/s]\n"]}]},{"cell_type":"code","metadata":{"id":"0f-fKyTjm0-1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638047734202,"user_tz":480,"elapsed":953,"user":{"displayName":"Shilpa Nair","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14689458463016539498"}},"outputId":"79a18e2b-6309-4fb4-c476-ea4c0f5783c9"},"source":["embeddings == embeddings1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([False, False, False,  ..., False, False, False])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_BAwzO-OGYB2","executionInfo":{"status":"ok","timestamp":1637887940150,"user_tz":480,"elapsed":197,"user":{"displayName":"Rishibha Bansal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562060109829238780"}},"outputId":"d3c1a67f-d8e3-49c3-8707-25d47f7731b1"},"source":["print(embeddings.size())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([768])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-N-B4-gMJFdj","executionInfo":{"status":"ok","timestamp":1637887942194,"user_tz":480,"elapsed":544,"user":{"displayName":"Rishibha Bansal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562060109829238780"}},"outputId":"1c8365a8-31a9-4afe-c8e5-8e19b7c31aae"},"source":["#Compute the cosine similarities between two groups of sentences\n","sentences_a = ['A woman is reading.', 'A man is playing a guitar.']\n","sentences_b = ['He plays guitar.', 'A woman is making a photo.']\n","similarities = model.similarity(sentences_a, sentences_b)\n","print(\"\\nSim1:\",similarities)\n","sentences_a = ['A woman is reading.', 'A man is playing a guitar.']\n","sentences_b = ['He is reading.', 'A woman is making a photo.']\n","similarities = model.similarity(sentences_a, sentences_b)\n","print(\"\\nSim2\", similarities)\n","sentences_a = ['A woman is reading.',  'A man is playing a guitar.']\n","sentences_b = ['He is reading.']\n","similarities = model.similarity(sentences_a, sentences_b)\n","print(\"\\nSim3:\",similarities)\n","sentences_a = ['A woman is reading.']\n","sentences_b = ['He is reading.']\n","similarities = model.similarity(sentences_a, sentences_b)\n","print(\"\\nSim4:\",similarities)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:00<00:00, 53.43it/s]\n","100%|██████████| 1/1 [00:00<00:00, 46.20it/s]\n","100%|██████████| 1/1 [00:00<00:00, 58.46it/s]\n","100%|██████████| 1/1 [00:00<00:00, 52.59it/s]\n","100%|██████████| 1/1 [00:00<00:00, 66.14it/s]\n","100%|██████████| 1/1 [00:00<00:00, 75.26it/s]\n","100%|██████████| 1/1 [00:00<00:00, 69.17it/s]\n","100%|██████████| 1/1 [00:00<00:00, 73.15it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Sim1: [[0.01262089 0.3446951 ]\n"," [0.8938425  0.04842839]]\n","\n","Sim2 [[0.65000594 0.3446951 ]\n"," [0.264742   0.04842839]]\n","\n","Sim3: [[0.65000594]\n"," [0.26474205]]\n","\n","Sim4: [[0.6500059]]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Wvhl50DTn4Q","executionInfo":{"status":"ok","timestamp":1638049494374,"user_tz":480,"elapsed":828,"user":{"displayName":"Shilpa Nair","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14689458463016539498"}},"outputId":"bd3b6d83-2c35-48ab-9db5-c30cdf4c78bc"},"source":["#build index for a group of sentences and search among them\n","sentences = ['what_extended','what']\n","model.build_index(sentences)\n","results = model.search(\"whaaaaaaaaaaat\")\n","print(\"\\nRes1:\",results)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["11/27/2021 21:44:56 - WARNING - simcse.tool -   Fail to import faiss. If you want to use faiss, install faiss through PyPI. Now the program continues with brute force search.\n","11/27/2021 21:44:56 - INFO - simcse.tool -   Encoding embeddings for sentences...\n","100%|██████████| 1/1 [00:00<00:00, 57.24it/s]\n","11/27/2021 21:44:56 - INFO - simcse.tool -   Building index...\n","11/27/2021 21:44:56 - INFO - simcse.tool -   Finished\n","100%|██████████| 1/1 [00:00<00:00, 65.92it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Res1: [('what', 1.0000001192092896)]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ciMoiLb5neCK","executionInfo":{"status":"ok","timestamp":1637887946331,"user_tz":480,"elapsed":225,"user":{"displayName":"Rishibha Bansal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562060109829238780"}},"outputId":"40b31df2-65eb-451b-bb3e-e69f7b654646"},"source":["#build index for a group of sentences and search among them\n","sentences = ['She has 10 apples','She has 100000 apples']\n","model.build_index(sentences)\n","results = model.search(\"He has 100000 apples\")\n","print(\"\\nRes1:\",results)\n","results = model.search(\"He has 10 apples.\")\n","print(\"\\nRes2:\",results)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["11/26/2021 00:52:26 - WARNING - simcse.tool -   Fail to import faiss. If you want to use faiss, install faiss through PyPI. Now the program continues with brute force search.\n","11/26/2021 00:52:26 - INFO - simcse.tool -   Encoding embeddings for sentences...\n","100%|██████████| 1/1 [00:00<00:00, 50.01it/s]\n","11/26/2021 00:52:26 - INFO - simcse.tool -   Building index...\n","11/26/2021 00:52:26 - INFO - simcse.tool -   Finished\n","100%|██████████| 1/1 [00:00<00:00, 58.34it/s]\n","100%|██████████| 1/1 [00:00<00:00, 73.45it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Res1: [('She has 100000 apples', 0.8586735725402832), ('She has 10 apples', 0.6768637299537659)]\n","\n","Res2: [('She has 10 apples', 0.8687605857849121), ('She has 100000 apples', 0.6759915947914124)]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w23N9d3EJCPN","executionInfo":{"status":"ok","timestamp":1637887949794,"user_tz":480,"elapsed":477,"user":{"displayName":"Rishibha Bansal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562060109829238780"}},"outputId":"c1bde828-dcc9-4c18-f75d-c87487c0c498"},"source":["#build index for a group of sentences and search among them\n","sentences = ['A woman is reading.', 'A man is playing a guitar.']\n","model.build_index(sentences)\n","results = model.search(\"He plays guitar.\")\n","print(\"\\nRes1:\",results)\n","results = model.search(\"She plays guitar.\")\n","print(\"\\nRes2:\",results)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["11/26/2021 00:52:29 - WARNING - simcse.tool -   Fail to import faiss. If you want to use faiss, install faiss through PyPI. Now the program continues with brute force search.\n","11/26/2021 00:52:29 - INFO - simcse.tool -   Encoding embeddings for sentences...\n","100%|██████████| 1/1 [00:00<00:00,  5.57it/s]\n","11/26/2021 00:52:29 - INFO - simcse.tool -   Building index...\n","11/26/2021 00:52:29 - INFO - simcse.tool -   Finished\n","100%|██████████| 1/1 [00:00<00:00, 47.49it/s]\n","100%|██████████| 1/1 [00:00<00:00, 70.97it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Res1: [('A man is playing a guitar.', 0.8938425779342651)]\n","\n","Res2: [('A man is playing a guitar.', 0.6488244533538818)]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VmkJGN2sGGmB","executionInfo":{"status":"ok","timestamp":1637888223462,"user_tz":480,"elapsed":229,"user":{"displayName":"Rishibha Bansal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07562060109829238780"}},"outputId":"e5ae6075-e885-4aba-f73a-c0681cd8f325"},"source":["#build index for a group of sentences and search among them\n","sentences = [\"whaaat!\", \"whaaattttt\"]\n","model.build_index(sentences)\n","results = model.search(\"what\")\n","print(\"\\nRes1:\",results)\n","sentences_a = [\"whaat\", \"whatt\"]\n","sentences_b = [\"what\"]\n","similarities = model.similarity(sentences_a, sentences_b)\n","print(\"\\nSim1:\",similarities)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["11/26/2021 00:57:03 - WARNING - simcse.tool -   Fail to import faiss. If you want to use faiss, install faiss through PyPI. Now the program continues with brute force search.\n","11/26/2021 00:57:03 - INFO - simcse.tool -   Encoding embeddings for sentences...\n","100%|██████████| 1/1 [00:00<00:00, 53.17it/s]\n","11/26/2021 00:57:03 - INFO - simcse.tool -   Building index...\n","11/26/2021 00:57:03 - INFO - simcse.tool -   Finished\n","100%|██████████| 1/1 [00:00<00:00, 51.46it/s]\n","100%|██████████| 1/1 [00:00<00:00, 61.36it/s]\n","100%|██████████| 1/1 [00:00<00:00, 63.04it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Res1: []\n","\n","Sim1: [[0.6356628]\n"," [0.874833 ]]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","metadata":{"id":"HCnESUCl1Klj"},"source":["# Uncomment the code below if we need to get the SimCSE code from their git\n","# !wget https://github.com/princeton-nlp/SimCSE/archive/refs/heads/main.zip\n","# !unzip main.zip\n","# !cd SimCSE-main/SentEval/data/downstream/ && wget https://huggingface.co/datasets/princeton-nlp/datasets-for-simcse/resolve/main/senteval.tar && tar xvf senteval.tar\n","# !ls SimCSE-main/SentEval/data/downstream/STS/STSBenchmark/\n","# !wget https://huggingface.co/datasets/princeton-nlp/datasets-for-simcse/resolve/main/nli_for_simcse.csv"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HP1_EdN9mkhH"},"source":["# Train"]},{"cell_type":"code","metadata":{"id":"dTE4fxlNTWEQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638236409944,"user_tz":480,"elapsed":1118,"user":{"displayName":"Venkatesh Madi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjEBVZrlTFNDzPSl7eB4CL2YPLP-bfPlNxWSqr0tEc=s64","userId":"10204830288063877139"}},"outputId":"a421d564-3a54-4f2a-9d11-ab4555a54543"},"source":["#Run this!\n","\n","%cd ../content/drive/MyDrive/CSCI_544_NLP_Project/Twitter_Bot_Detection/Data/Model_TwiBot_Similarity_With_Metadata_360k_Tweets\n","!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1ygEmNCP-_htwwx_sBJE2NdJ3Nb7aJhr3/CSCI_544_NLP_Project/Twitter_Bot_Detection/Data/Model_TwiBot_Similarity_With_Metadata_360k_Tweets\n","/content/drive/.shortcut-targets-by-id/1ygEmNCP-_htwwx_sBJE2NdJ3Nb7aJhr3/CSCI_544_NLP_Project/Twitter_Bot_Detection/Data/Model_TwiBot_Similarity_With_Metadata_360k_Tweets\n"]}]},{"cell_type":"markdown","metadata":{"id":"Ju1hyZWHdDZs"},"source":["## Deleting a folder - USE WITH CAUTION!\n"]},{"cell_type":"code","metadata":{"id":"9IIrrIepcv5G"},"source":["# import shutil\n","# shutil.rmtree('/content/drive/MyDrive/CSCI_544_NLP_Project/Twitter_Bot_Detection/Data/twiBot-similarity-20epochs-sup-simcse-bert-base-uncased')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"beJqkyTVvofo"},"source":["## Training with TwiBot - GPU"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vIjIY0nxvt3p","executionInfo":{"status":"ok","timestamp":1637364075338,"user_tz":480,"elapsed":433,"user":{"displayName":"zeeshan ahmad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15348670853435150367"}},"outputId":"e65f784b-1805-47ff-de84-6c5ccf212edc"},"source":["!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1ygEmNCP-_htwwx_sBJE2NdJ3Nb7aJhr3/CSCI_544_NLP_Project/Twitter_Bot_Detection/Data\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XvHsQRtuvsZf","executionInfo":{"status":"ok","timestamp":1637364740318,"user_tz":480,"elapsed":663729,"user":{"displayName":"zeeshan ahmad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15348670853435150367"}},"outputId":"3bcfdc34-404f-4b97-bc76-b415b5941188"},"source":["!cd SimCSE-main && python train.py --model_name_or_path bert-base-uncased \\\n","    --train_file ../train_triplets.csv \\\n","    --output_dir ../twiBot-sup-simcse-bert-base-uncased \\\n","    --num_train_epochs 1 \\\n","    --per_device_train_batch_size 32 \\\n","    --learning_rate 5e-5 \\\n","    --max_seq_length 32 \\\n","    --evaluation_strategy steps \\\n","    --metric_for_best_model stsb_spearman \\\n","    --load_best_model_at_end \\\n","    --overwrite_output_dir \\\n","    --temp 0.05 \\\n","    --do_train \\"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["11/19/2021 23:21:27 - INFO - __main__ -   PyTorch: setting up devices\n","11/19/2021 23:21:27 - INFO - __main__ -   Set device to CUDA\n","11/19/2021 23:21:27 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1 distributed training: False, 16-bits training: False\n","11/19/2021 23:21:27 - INFO - __main__ -   Training/evaluation parameters OurTrainingArguments(output_dir='../twiBot-sup-simcse-bert-base-uncased', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_steps=0, logging_dir='runs/Nov19_23-21-27_76b2d4b544f2', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', fp16_backend='auto', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='../twiBot-sup-simcse-bert-base-uncased', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model='stsb_spearman', greater_is_better=True, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, eval_transfer=False)\n","Downloading: 5.33kB [00:00, 5.30MB/s]       \n","Using custom data configuration default\n","Reusing dataset csv (./data/csv/default-d9d1c7722e0e7e63/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2)\n","[INFO|file_utils.py:1272] 2021-11-19 23:21:31,524 >> https://huggingface.co/bert-base-uncased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp7kel_za9\n","Downloading: 100% 570/570 [00:00<00:00, 478kB/s]\n","[INFO|file_utils.py:1276] 2021-11-19 23:21:31,801 >> storing https://huggingface.co/bert-base-uncased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|file_utils.py:1279] 2021-11-19 23:21:31,801 >> creating metadata file for /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|configuration_utils.py:445] 2021-11-19 23:21:31,801 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|configuration_utils.py:481] 2021-11-19 23:21:31,802 >> Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|configuration_utils.py:445] 2021-11-19 23:21:32,073 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|configuration_utils.py:481] 2021-11-19 23:21:32,073 >> Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|file_utils.py:1272] 2021-11-19 23:21:32,348 >> https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp_opzmue5\n","Downloading: 100% 232k/232k [00:00<00:00, 922kB/s]\n","[INFO|file_utils.py:1276] 2021-11-19 23:21:32,874 >> storing https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","[INFO|file_utils.py:1279] 2021-11-19 23:21:32,874 >> creating metadata file for /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","[INFO|file_utils.py:1272] 2021-11-19 23:21:33,150 >> https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmplq0r349q\n","Downloading: 100% 466k/466k [00:00<00:00, 1.47MB/s]\n","[INFO|file_utils.py:1276] 2021-11-19 23:21:33,746 >> storing https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","[INFO|file_utils.py:1279] 2021-11-19 23:21:33,746 >> creating metadata file for /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","[INFO|tokenization_utils_base.py:1766] 2021-11-19 23:21:33,746 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","[INFO|tokenization_utils_base.py:1766] 2021-11-19 23:21:33,747 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","[INFO|file_utils.py:1272] 2021-11-19 23:21:34,040 >> https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp_vlodq3d\n","Downloading: 100% 440M/440M [00:10<00:00, 41.9MB/s]\n","[INFO|file_utils.py:1276] 2021-11-19 23:21:44,632 >> storing https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","[INFO|file_utils.py:1279] 2021-11-19 23:21:44,632 >> creating metadata file for /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","[INFO|modeling_utils.py:1027] 2021-11-19 23:21:44,632 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","[WARNING|modeling_utils.py:1135] 2021-11-19 23:21:48,272 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForCL: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n","- This IS expected if you are initializing BertForCL from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForCL from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[WARNING|modeling_utils.py:1146] 2021-11-19 23:21:48,272 >> Some weights of BertForCL were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['mlp.dense.weight', 'mlp.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Loading cached processed dataset at ./data/csv/default-d9d1c7722e0e7e63/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2/cache-fd47a88cc5fd8452.arrow\n","/usr/local/lib/python3.7/dist-packages/_distutils_hack/__init__.py:19: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n","  \"Distutils was imported before Setuptools. This usage is discouraged \"\n","[INFO|trainer.py:442] 2021-11-19 23:21:54,410 >> The following columns in the training set don't have a corresponding argument in `BertForCL.forward` and have been ignored: .\n","11/19/2021 23:21:54 - INFO - simcse.trainers -   ***** Running training *****\n","11/19/2021 23:21:54 - INFO - simcse.trainers -     Num examples = 20000\n","11/19/2021 23:21:54 - INFO - simcse.trainers -     Num Epochs = 1\n","11/19/2021 23:21:54 - INFO - simcse.trainers -     Instantaneous batch size per device = 32\n","11/19/2021 23:21:54 - INFO - simcse.trainers -     Total train batch size (w. parallel, distributed & accumulation) = 32\n","11/19/2021 23:21:54 - INFO - simcse.trainers -     Gradient Accumulation steps = 1\n","11/19/2021 23:21:54 - INFO - simcse.trainers -     Total optimization steps = 625\n","{'loss': 4.1662, 'learning_rate': 1e-05, 'epoch': 0.8}\n","{'eval_stsb_spearman': 0.20204853209131643, 'eval_sickr_spearman': 0.24814244405412764, 'eval_avg_sts': 0.22509548807272203, 'epoch': 0.8}\n"," 80% 500/625 [03:09<00:37,  3.29it/s][INFO|trainer.py:1344] 2021-11-19 23:25:04,213 >> Saving model checkpoint to ../twiBot-sup-simcse-bert-base-uncased\n","[INFO|configuration_utils.py:300] 2021-11-19 23:25:04,220 >> Configuration saved in ../twiBot-sup-simcse-bert-base-uncased/config.json\n","[INFO|modeling_utils.py:817] 2021-11-19 23:25:05,765 >> Model weights saved in ../twiBot-sup-simcse-bert-base-uncased/pytorch_model.bin\n","100% 625/625 [03:52<00:00,  3.30it/s]11/19/2021 23:25:47 - INFO - simcse.trainers -   \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","11/19/2021 23:25:47 - INFO - simcse.trainers -   Loading best model from ../twiBot-sup-simcse-bert-base-uncased (score: 0.20204853209131643).\n","[INFO|configuration_utils.py:443] 2021-11-19 23:25:47,342 >> loading configuration file ../twiBot-sup-simcse-bert-base-uncased/config.json\n","[INFO|configuration_utils.py:481] 2021-11-19 23:25:47,343 >> Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForCL\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|modeling_utils.py:1025] 2021-11-19 23:25:47,344 >> loading weights file ../twiBot-sup-simcse-bert-base-uncased/pytorch_model.bin\n","[INFO|modeling_utils.py:1143] 2021-11-19 23:25:50,583 >> All model checkpoint weights were used when initializing BertForCL.\n","\n","[INFO|modeling_utils.py:1152] 2021-11-19 23:25:50,583 >> All the weights of BertForCL were initialized from the model checkpoint at ../twiBot-sup-simcse-bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForCL for predictions without further training.\n","{'train_runtime': 236.2565, 'train_samples_per_second': 2.645, 'epoch': 1.0}\n","100% 625/625 [03:56<00:00,  2.65it/s]\n","[INFO|trainer.py:1344] 2021-11-19 23:25:50,677 >> Saving model checkpoint to ../twiBot-sup-simcse-bert-base-uncased\n","[INFO|configuration_utils.py:300] 2021-11-19 23:25:50,682 >> Configuration saved in ../twiBot-sup-simcse-bert-base-uncased/config.json\n","[INFO|modeling_utils.py:817] 2021-11-19 23:25:52,286 >> Model weights saved in ../twiBot-sup-simcse-bert-base-uncased/pytorch_model.bin\n","11/19/2021 23:25:53 - INFO - __main__ -   ***** Train results *****\n","11/19/2021 23:25:53 - INFO - __main__ -     epoch = 1.0\n","11/19/2021 23:25:53 - INFO - __main__ -     train_runtime = 236.2565\n","11/19/2021 23:25:53 - INFO - __main__ -     train_samples_per_second = 2.645\n","11/19/2021 23:25:53 - INFO - __main__ -   *** Evaluate ***\n","11/19/2021 23:26:29 - INFO - root -   Generating sentence embeddings\n","11/19/2021 23:26:43 - INFO - root -   Generated sentence embeddings\n","11/19/2021 23:26:43 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/19/2021 23:26:54 - INFO - root -   Best param found at split 1: l2reg = 1e-05                 with score 49.99\n","11/19/2021 23:27:06 - INFO - root -   Best param found at split 2: l2reg = 1e-05                 with score 50.01\n","11/19/2021 23:27:17 - INFO - root -   Best param found at split 3: l2reg = 1e-05                 with score 50.0\n","11/19/2021 23:27:29 - INFO - root -   Best param found at split 4: l2reg = 1e-05                 with score 50.0\n","11/19/2021 23:27:40 - INFO - root -   Best param found at split 5: l2reg = 1e-05                 with score 50.0\n","11/19/2021 23:27:42 - INFO - root -   Generating sentence embeddings\n","11/19/2021 23:27:46 - INFO - root -   Generated sentence embeddings\n","11/19/2021 23:27:46 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/19/2021 23:27:50 - INFO - root -   Best param found at split 1: l2reg = 0.01                 with score 63.81\n","11/19/2021 23:27:54 - INFO - root -   Best param found at split 2: l2reg = 1e-05                 with score 63.77\n","11/19/2021 23:27:59 - INFO - root -   Best param found at split 3: l2reg = 1e-05                 with score 63.77\n","11/19/2021 23:28:03 - INFO - root -   Best param found at split 4: l2reg = 1e-05                 with score 63.74\n","11/19/2021 23:28:07 - INFO - root -   Best param found at split 5: l2reg = 1e-05                 with score 63.74\n","11/19/2021 23:28:08 - INFO - root -   Generating sentence embeddings\n","11/19/2021 23:28:23 - INFO - root -   Generated sentence embeddings\n","11/19/2021 23:28:23 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/19/2021 23:28:33 - INFO - root -   Best param found at split 1: l2reg = 1e-05                 with score 50.0\n","11/19/2021 23:28:43 - INFO - root -   Best param found at split 2: l2reg = 1e-05                 with score 50.0\n","11/19/2021 23:28:54 - INFO - root -   Best param found at split 3: l2reg = 1e-05                 with score 50.0\n","11/19/2021 23:29:04 - INFO - root -   Best param found at split 4: l2reg = 1e-05                 with score 50.0\n","11/19/2021 23:29:15 - INFO - root -   Best param found at split 5: l2reg = 1e-05                 with score 50.0\n","11/19/2021 23:29:16 - INFO - root -   Generating sentence embeddings\n","11/19/2021 23:29:20 - INFO - root -   Generated sentence embeddings\n","11/19/2021 23:29:20 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/19/2021 23:29:31 - INFO - root -   Best param found at split 1: l2reg = 1e-05                 with score 68.78\n","11/19/2021 23:29:43 - INFO - root -   Best param found at split 2: l2reg = 1e-05                 with score 68.77\n","11/19/2021 23:29:55 - INFO - root -   Best param found at split 3: l2reg = 1e-05                 with score 68.77\n","11/19/2021 23:30:07 - INFO - root -   Best param found at split 4: l2reg = 1e-05                 with score 68.77\n","11/19/2021 23:30:19 - INFO - root -   Best param found at split 5: l2reg = 1e-05                 with score 68.78\n","11/19/2021 23:30:22 - INFO - root -   Computing embedding for train\n","11/19/2021 23:31:09 - INFO - root -   Computed train embeddings\n","11/19/2021 23:31:09 - INFO - root -   Computing embedding for dev\n","11/19/2021 23:31:10 - INFO - root -   Computed dev embeddings\n","11/19/2021 23:31:10 - INFO - root -   Computing embedding for test\n","11/19/2021 23:31:12 - INFO - root -   Computed test embeddings\n","11/19/2021 23:31:12 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..\n","11/19/2021 23:31:36 - INFO - root -   [('reg:1e-05', 50.92), ('reg:0.0001', 50.92), ('reg:0.001', 50.92), ('reg:0.01', 50.92)]\n","11/19/2021 23:31:36 - INFO - root -   Validation : best param found is reg = 1e-05 with score             50.92\n","11/19/2021 23:31:36 - INFO - root -   Evaluating...\n","11/19/2021 23:31:42 - INFO - root -   ***** Transfer task : TREC *****\n","\n","\n","11/19/2021 23:31:46 - INFO - root -   Computed train embeddings\n","11/19/2021 23:31:47 - INFO - root -   Computed test embeddings\n","11/19/2021 23:31:47 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation\n","11/19/2021 23:31:55 - INFO - root -   [('reg:1e-05', 23.17), ('reg:0.0001', 22.73), ('reg:0.001', 22.62), ('reg:0.01', 23.29)]\n","11/19/2021 23:31:55 - INFO - root -   Cross-validation : best param found is reg = 0.01             with score 23.29\n","11/19/2021 23:31:55 - INFO - root -   Evaluating...\n","11/19/2021 23:31:55 - INFO - root -   ***** Transfer task : MRPC *****\n","\n","\n","11/19/2021 23:31:56 - INFO - root -   Computing embedding for train\n","11/19/2021 23:32:07 - INFO - root -   Computed train embeddings\n","11/19/2021 23:32:07 - INFO - root -   Computing embedding for test\n","11/19/2021 23:32:11 - INFO - root -   Computed test embeddings\n","11/19/2021 23:32:11 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation\n","11/19/2021 23:32:18 - INFO - root -   [('reg:1e-05', 67.76), ('reg:0.0001', 67.69), ('reg:0.001', 67.59), ('reg:0.01', 67.57)]\n","11/19/2021 23:32:18 - INFO - root -   Cross-validation : best param found is reg = 1e-05             with score 67.76\n","11/19/2021 23:32:18 - INFO - root -   Evaluating...\n","11/19/2021 23:32:18 - INFO - __main__ -   ***** Eval results *****\n","11/19/2021 23:32:18 - INFO - __main__ -     epoch = 1.0\n","11/19/2021 23:32:18 - INFO - __main__ -     eval_CR = 63.77\n","11/19/2021 23:32:18 - INFO - __main__ -     eval_MPQA = 68.77\n","11/19/2021 23:32:18 - INFO - __main__ -     eval_MR = 50.0\n","11/19/2021 23:32:18 - INFO - __main__ -     eval_MRPC = 67.76\n","11/19/2021 23:32:18 - INFO - __main__ -     eval_SST2 = 50.92\n","11/19/2021 23:32:18 - INFO - __main__ -     eval_SUBJ = 50.0\n","11/19/2021 23:32:18 - INFO - __main__ -     eval_TREC = 23.29\n","11/19/2021 23:32:18 - INFO - __main__ -     eval_avg_sts = 0.22509548807272203\n","11/19/2021 23:32:18 - INFO - __main__ -     eval_avg_transfer = 53.501428571428576\n","11/19/2021 23:32:18 - INFO - __main__ -     eval_sickr_spearman = 0.24814244405412764\n","11/19/2021 23:32:18 - INFO - __main__ -     eval_stsb_spearman = 0.20204853209131643\n"]}]},{"cell_type":"markdown","metadata":{"id":"XotekNFD1D2k"},"source":["## Training with TwiBot 20 epochs - GPU"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZtClBxfZ1AZf","executionInfo":{"status":"ok","timestamp":1637240607335,"user_tz":480,"elapsed":5253315,"user":{"displayName":"zeeshan ahmad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15348670853435150367"}},"outputId":"36a0c318-35be-443a-be4b-399ce346c78f"},"source":["!cd SimCSE-main && python train.py --model_name_or_path bert-base-uncased \\\n","    --train_file ../train_triplets.csv \\\n","    --output_dir ../twiBot-20epochs-sup-simcse-bert-base-uncased \\\n","    --num_train_epochs 20 \\\n","    --per_device_train_batch_size 32 \\\n","    --learning_rate 5e-5 \\\n","    --max_seq_length 32 \\\n","    --evaluation_strategy steps \\\n","    --metric_for_best_model stsb_spearman \\\n","    --load_best_model_at_end \\\n","    --pooler_type cls \\\n","    --overwrite_output_dir \\\n","    --temp 0.05 \\\n","    --do_train \\"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["11/18/2021 11:35:58 - INFO - __main__ -   PyTorch: setting up devices\n","11/18/2021 11:35:58 - INFO - __main__ -   Set device to CUDA\n","11/18/2021 11:35:58 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1 distributed training: False, 16-bits training: False\n","11/18/2021 11:35:58 - INFO - __main__ -   Training/evaluation parameters OurTrainingArguments(output_dir='../twiBot-20epochs-sup-simcse-bert-base-uncased', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=20.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_steps=0, logging_dir='runs/Nov18_11-35-58_9d4b5f2cfaf0', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', fp16_backend='auto', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='../twiBot-20epochs-sup-simcse-bert-base-uncased', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model='stsb_spearman', greater_is_better=True, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, eval_transfer=False)\n","Using custom data configuration default\n","Reusing dataset csv (./data/csv/default-d9d1c7722e0e7e63/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2)\n","[INFO|configuration_utils.py:445] 2021-11-18 11:36:01,277 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|configuration_utils.py:481] 2021-11-18 11:36:01,277 >> Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|configuration_utils.py:445] 2021-11-18 11:36:02,037 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|configuration_utils.py:481] 2021-11-18 11:36:02,037 >> Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|tokenization_utils_base.py:1766] 2021-11-18 11:36:03,539 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","[INFO|tokenization_utils_base.py:1766] 2021-11-18 11:36:03,539 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","[INFO|modeling_utils.py:1027] 2021-11-18 11:36:04,308 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","[WARNING|modeling_utils.py:1135] 2021-11-18 11:36:07,860 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForCL: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n","- This IS expected if you are initializing BertForCL from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForCL from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[WARNING|modeling_utils.py:1146] 2021-11-18 11:36:07,861 >> Some weights of BertForCL were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['mlp.dense.weight', 'mlp.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Loading cached processed dataset at ./data/csv/default-d9d1c7722e0e7e63/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2/cache-fd47a88cc5fd8452.arrow\n","/usr/local/lib/python3.7/dist-packages/_distutils_hack/__init__.py:19: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n","  \"Distutils was imported before Setuptools. This usage is discouraged \"\n","[INFO|trainer.py:442] 2021-11-18 11:36:11,609 >> The following columns in the training set don't have a corresponding argument in `BertForCL.forward` and have been ignored: .\n","11/18/2021 11:36:11 - INFO - simcse.trainers -   ***** Running training *****\n","11/18/2021 11:36:11 - INFO - simcse.trainers -     Num examples = 20000\n","11/18/2021 11:36:11 - INFO - simcse.trainers -     Num Epochs = 20\n","11/18/2021 11:36:11 - INFO - simcse.trainers -     Instantaneous batch size per device = 32\n","11/18/2021 11:36:11 - INFO - simcse.trainers -     Total train batch size (w. parallel, distributed & accumulation) = 32\n","11/18/2021 11:36:11 - INFO - simcse.trainers -     Gradient Accumulation steps = 1\n","11/18/2021 11:36:11 - INFO - simcse.trainers -     Total optimization steps = 12500\n","{'loss': 4.1655, 'learning_rate': 4.8e-05, 'epoch': 0.8}\n","{'eval_stsb_spearman': 0.5518227408955312, 'eval_sickr_spearman': 0.5397860369657473, 'eval_avg_sts': 0.5458043889306392, 'epoch': 0.8}\n","  4% 500/12500 [03:06<1:00:45,  3.29it/s][INFO|trainer.py:1344] 2021-11-18 11:39:17,910 >> Saving model checkpoint to ../twiBot-20epochs-sup-simcse-bert-base-uncased\n","[INFO|configuration_utils.py:300] 2021-11-18 11:39:17,916 >> Configuration saved in ../twiBot-20epochs-sup-simcse-bert-base-uncased/config.json\n","[INFO|modeling_utils.py:817] 2021-11-18 11:39:19,880 >> Model weights saved in ../twiBot-20epochs-sup-simcse-bert-base-uncased/pytorch_model.bin\n","{'loss': 4.1594, 'learning_rate': 4.600000000000001e-05, 'epoch': 1.6}\n","{'eval_stsb_spearman': 0.4836384689363567, 'eval_sickr_spearman': 0.5249892376347858, 'eval_avg_sts': 0.5043138532855712, 'epoch': 1.6}\n","{'loss': 4.1591, 'learning_rate': 4.4000000000000006e-05, 'epoch': 2.4}\n","{'eval_stsb_spearman': 0.369284739629147, 'eval_sickr_spearman': 0.41118689392924085, 'eval_avg_sts': 0.39023581677919394, 'epoch': 2.4}\n","{'loss': 4.1592, 'learning_rate': 4.2e-05, 'epoch': 3.2}\n","{'eval_stsb_spearman': 0.3697731264263238, 'eval_sickr_spearman': 0.43281561048097245, 'eval_avg_sts': 0.40129436845364813, 'epoch': 3.2}\n","{'loss': 4.1589, 'learning_rate': 4e-05, 'epoch': 4.0}\n","{'eval_stsb_spearman': 0.4818414305248774, 'eval_sickr_spearman': 0.5115986329851645, 'eval_avg_sts': 0.49672003175502094, 'epoch': 4.0}\n","{'eval_stsb_spearman': 0.4818414305248774, 'eval_sickr_spearman': 0.5115986329851645, 'eval_avg_sts': 0.49672003175502094, 'epoch': 4.0}\n","{'loss': 4.1592, 'learning_rate': 3.8e-05, 'epoch': 4.8}\n","{'eval_stsb_spearman': 0.10726398774874038, 'eval_sickr_spearman': 0.2206974708249436, 'eval_avg_sts': 0.163980729286842, 'epoch': 4.8}\n","{'loss': 4.1591, 'learning_rate': 3.6e-05, 'epoch': 5.6}\n","{'eval_stsb_spearman': 0.1444024135234775, 'eval_sickr_spearman': 0.2888518544298833, 'eval_avg_sts': 0.2166271339766804, 'epoch': 5.6}\n","{'loss': 4.1591, 'learning_rate': 3.4000000000000007e-05, 'epoch': 6.4}\n","{'eval_stsb_spearman': 0.08001077089156679, 'eval_sickr_spearman': 0.1572120058795787, 'eval_avg_sts': 0.11861138838557275, 'epoch': 6.4}\n","{'loss': 4.159, 'learning_rate': 3.2000000000000005e-05, 'epoch': 7.2}\n","{'eval_stsb_spearman': 0.03101695457355351, 'eval_sickr_spearman': -0.031397743239914414, 'eval_avg_sts': -0.00019039433318045196, 'epoch': 7.2}\n","{'loss': 4.159, 'learning_rate': 3e-05, 'epoch': 8.0}\n","{'eval_stsb_spearman': 0.045367753173773506, 'eval_sickr_spearman': 0.08171164914299527, 'eval_avg_sts': 0.06353970115838439, 'epoch': 8.0}\n","{'eval_stsb_spearman': 0.045367753173773506, 'eval_sickr_spearman': 0.08171164914299527, 'eval_avg_sts': 0.06353970115838439, 'epoch': 8.0}\n","{'loss': 4.1589, 'learning_rate': 2.8000000000000003e-05, 'epoch': 8.8}\n","{'eval_stsb_spearman': 0.0695586941192058, 'eval_sickr_spearman': 0.16196037671933236, 'eval_avg_sts': 0.11575953541926909, 'epoch': 8.8}\n","{'loss': 4.1591, 'learning_rate': 2.6000000000000002e-05, 'epoch': 9.6}\n","{'eval_stsb_spearman': 0.26685617611090917, 'eval_sickr_spearman': 0.2765959200075755, 'eval_avg_sts': 0.27172604805924233, 'epoch': 9.6}\n","{'loss': 4.1589, 'learning_rate': 2.4e-05, 'epoch': 10.4}\n","{'eval_stsb_spearman': 0.35377358281723925, 'eval_sickr_spearman': 0.2772591372555364, 'eval_avg_sts': 0.31551636003638783, 'epoch': 10.4}\n","{'loss': 4.159, 'learning_rate': 2.2000000000000003e-05, 'epoch': 11.2}\n","{'eval_stsb_spearman': 0.28865692426910305, 'eval_sickr_spearman': 0.2686943361636903, 'eval_avg_sts': 0.2786756302163967, 'epoch': 11.2}\n","{'loss': 4.1589, 'learning_rate': 2e-05, 'epoch': 12.0}\n","{'eval_stsb_spearman': 0.24365283217059225, 'eval_sickr_spearman': 0.21951004244873437, 'eval_avg_sts': 0.2315814373096633, 'epoch': 12.0}\n","{'eval_stsb_spearman': 0.24365283217059225, 'eval_sickr_spearman': 0.21951004244873437, 'eval_avg_sts': 0.2315814373096633, 'epoch': 12.0}\n","{'loss': 4.159, 'learning_rate': 1.8e-05, 'epoch': 12.8}\n","{'eval_stsb_spearman': 0.24534906342915735, 'eval_sickr_spearman': 0.3342766654420909, 'eval_avg_sts': 0.28981286443562415, 'epoch': 12.8}\n","{'loss': 4.1589, 'learning_rate': 1.6000000000000003e-05, 'epoch': 13.6}\n","{'eval_stsb_spearman': 0.3611987462360863, 'eval_sickr_spearman': 0.43233382990878017, 'eval_avg_sts': 0.3967662880724332, 'epoch': 13.6}\n","{'loss': 4.1589, 'learning_rate': 1.4000000000000001e-05, 'epoch': 14.4}\n","{'eval_stsb_spearman': 0.39882907158272174, 'eval_sickr_spearman': 0.43360525502192787, 'eval_avg_sts': 0.41621716330232483, 'epoch': 14.4}\n","{'loss': 4.1589, 'learning_rate': 1.2e-05, 'epoch': 15.2}\n","{'eval_stsb_spearman': 0.40866708570642124, 'eval_sickr_spearman': 0.4697933114488055, 'eval_avg_sts': 0.43923019857761336, 'epoch': 15.2}\n","{'loss': 4.1589, 'learning_rate': 1e-05, 'epoch': 16.0}\n","{'eval_stsb_spearman': 0.45904641751343717, 'eval_sickr_spearman': 0.5451199488617546, 'eval_avg_sts': 0.5020831831875959, 'epoch': 16.0}\n","{'eval_stsb_spearman': 0.45904641751343717, 'eval_sickr_spearman': 0.5451199488617546, 'eval_avg_sts': 0.5020831831875959, 'epoch': 16.0}\n","{'loss': 4.1589, 'learning_rate': 8.000000000000001e-06, 'epoch': 16.8}\n","{'eval_stsb_spearman': 0.2563942736889102, 'eval_sickr_spearman': 0.22454189964388332, 'eval_avg_sts': 0.24046808666639677, 'epoch': 16.8}\n","{'loss': 4.1589, 'learning_rate': 6e-06, 'epoch': 17.6}\n","{'eval_stsb_spearman': 0.4929811211220155, 'eval_sickr_spearman': 0.46047390601024657, 'eval_avg_sts': 0.476727513566131, 'epoch': 17.6}\n","{'loss': 4.1589, 'learning_rate': 4.000000000000001e-06, 'epoch': 18.4}\n","{'eval_stsb_spearman': 0.3698814303095041, 'eval_sickr_spearman': 0.3616501679976289, 'eval_avg_sts': 0.3657657991535665, 'epoch': 18.4}\n","{'loss': 4.1579, 'learning_rate': 2.0000000000000003e-06, 'epoch': 19.2}\n","{'eval_stsb_spearman': 0.24537253232863962, 'eval_sickr_spearman': 0.18927485744986744, 'eval_avg_sts': 0.21732369488925352, 'epoch': 19.2}\n","{'loss': 4.1557, 'learning_rate': 0.0, 'epoch': 20.0}\n","{'eval_stsb_spearman': 0.252121832931486, 'eval_sickr_spearman': 0.21484013555351572, 'eval_avg_sts': 0.23348098424250086, 'epoch': 20.0}\n","{'eval_stsb_spearman': 0.252121832931486, 'eval_sickr_spearman': 0.21484013555351572, 'eval_avg_sts': 0.23348098424250086, 'epoch': 20.0}\n","100% 12500/12500 [1:20:34<00:00,  3.29it/s]11/18/2021 12:56:46 - INFO - simcse.trainers -   \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","11/18/2021 12:56:46 - INFO - simcse.trainers -   Loading best model from ../twiBot-20epochs-sup-simcse-bert-base-uncased (score: 0.5518227408955312).\n","[INFO|configuration_utils.py:443] 2021-11-18 12:56:46,607 >> loading configuration file ../twiBot-20epochs-sup-simcse-bert-base-uncased/config.json\n","[INFO|configuration_utils.py:481] 2021-11-18 12:56:46,608 >> Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForCL\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|modeling_utils.py:1025] 2021-11-18 12:56:46,608 >> loading weights file ../twiBot-20epochs-sup-simcse-bert-base-uncased/pytorch_model.bin\n","[INFO|modeling_utils.py:1143] 2021-11-18 12:56:49,773 >> All model checkpoint weights were used when initializing BertForCL.\n","\n","[INFO|modeling_utils.py:1152] 2021-11-18 12:56:49,773 >> All the weights of BertForCL were initialized from the model checkpoint at ../twiBot-20epochs-sup-simcse-bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForCL for predictions without further training.\n","{'train_runtime': 4838.2803, 'train_samples_per_second': 2.584, 'epoch': 20.0}\n","100% 12500/12500 [1:20:38<00:00,  2.58it/s]\n","[INFO|trainer.py:1344] 2021-11-18 12:56:49,900 >> Saving model checkpoint to ../twiBot-20epochs-sup-simcse-bert-base-uncased\n","[INFO|configuration_utils.py:300] 2021-11-18 12:56:49,906 >> Configuration saved in ../twiBot-20epochs-sup-simcse-bert-base-uncased/config.json\n","[INFO|modeling_utils.py:817] 2021-11-18 12:56:51,968 >> Model weights saved in ../twiBot-20epochs-sup-simcse-bert-base-uncased/pytorch_model.bin\n","11/18/2021 12:56:52 - INFO - __main__ -   ***** Train results *****\n","11/18/2021 12:56:52 - INFO - __main__ -     epoch = 20.0\n","11/18/2021 12:56:52 - INFO - __main__ -     train_runtime = 4838.2803\n","11/18/2021 12:56:52 - INFO - __main__ -     train_samples_per_second = 2.584\n","11/18/2021 12:56:56 - INFO - __main__ -   *** Evaluate ***\n","11/18/2021 12:57:31 - INFO - root -   Generating sentence embeddings\n","11/18/2021 12:57:45 - INFO - root -   Generated sentence embeddings\n","11/18/2021 12:57:45 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/18/2021 12:57:56 - INFO - root -   Best param found at split 1: l2reg = 1e-05                 with score 49.99\n","11/18/2021 12:58:08 - INFO - root -   Best param found at split 2: l2reg = 1e-05                 with score 50.01\n","11/18/2021 12:58:21 - INFO - root -   Best param found at split 3: l2reg = 1e-05                 with score 50.0\n","11/18/2021 12:58:33 - INFO - root -   Best param found at split 4: l2reg = 1e-05                 with score 50.0\n","11/18/2021 12:58:45 - INFO - root -   Best param found at split 5: l2reg = 1e-05                 with score 50.0\n","11/18/2021 12:58:45 - INFO - root -   Generating sentence embeddings\n","11/18/2021 12:58:49 - INFO - root -   Generated sentence embeddings\n","11/18/2021 12:58:49 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/18/2021 12:58:54 - INFO - root -   Best param found at split 1: l2reg = 1e-05                 with score 63.77\n","11/18/2021 12:58:58 - INFO - root -   Best param found at split 2: l2reg = 1e-05                 with score 63.77\n","11/18/2021 12:59:03 - INFO - root -   Best param found at split 3: l2reg = 1e-05                 with score 63.77\n","11/18/2021 12:59:07 - INFO - root -   Best param found at split 4: l2reg = 1e-05                 with score 63.74\n","11/18/2021 12:59:12 - INFO - root -   Best param found at split 5: l2reg = 1e-05                 with score 63.84\n","11/18/2021 12:59:12 - INFO - root -   Generating sentence embeddings\n","11/18/2021 12:59:26 - INFO - root -   Generated sentence embeddings\n","11/18/2021 12:59:26 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/18/2021 12:59:37 - INFO - root -   Best param found at split 1: l2reg = 1e-05                 with score 50.0\n","11/18/2021 12:59:48 - INFO - root -   Best param found at split 2: l2reg = 1e-05                 with score 50.0\n","11/18/2021 12:59:59 - INFO - root -   Best param found at split 3: l2reg = 1e-05                 with score 50.0\n","11/18/2021 13:00:10 - INFO - root -   Best param found at split 4: l2reg = 1e-05                 with score 50.0\n","11/18/2021 13:00:22 - INFO - root -   Best param found at split 5: l2reg = 1e-05                 with score 50.0\n","11/18/2021 13:00:22 - INFO - root -   Generating sentence embeddings\n","11/18/2021 13:00:26 - INFO - root -   Generated sentence embeddings\n","11/18/2021 13:00:26 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/18/2021 13:00:38 - INFO - root -   Best param found at split 1: l2reg = 1e-05                 with score 68.78\n","11/18/2021 13:00:50 - INFO - root -   Best param found at split 2: l2reg = 1e-05                 with score 68.77\n","11/18/2021 13:01:03 - INFO - root -   Best param found at split 3: l2reg = 1e-05                 with score 68.77\n","11/18/2021 13:01:17 - INFO - root -   Best param found at split 4: l2reg = 1e-05                 with score 68.77\n","11/18/2021 13:01:29 - INFO - root -   Best param found at split 5: l2reg = 1e-05                 with score 68.78\n","11/18/2021 13:01:31 - INFO - root -   Computing embedding for train\n","11/18/2021 13:02:17 - INFO - root -   Computed train embeddings\n","11/18/2021 13:02:17 - INFO - root -   Computing embedding for dev\n","11/18/2021 13:02:18 - INFO - root -   Computed dev embeddings\n","11/18/2021 13:02:18 - INFO - root -   Computing embedding for test\n","11/18/2021 13:02:20 - INFO - root -   Computed test embeddings\n","11/18/2021 13:02:20 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..\n","11/18/2021 13:02:45 - INFO - root -   [('reg:1e-05', 50.92), ('reg:0.0001', 50.92), ('reg:0.001', 50.92), ('reg:0.01', 50.92)]\n","11/18/2021 13:02:45 - INFO - root -   Validation : best param found is reg = 1e-05 with score             50.92\n","11/18/2021 13:02:45 - INFO - root -   Evaluating...\n","11/18/2021 13:02:52 - INFO - root -   ***** Transfer task : TREC *****\n","\n","\n","11/18/2021 13:02:56 - INFO - root -   Computed train embeddings\n","11/18/2021 13:02:56 - INFO - root -   Computed test embeddings\n","11/18/2021 13:02:56 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation\n","11/18/2021 13:03:04 - INFO - root -   [('reg:1e-05', 22.73), ('reg:0.0001', 22.63), ('reg:0.001', 22.74), ('reg:0.01', 22.74)]\n","11/18/2021 13:03:04 - INFO - root -   Cross-validation : best param found is reg = 0.001             with score 22.74\n","11/18/2021 13:03:04 - INFO - root -   Evaluating...\n","11/18/2021 13:03:05 - INFO - root -   ***** Transfer task : MRPC *****\n","\n","\n","11/18/2021 13:03:05 - INFO - root -   Computing embedding for train\n","11/18/2021 13:03:15 - INFO - root -   Computed train embeddings\n","11/18/2021 13:03:15 - INFO - root -   Computing embedding for test\n","11/18/2021 13:03:19 - INFO - root -   Computed test embeddings\n","11/18/2021 13:03:19 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation\n","11/18/2021 13:03:25 - INFO - root -   [('reg:1e-05', 67.59), ('reg:0.0001', 67.54), ('reg:0.001', 67.59), ('reg:0.01', 67.54)]\n","11/18/2021 13:03:25 - INFO - root -   Cross-validation : best param found is reg = 1e-05             with score 67.59\n","11/18/2021 13:03:25 - INFO - root -   Evaluating...\n","11/18/2021 13:03:26 - INFO - __main__ -   ***** Eval results *****\n","11/18/2021 13:03:26 - INFO - __main__ -     epoch = 20.0\n","11/18/2021 13:03:26 - INFO - __main__ -     eval_CR = 63.78\n","11/18/2021 13:03:26 - INFO - __main__ -     eval_MPQA = 68.77\n","11/18/2021 13:03:26 - INFO - __main__ -     eval_MR = 50.0\n","11/18/2021 13:03:26 - INFO - __main__ -     eval_MRPC = 67.59\n","11/18/2021 13:03:26 - INFO - __main__ -     eval_SST2 = 50.92\n","11/18/2021 13:03:26 - INFO - __main__ -     eval_SUBJ = 50.0\n","11/18/2021 13:03:26 - INFO - __main__ -     eval_TREC = 22.74\n","11/18/2021 13:03:26 - INFO - __main__ -     eval_avg_sts = 0.5458043889306392\n","11/18/2021 13:03:26 - INFO - __main__ -     eval_avg_transfer = 53.40000000000001\n","11/18/2021 13:03:26 - INFO - __main__ -     eval_sickr_spearman = 0.5397860369657473\n","11/18/2021 13:03:26 - INFO - __main__ -     eval_stsb_spearman = 0.5518227408955312\n"]}]},{"cell_type":"code","metadata":{"id":"XIvvangrzltO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cvC2S6Whyvb8"},"source":["## Training with TwiBot dataset built on *similarity* - GPU"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UhFydujM0Z7j","executionInfo":{"status":"ok","timestamp":1637637793766,"user_tz":480,"elapsed":202,"user":{"displayName":"zeeshan ahmad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15348670853435150367"}},"outputId":"177ae17b-f339-4c20-bae9-b46ec659a58f"},"source":["!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1ygEmNCP-_htwwx_sBJE2NdJ3Nb7aJhr3/CSCI_544_NLP_Project/Twitter_Bot_Detection/Data\n"]}]},{"cell_type":"code","metadata":{"id":"I3zNiLSnzoHv"},"source":["# Don't run again!\n","\n","# Extract only the tweet data from the dataset and copy to train_triplets_with_similarity_only_tweets.csv\n","df = pd.read_csv(\"/content/drive/MyDrive/CSCI_544_NLP_Project/Twitter_Bot_Detection/Data/train_triplets_with_similarity.csv\")\n","df_only_tweets = df[['sent0', 'sent1', 'hard_neg']]\n","df_only_tweets.to_csv(\"train_triplets_with_similarity_only_tweets.csv\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TGUv6dbDys7V","executionInfo":{"status":"ok","timestamp":1637640778948,"user_tz":480,"elapsed":2914520,"user":{"displayName":"zeeshan ahmad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15348670853435150367"}},"outputId":"4580784c-b471-4743-c513-b27bc27b5cec"},"source":["!cd SimCSE-main && python train.py --model_name_or_path bert-base-uncased \\\n","    --train_file ../train_triplets_with_similarity_only_tweets.csv \\\n","    --output_dir ../twiBot-similarity-sup-simcse-bert-base-uncased \\\n","    --num_train_epochs 1 \\\n","    --per_device_train_batch_size 32 \\\n","    --learning_rate 5e-5 \\\n","    --max_seq_length 32 \\\n","    --evaluation_strategy steps \\\n","    --metric_for_best_model stsb_spearman \\\n","    --load_best_model_at_end \\\n","    --overwrite_output_dir \\\n","    --temp 0.05 \\\n","    --do_train \\"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["11/23/2021 03:24:35 - INFO - __main__ -   PyTorch: setting up devices\n","11/23/2021 03:24:35 - INFO - __main__ -   Set device to CUDA\n","11/23/2021 03:24:35 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1 distributed training: False, 16-bits training: False\n","11/23/2021 03:24:35 - INFO - __main__ -   Training/evaluation parameters OurTrainingArguments(output_dir='../twiBot-similarity-sup-simcse-bert-base-uncased', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_steps=0, logging_dir='runs/Nov23_03-24-35_84244e99f0ca', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', fp16_backend='auto', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='../twiBot-similarity-sup-simcse-bert-base-uncased', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model='stsb_spearman', greater_is_better=True, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, eval_transfer=False)\n","Downloading: 5.33kB [00:00, 5.03MB/s]       \n","Using custom data configuration default\n","Downloading and preparing dataset csv/default-b99d57eeab534056 (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to ./data/csv/default-b99d57eeab534056/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2...\n","Dataset csv downloaded and prepared to ./data/csv/default-b99d57eeab534056/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2. Subsequent calls will reuse this data.\n","[INFO|file_utils.py:1272] 2021-11-23 03:24:38,101 >> https://huggingface.co/bert-base-uncased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpaocjmln3\n","Downloading: 100% 570/570 [00:00<00:00, 438kB/s]\n","[INFO|file_utils.py:1276] 2021-11-23 03:24:38,376 >> storing https://huggingface.co/bert-base-uncased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|file_utils.py:1279] 2021-11-23 03:24:38,377 >> creating metadata file for /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|configuration_utils.py:445] 2021-11-23 03:24:38,377 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|configuration_utils.py:481] 2021-11-23 03:24:38,378 >> Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|configuration_utils.py:445] 2021-11-23 03:24:38,650 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|configuration_utils.py:481] 2021-11-23 03:24:38,651 >> Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|file_utils.py:1272] 2021-11-23 03:24:38,922 >> https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpzjyniv31\n","Downloading: 100% 232k/232k [00:00<00:00, 924kB/s]\n","[INFO|file_utils.py:1276] 2021-11-23 03:24:39,445 >> storing https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","[INFO|file_utils.py:1279] 2021-11-23 03:24:39,445 >> creating metadata file for /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","[INFO|file_utils.py:1272] 2021-11-23 03:24:39,721 >> https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp0zp0ufqo\n","Downloading: 100% 466k/466k [00:00<00:00, 1.49MB/s]\n","[INFO|file_utils.py:1276] 2021-11-23 03:24:40,315 >> storing https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","[INFO|file_utils.py:1279] 2021-11-23 03:24:40,316 >> creating metadata file for /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","[INFO|tokenization_utils_base.py:1766] 2021-11-23 03:24:40,316 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","[INFO|tokenization_utils_base.py:1766] 2021-11-23 03:24:40,316 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","[INFO|file_utils.py:1272] 2021-11-23 03:24:40,609 >> https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp2yb6r3gu\n","Downloading: 100% 440M/440M [00:10<00:00, 42.3MB/s]\n","[INFO|file_utils.py:1276] 2021-11-23 03:24:51,079 >> storing https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","[INFO|file_utils.py:1279] 2021-11-23 03:24:51,079 >> creating metadata file for /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","[INFO|modeling_utils.py:1027] 2021-11-23 03:24:51,079 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","[WARNING|modeling_utils.py:1135] 2021-11-23 03:24:54,799 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForCL: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n","- This IS expected if you are initializing BertForCL from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForCL from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[WARNING|modeling_utils.py:1146] 2021-11-23 03:24:54,800 >> Some weights of BertForCL were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['mlp.dense.weight', 'mlp.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 200/200 [01:14<00:00,  2.70ba/s]\n","/usr/local/lib/python3.7/dist-packages/_distutils_hack/__init__.py:19: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n","  \"Distutils was imported before Setuptools. This usage is discouraged \"\n","[INFO|trainer.py:442] 2021-11-23 03:26:14,697 >> The following columns in the training set don't have a corresponding argument in `BertForCL.forward` and have been ignored: .\n","11/23/2021 03:26:14 - INFO - simcse.trainers -   ***** Running training *****\n","11/23/2021 03:26:14 - INFO - simcse.trainers -     Num examples = 200000\n","11/23/2021 03:26:14 - INFO - simcse.trainers -     Num Epochs = 1\n","11/23/2021 03:26:14 - INFO - simcse.trainers -     Instantaneous batch size per device = 32\n","11/23/2021 03:26:14 - INFO - simcse.trainers -     Total train batch size (w. parallel, distributed & accumulation) = 32\n","11/23/2021 03:26:14 - INFO - simcse.trainers -     Gradient Accumulation steps = 1\n","11/23/2021 03:26:14 - INFO - simcse.trainers -     Total optimization steps = 6250\n","{'loss': 1.148, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.08}\n","{'eval_stsb_spearman': 0.8045812314066786, 'eval_sickr_spearman': 0.739929156154326, 'eval_avg_sts': 0.7722551937805022, 'epoch': 0.08}\n","  8% 500/6250 [03:11<29:09,  3.29it/s][INFO|trainer.py:1344] 2021-11-23 03:29:26,436 >> Saving model checkpoint to ../twiBot-similarity-sup-simcse-bert-base-uncased\n","[INFO|configuration_utils.py:300] 2021-11-23 03:29:26,442 >> Configuration saved in ../twiBot-similarity-sup-simcse-bert-base-uncased/config.json\n","[INFO|modeling_utils.py:817] 2021-11-23 03:29:27,934 >> Model weights saved in ../twiBot-similarity-sup-simcse-bert-base-uncased/pytorch_model.bin\n","{'loss': 0.9994, 'learning_rate': 4.2e-05, 'epoch': 0.16}\n","{'eval_stsb_spearman': 0.8010589417869883, 'eval_sickr_spearman': 0.7217435724967264, 'eval_avg_sts': 0.7614012571418574, 'epoch': 0.16}\n","{'loss': 0.9268, 'learning_rate': 3.8e-05, 'epoch': 0.24}\n","{'eval_stsb_spearman': 0.8077151090142409, 'eval_sickr_spearman': 0.7301257681953002, 'eval_avg_sts': 0.7689204386047706, 'epoch': 0.24}\n"," 24% 1500/6250 [09:31<24:06,  3.28it/s][INFO|trainer.py:1344] 2021-11-23 03:35:45,811 >> Saving model checkpoint to ../twiBot-similarity-sup-simcse-bert-base-uncased\n","[INFO|configuration_utils.py:300] 2021-11-23 03:35:45,817 >> Configuration saved in ../twiBot-similarity-sup-simcse-bert-base-uncased/config.json\n","[INFO|modeling_utils.py:817] 2021-11-23 03:35:47,361 >> Model weights saved in ../twiBot-similarity-sup-simcse-bert-base-uncased/pytorch_model.bin\n","{'loss': 0.8937, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.32}\n","{'eval_stsb_spearman': 0.8015148211047491, 'eval_sickr_spearman': 0.722374028734203, 'eval_avg_sts': 0.761944424919476, 'epoch': 0.32}\n","{'loss': 0.8188, 'learning_rate': 3e-05, 'epoch': 0.4}\n","{'eval_stsb_spearman': 0.8092450470731586, 'eval_sickr_spearman': 0.7362563138895564, 'eval_avg_sts': 0.7727506804813575, 'epoch': 0.4}\n"," 40% 2500/6250 [15:51<19:00,  3.29it/s][INFO|trainer.py:1344] 2021-11-23 03:42:05,766 >> Saving model checkpoint to ../twiBot-similarity-sup-simcse-bert-base-uncased\n","[INFO|configuration_utils.py:300] 2021-11-23 03:42:05,773 >> Configuration saved in ../twiBot-similarity-sup-simcse-bert-base-uncased/config.json\n","[INFO|modeling_utils.py:817] 2021-11-23 03:42:07,326 >> Model weights saved in ../twiBot-similarity-sup-simcse-bert-base-uncased/pytorch_model.bin\n","{'loss': 0.7547, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.48}\n","{'eval_stsb_spearman': 0.8040796787443909, 'eval_sickr_spearman': 0.7400203672159571, 'eval_avg_sts': 0.772050022980174, 'epoch': 0.48}\n","{'loss': 0.707, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.56}\n","{'eval_stsb_spearman': 0.8056032047054703, 'eval_sickr_spearman': 0.7376486394580445, 'eval_avg_sts': 0.7716259220817574, 'epoch': 0.56}\n","{'loss': 0.6833, 'learning_rate': 1.8e-05, 'epoch': 0.64}\n","{'eval_stsb_spearman': 0.8051488883820547, 'eval_sickr_spearman': 0.7286319048783719, 'eval_avg_sts': 0.7668903966302133, 'epoch': 0.64}\n","{'loss': 0.6327, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.72}\n","{'eval_stsb_spearman': 0.8100345369411357, 'eval_sickr_spearman': 0.7374324034393701, 'eval_avg_sts': 0.773733470190253, 'epoch': 0.72}\n"," 72% 4500/6250 [28:24<08:52,  3.28it/s][INFO|trainer.py:1344] 2021-11-23 03:54:39,018 >> Saving model checkpoint to ../twiBot-similarity-sup-simcse-bert-base-uncased\n","[INFO|configuration_utils.py:300] 2021-11-23 03:54:39,024 >> Configuration saved in ../twiBot-similarity-sup-simcse-bert-base-uncased/config.json\n","[INFO|modeling_utils.py:817] 2021-11-23 03:54:40,586 >> Model weights saved in ../twiBot-similarity-sup-simcse-bert-base-uncased/pytorch_model.bin\n","{'loss': 0.5996, 'learning_rate': 1e-05, 'epoch': 0.8}\n","{'eval_stsb_spearman': 0.8025398253699232, 'eval_sickr_spearman': 0.7246010387834826, 'eval_avg_sts': 0.7635704320767029, 'epoch': 0.8}\n","{'loss': 0.5803, 'learning_rate': 6e-06, 'epoch': 0.88}\n","{'eval_stsb_spearman': 0.8071939655883341, 'eval_sickr_spearman': 0.7381661265449387, 'eval_avg_sts': 0.7726800460666364, 'epoch': 0.88}\n","{'loss': 0.5469, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.96}\n","{'eval_stsb_spearman': 0.8058787750067535, 'eval_sickr_spearman': 0.7358875310927147, 'eval_avg_sts': 0.7708831530497341, 'epoch': 0.96}\n","100% 6250/6250 [39:05<00:00,  3.29it/s]11/23/2021 04:05:20 - INFO - simcse.trainers -   \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","11/23/2021 04:05:20 - INFO - simcse.trainers -   Loading best model from ../twiBot-similarity-sup-simcse-bert-base-uncased (score: 0.8100345369411357).\n","[INFO|configuration_utils.py:443] 2021-11-23 04:05:20,508 >> loading configuration file ../twiBot-similarity-sup-simcse-bert-base-uncased/config.json\n","[INFO|configuration_utils.py:481] 2021-11-23 04:05:20,509 >> Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForCL\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|modeling_utils.py:1025] 2021-11-23 04:05:20,509 >> loading weights file ../twiBot-similarity-sup-simcse-bert-base-uncased/pytorch_model.bin\n","[INFO|modeling_utils.py:1143] 2021-11-23 04:05:23,796 >> All model checkpoint weights were used when initializing BertForCL.\n","\n","[INFO|modeling_utils.py:1152] 2021-11-23 04:05:23,796 >> All the weights of BertForCL were initialized from the model checkpoint at ../twiBot-similarity-sup-simcse-bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForCL for predictions without further training.\n","{'train_runtime': 2349.2102, 'train_samples_per_second': 2.66, 'epoch': 1.0}\n","100% 6250/6250 [39:09<00:00,  2.66it/s]\n","[INFO|trainer.py:1344] 2021-11-23 04:05:23,917 >> Saving model checkpoint to ../twiBot-similarity-sup-simcse-bert-base-uncased\n","[INFO|configuration_utils.py:300] 2021-11-23 04:05:23,923 >> Configuration saved in ../twiBot-similarity-sup-simcse-bert-base-uncased/config.json\n","[INFO|modeling_utils.py:817] 2021-11-23 04:05:25,560 >> Model weights saved in ../twiBot-similarity-sup-simcse-bert-base-uncased/pytorch_model.bin\n","11/23/2021 04:05:25 - INFO - __main__ -   ***** Train results *****\n","11/23/2021 04:05:25 - INFO - __main__ -     epoch = 1.0\n","11/23/2021 04:05:25 - INFO - __main__ -     train_runtime = 2349.2102\n","11/23/2021 04:05:25 - INFO - __main__ -     train_samples_per_second = 2.66\n","11/23/2021 04:05:25 - INFO - __main__ -   *** Evaluate ***\n","11/23/2021 04:06:01 - INFO - root -   Generating sentence embeddings\n","11/23/2021 04:06:16 - INFO - root -   Generated sentence embeddings\n","11/23/2021 04:06:16 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/23/2021 04:06:31 - INFO - root -   Best param found at split 1: l2reg = 1e-05                 with score 81.1\n","11/23/2021 04:06:45 - INFO - root -   Best param found at split 2: l2reg = 0.001                 with score 80.7\n","11/23/2021 04:07:00 - INFO - root -   Best param found at split 3: l2reg = 1e-05                 with score 80.75\n","11/23/2021 04:07:15 - INFO - root -   Best param found at split 4: l2reg = 0.001                 with score 80.33\n","11/23/2021 04:07:30 - INFO - root -   Best param found at split 5: l2reg = 0.001                 with score 80.98\n","11/23/2021 04:07:32 - INFO - root -   Generating sentence embeddings\n","11/23/2021 04:07:36 - INFO - root -   Generated sentence embeddings\n","11/23/2021 04:07:36 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/23/2021 04:07:40 - INFO - root -   Best param found at split 1: l2reg = 1e-05                 with score 87.95\n","11/23/2021 04:07:46 - INFO - root -   Best param found at split 2: l2reg = 1e-05                 with score 88.15\n","11/23/2021 04:07:51 - INFO - root -   Best param found at split 3: l2reg = 0.01                 with score 88.01\n","11/23/2021 04:07:57 - INFO - root -   Best param found at split 4: l2reg = 0.001                 with score 87.35\n","11/23/2021 04:08:02 - INFO - root -   Best param found at split 5: l2reg = 0.01                 with score 87.62\n","11/23/2021 04:08:04 - INFO - root -   Generating sentence embeddings\n","11/23/2021 04:08:18 - INFO - root -   Generated sentence embeddings\n","11/23/2021 04:08:18 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/23/2021 04:08:32 - INFO - root -   Best param found at split 1: l2reg = 0.0001                 with score 94.58\n","11/23/2021 04:08:48 - INFO - root -   Best param found at split 2: l2reg = 0.0001                 with score 94.91\n","11/23/2021 04:09:05 - INFO - root -   Best param found at split 3: l2reg = 1e-05                 with score 94.84\n","11/23/2021 04:09:20 - INFO - root -   Best param found at split 4: l2reg = 1e-05                 with score 94.79\n","11/23/2021 04:09:37 - INFO - root -   Best param found at split 5: l2reg = 0.0001                 with score 94.89\n","11/23/2021 04:09:39 - INFO - root -   Generating sentence embeddings\n","11/23/2021 04:09:42 - INFO - root -   Generated sentence embeddings\n","11/23/2021 04:09:42 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/23/2021 04:09:57 - INFO - root -   Best param found at split 1: l2reg = 0.0001                 with score 89.26\n","11/23/2021 04:10:12 - INFO - root -   Best param found at split 2: l2reg = 1e-05                 with score 88.5\n","11/23/2021 04:10:28 - INFO - root -   Best param found at split 3: l2reg = 1e-05                 with score 88.59\n","11/23/2021 04:10:43 - INFO - root -   Best param found at split 4: l2reg = 1e-05                 with score 88.34\n","11/23/2021 04:10:58 - INFO - root -   Best param found at split 5: l2reg = 0.001                 with score 88.59\n","11/23/2021 04:11:00 - INFO - root -   Computing embedding for train\n","11/23/2021 04:11:47 - INFO - root -   Computed train embeddings\n","11/23/2021 04:11:47 - INFO - root -   Computing embedding for dev\n","11/23/2021 04:11:48 - INFO - root -   Computed dev embeddings\n","11/23/2021 04:11:48 - INFO - root -   Computing embedding for test\n","11/23/2021 04:11:51 - INFO - root -   Computed test embeddings\n","11/23/2021 04:11:51 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..\n","11/23/2021 04:12:12 - INFO - root -   [('reg:1e-05', 85.44), ('reg:0.0001', 85.55), ('reg:0.001', 84.98), ('reg:0.01', 84.75)]\n","11/23/2021 04:12:12 - INFO - root -   Validation : best param found is reg = 0.0001 with score             85.55\n","11/23/2021 04:12:12 - INFO - root -   Evaluating...\n","11/23/2021 04:12:17 - INFO - root -   ***** Transfer task : TREC *****\n","\n","\n","11/23/2021 04:12:21 - INFO - root -   Computed train embeddings\n","11/23/2021 04:12:21 - INFO - root -   Computed test embeddings\n","11/23/2021 04:12:21 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation\n","11/23/2021 04:12:31 - INFO - root -   [('reg:1e-05', 78.83), ('reg:0.0001', 78.6), ('reg:0.001', 76.71), ('reg:0.01', 69.85)]\n","11/23/2021 04:12:31 - INFO - root -   Cross-validation : best param found is reg = 1e-05             with score 78.83\n","11/23/2021 04:12:31 - INFO - root -   Evaluating...\n","11/23/2021 04:12:32 - INFO - root -   ***** Transfer task : MRPC *****\n","\n","\n","11/23/2021 04:12:33 - INFO - root -   Computing embedding for train\n","11/23/2021 04:12:43 - INFO - root -   Computed train embeddings\n","11/23/2021 04:12:43 - INFO - root -   Computing embedding for test\n","11/23/2021 04:12:48 - INFO - root -   Computed test embeddings\n","11/23/2021 04:12:48 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation\n","11/23/2021 04:12:55 - INFO - root -   [('reg:1e-05', 73.92), ('reg:0.0001', 73.9), ('reg:0.001', 73.87), ('reg:0.01', 74.24)]\n","11/23/2021 04:12:55 - INFO - root -   Cross-validation : best param found is reg = 0.01             with score 74.24\n","11/23/2021 04:12:55 - INFO - root -   Evaluating...\n","11/23/2021 04:12:56 - INFO - __main__ -   ***** Eval results *****\n","11/23/2021 04:12:56 - INFO - __main__ -     epoch = 1.0\n","11/23/2021 04:12:56 - INFO - __main__ -     eval_CR = 87.82\n","11/23/2021 04:12:56 - INFO - __main__ -     eval_MPQA = 88.66\n","11/23/2021 04:12:56 - INFO - __main__ -     eval_MR = 80.77\n","11/23/2021 04:12:56 - INFO - __main__ -     eval_MRPC = 74.24\n","11/23/2021 04:12:56 - INFO - __main__ -     eval_SST2 = 85.55\n","11/23/2021 04:12:56 - INFO - __main__ -     eval_SUBJ = 94.8\n","11/23/2021 04:12:56 - INFO - __main__ -     eval_TREC = 78.83\n","11/23/2021 04:12:56 - INFO - __main__ -     eval_avg_sts = 0.773733470190253\n","11/23/2021 04:12:56 - INFO - __main__ -     eval_avg_transfer = 84.38142857142857\n","11/23/2021 04:12:56 - INFO - __main__ -     eval_sickr_spearman = 0.7374324034393701\n","11/23/2021 04:12:56 - INFO - __main__ -     eval_stsb_spearman = 0.8100345369411357\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mJ7tfgZb_5LT","executionInfo":{"status":"ok","timestamp":1637664828070,"user_tz":480,"elapsed":8579756,"user":{"displayName":"zeeshan ahmad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15348670853435150367"}},"outputId":"e160f66d-f361-425d-ecb1-c29f97f0a5a2"},"source":["!cd SimCSE-main && python train.py --model_name_or_path bert-base-uncased \\\n","    --train_file ../train_triplets_with_similarity_only_tweets.csv \\\n","    --output_dir ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased \\\n","    --num_train_epochs 10 \\\n","    --per_device_train_batch_size 32 \\\n","    --learning_rate 5e-5 \\\n","    --max_seq_length 32 \\\n","    --evaluation_strategy steps \\\n","    --metric_for_best_model stsb_spearman \\\n","    --load_best_model_at_end \\\n","    --overwrite_output_dir \\\n","    --temp 0.05 \\\n","    --do_train \\"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["11/23/2021 04:13:50 - INFO - __main__ -   PyTorch: setting up devices\n","11/23/2021 04:13:50 - INFO - __main__ -   Set device to CUDA\n","11/23/2021 04:13:50 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1 distributed training: False, 16-bits training: False\n","11/23/2021 04:13:50 - INFO - __main__ -   Training/evaluation parameters OurTrainingArguments(output_dir='../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=10.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_steps=0, logging_dir='runs/Nov23_04-13-50_84244e99f0ca', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', fp16_backend='auto', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model='stsb_spearman', greater_is_better=True, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, eval_transfer=False)\n","Using custom data configuration default\n","Reusing dataset csv (./data/csv/default-b99d57eeab534056/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2)\n","[INFO|configuration_utils.py:445] 2021-11-23 04:13:51,077 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|configuration_utils.py:481] 2021-11-23 04:13:51,078 >> Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|configuration_utils.py:445] 2021-11-23 04:13:51,348 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|configuration_utils.py:481] 2021-11-23 04:13:51,349 >> Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|tokenization_utils_base.py:1766] 2021-11-23 04:13:51,893 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","[INFO|tokenization_utils_base.py:1766] 2021-11-23 04:13:51,893 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","[INFO|modeling_utils.py:1027] 2021-11-23 04:13:52,188 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","[WARNING|modeling_utils.py:1135] 2021-11-23 04:13:55,783 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForCL: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n","- This IS expected if you are initializing BertForCL from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForCL from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[WARNING|modeling_utils.py:1146] 2021-11-23 04:13:55,783 >> Some weights of BertForCL were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['mlp.dense.weight', 'mlp.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Loading cached processed dataset at ./data/csv/default-b99d57eeab534056/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2/cache-4f26577a319b5db8.arrow\n","/usr/local/lib/python3.7/dist-packages/_distutils_hack/__init__.py:19: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n","  \"Distutils was imported before Setuptools. This usage is discouraged \"\n","[INFO|trainer.py:442] 2021-11-23 04:13:59,706 >> The following columns in the training set don't have a corresponding argument in `BertForCL.forward` and have been ignored: .\n","11/23/2021 04:13:59 - INFO - simcse.trainers -   ***** Running training *****\n","11/23/2021 04:13:59 - INFO - simcse.trainers -     Num examples = 200000\n","11/23/2021 04:13:59 - INFO - simcse.trainers -     Num Epochs = 10\n","11/23/2021 04:13:59 - INFO - simcse.trainers -     Instantaneous batch size per device = 32\n","11/23/2021 04:13:59 - INFO - simcse.trainers -     Total train batch size (w. parallel, distributed & accumulation) = 32\n","11/23/2021 04:13:59 - INFO - simcse.trainers -     Gradient Accumulation steps = 1\n","11/23/2021 04:13:59 - INFO - simcse.trainers -     Total optimization steps = 62500\n","{'loss': 1.1414, 'learning_rate': 4.96e-05, 'epoch': 0.08}\n","{'eval_stsb_spearman': 0.8030418379955724, 'eval_sickr_spearman': 0.7389823190516766, 'eval_avg_sts': 0.7710120785236245, 'epoch': 0.08}\n","  1% 500/62500 [03:07<5:15:01,  3.28it/s][INFO|trainer.py:1344] 2021-11-23 04:17:07,410 >> Saving model checkpoint to ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased\n","[INFO|configuration_utils.py:300] 2021-11-23 04:17:07,417 >> Configuration saved in ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased/config.json\n","[INFO|modeling_utils.py:817] 2021-11-23 04:17:09,283 >> Model weights saved in ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased/pytorch_model.bin\n","{'loss': 1.0122, 'learning_rate': 4.92e-05, 'epoch': 0.16}\n","{'eval_stsb_spearman': 0.8013920167496471, 'eval_sickr_spearman': 0.7298667844963457, 'eval_avg_sts': 0.7656294006229964, 'epoch': 0.16}\n","{'loss': 0.946, 'learning_rate': 4.88e-05, 'epoch': 0.24}\n","{'eval_stsb_spearman': 0.8033828722143146, 'eval_sickr_spearman': 0.7343156652670509, 'eval_avg_sts': 0.7688492687406827, 'epoch': 0.24}\n","  2% 1500/62500 [09:27<5:09:27,  3.29it/s][INFO|trainer.py:1344] 2021-11-23 04:23:26,839 >> Saving model checkpoint to ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased\n","[INFO|configuration_utils.py:300] 2021-11-23 04:23:26,846 >> Configuration saved in ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased/config.json\n","[INFO|modeling_utils.py:817] 2021-11-23 04:23:28,376 >> Model weights saved in ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased/pytorch_model.bin\n","{'loss': 0.9254, 'learning_rate': 4.8400000000000004e-05, 'epoch': 0.32}\n","{'eval_stsb_spearman': 0.7987724373623808, 'eval_sickr_spearman': 0.7263666554896665, 'eval_avg_sts': 0.7625695464260236, 'epoch': 0.32}\n","{'loss': 0.8537, 'learning_rate': 4.8e-05, 'epoch': 0.4}\n","{'eval_stsb_spearman': 0.802434357325702, 'eval_sickr_spearman': 0.738328087418988, 'eval_avg_sts': 0.770381222372345, 'epoch': 0.4}\n","{'loss': 0.8068, 'learning_rate': 4.76e-05, 'epoch': 0.48}\n","{'eval_stsb_spearman': 0.7954914343910221, 'eval_sickr_spearman': 0.7515319332665281, 'eval_avg_sts': 0.7735116838287751, 'epoch': 0.48}\n","{'loss': 0.7615, 'learning_rate': 4.72e-05, 'epoch': 0.56}\n","{'eval_stsb_spearman': 0.802532495117379, 'eval_sickr_spearman': 0.7401810312502675, 'eval_avg_sts': 0.7713567631838232, 'epoch': 0.56}\n","{'loss': 0.737, 'learning_rate': 4.6800000000000006e-05, 'epoch': 0.64}\n","{'eval_stsb_spearman': 0.8082003150363806, 'eval_sickr_spearman': 0.7478077937854225, 'eval_avg_sts': 0.7780040544109015, 'epoch': 0.64}\n","  6% 4000/62500 [25:05<4:56:19,  3.29it/s][INFO|trainer.py:1344] 2021-11-23 04:39:05,465 >> Saving model checkpoint to ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased\n","[INFO|configuration_utils.py:300] 2021-11-23 04:39:05,472 >> Configuration saved in ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased/config.json\n","[INFO|modeling_utils.py:817] 2021-11-23 04:39:07,172 >> Model weights saved in ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased/pytorch_model.bin\n","{'loss': 0.691, 'learning_rate': 4.64e-05, 'epoch': 0.72}\n","{'eval_stsb_spearman': 0.801621420822348, 'eval_sickr_spearman': 0.747949389472462, 'eval_avg_sts': 0.774785405147405, 'epoch': 0.72}\n","{'loss': 0.6616, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.8}\n","{'eval_stsb_spearman': 0.8008434423503221, 'eval_sickr_spearman': 0.7292478557232143, 'eval_avg_sts': 0.7650456490367682, 'epoch': 0.8}\n","{'loss': 0.6331, 'learning_rate': 4.5600000000000004e-05, 'epoch': 0.88}\n","{'eval_stsb_spearman': 0.8047860760284083, 'eval_sickr_spearman': 0.7560690952016764, 'eval_avg_sts': 0.7804275856150424, 'epoch': 0.88}\n","{'loss': 0.5803, 'learning_rate': 4.52e-05, 'epoch': 0.96}\n","{'eval_stsb_spearman': 0.8009038224629949, 'eval_sickr_spearman': 0.7462247847442253, 'eval_avg_sts': 0.7735643036036101, 'epoch': 0.96}\n","{'loss': 0.4534, 'learning_rate': 4.4800000000000005e-05, 'epoch': 1.04}\n","{'eval_stsb_spearman': 0.8058848774974701, 'eval_sickr_spearman': 0.7549680782634106, 'eval_avg_sts': 0.7804264778804404, 'epoch': 1.04}\n","{'loss': 0.3467, 'learning_rate': 4.44e-05, 'epoch': 1.12}\n","{'eval_stsb_spearman': 0.8027467123470632, 'eval_sickr_spearman': 0.7543316181382542, 'eval_avg_sts': 0.7785391652426588, 'epoch': 1.12}\n","{'loss': 0.3494, 'learning_rate': 4.4000000000000006e-05, 'epoch': 1.2}\n","{'eval_stsb_spearman': 0.7997704024638985, 'eval_sickr_spearman': 0.7409964552593824, 'eval_avg_sts': 0.7703834288616405, 'epoch': 1.2}\n","{'loss': 0.3448, 'learning_rate': 4.36e-05, 'epoch': 1.28}\n","{'eval_stsb_spearman': 0.8014610043416788, 'eval_sickr_spearman': 0.7559553095223696, 'eval_avg_sts': 0.7787081569320242, 'epoch': 1.28}\n","{'loss': 0.3348, 'learning_rate': 4.32e-05, 'epoch': 1.36}\n","{'eval_stsb_spearman': 0.790169857769539, 'eval_sickr_spearman': 0.7440847109885488, 'eval_avg_sts': 0.7671272843790439, 'epoch': 1.36}\n","{'loss': 0.326, 'learning_rate': 4.2800000000000004e-05, 'epoch': 1.44}\n","{'eval_stsb_spearman': 0.7974630033655289, 'eval_sickr_spearman': 0.7349137005110569, 'eval_avg_sts': 0.7661883519382928, 'epoch': 1.44}\n","{'loss': 0.3247, 'learning_rate': 4.24e-05, 'epoch': 1.52}\n","{'eval_stsb_spearman': 0.8002946448185664, 'eval_sickr_spearman': 0.7190065201812755, 'eval_avg_sts': 0.7596505824999209, 'epoch': 1.52}\n","{'loss': 0.3172, 'learning_rate': 4.2e-05, 'epoch': 1.6}\n","{'eval_stsb_spearman': 0.7955012422269635, 'eval_sickr_spearman': 0.7110701011351489, 'eval_avg_sts': 0.7532856716810562, 'epoch': 1.6}\n","{'loss': 0.2991, 'learning_rate': 4.16e-05, 'epoch': 1.68}\n","{'eval_stsb_spearman': 0.7951774395126884, 'eval_sickr_spearman': 0.7272599444968937, 'eval_avg_sts': 0.761218692004791, 'epoch': 1.68}\n","{'loss': 0.3039, 'learning_rate': 4.12e-05, 'epoch': 1.76}\n","{'eval_stsb_spearman': 0.7930635964187709, 'eval_sickr_spearman': 0.7262722329269202, 'eval_avg_sts': 0.7596679146728456, 'epoch': 1.76}\n","{'loss': 0.2776, 'learning_rate': 4.08e-05, 'epoch': 1.84}\n","{'eval_stsb_spearman': 0.7931320626581301, 'eval_sickr_spearman': 0.7240798052706763, 'eval_avg_sts': 0.7586059339644031, 'epoch': 1.84}\n","{'loss': 0.2648, 'learning_rate': 4.0400000000000006e-05, 'epoch': 1.92}\n","{'eval_stsb_spearman': 0.801578078088619, 'eval_sickr_spearman': 0.7391983149148437, 'eval_avg_sts': 0.7703881965017314, 'epoch': 1.92}\n","{'loss': 0.2683, 'learning_rate': 4e-05, 'epoch': 2.0}\n","{'eval_stsb_spearman': 0.789311744000715, 'eval_sickr_spearman': 0.7233157265089987, 'eval_avg_sts': 0.7563137352548568, 'epoch': 2.0}\n","{'eval_stsb_spearman': 0.789311744000715, 'eval_sickr_spearman': 0.7233157265089987, 'eval_avg_sts': 0.7563137352548568, 'epoch': 2.0}\n","{'loss': 0.1633, 'learning_rate': 3.960000000000001e-05, 'epoch': 2.08}\n","{'eval_stsb_spearman': 0.7949872810186377, 'eval_sickr_spearman': 0.7231491066181098, 'eval_avg_sts': 0.7590681938183738, 'epoch': 2.08}\n","{'loss': 0.1625, 'learning_rate': 3.9200000000000004e-05, 'epoch': 2.16}\n","{'eval_stsb_spearman': 0.7891546595609454, 'eval_sickr_spearman': 0.7219389149862752, 'eval_avg_sts': 0.7555467872736104, 'epoch': 2.16}\n","{'loss': 0.1737, 'learning_rate': 3.88e-05, 'epoch': 2.24}\n","{'eval_stsb_spearman': 0.788214194499945, 'eval_sickr_spearman': 0.721333290828242, 'eval_avg_sts': 0.7547737426640935, 'epoch': 2.24}\n","{'loss': 0.1704, 'learning_rate': 3.8400000000000005e-05, 'epoch': 2.32}\n","{'eval_stsb_spearman': 0.7919816526125735, 'eval_sickr_spearman': 0.7172119821693447, 'eval_avg_sts': 0.7545968173909591, 'epoch': 2.32}\n","{'loss': 0.1717, 'learning_rate': 3.8e-05, 'epoch': 2.4}\n","{'eval_stsb_spearman': 0.7956539156373019, 'eval_sickr_spearman': 0.7401015397773875, 'eval_avg_sts': 0.7678777277073447, 'epoch': 2.4}\n","{'loss': 0.173, 'learning_rate': 3.76e-05, 'epoch': 2.48}\n","{'eval_stsb_spearman': 0.806727636085435, 'eval_sickr_spearman': 0.73952516656013, 'eval_avg_sts': 0.7731264013227825, 'epoch': 2.48}\n","{'loss': 0.1672, 'learning_rate': 3.72e-05, 'epoch': 2.56}\n","{'eval_stsb_spearman': 0.8049639231260735, 'eval_sickr_spearman': 0.7318399021434234, 'eval_avg_sts': 0.7684019126347484, 'epoch': 2.56}\n","{'loss': 0.1548, 'learning_rate': 3.68e-05, 'epoch': 2.64}\n","{'eval_stsb_spearman': 0.8002706181115937, 'eval_sickr_spearman': 0.7126485952528111, 'eval_avg_sts': 0.7564596066822025, 'epoch': 2.64}\n","{'loss': 0.1661, 'learning_rate': 3.6400000000000004e-05, 'epoch': 2.72}\n","{'eval_stsb_spearman': 0.797544022994323, 'eval_sickr_spearman': 0.7294454076434292, 'eval_avg_sts': 0.7634947153188761, 'epoch': 2.72}\n","{'loss': 0.1633, 'learning_rate': 3.6e-05, 'epoch': 2.8}\n","{'eval_stsb_spearman': 0.7895600121534906, 'eval_sickr_spearman': 0.7274391485363592, 'eval_avg_sts': 0.7584995803449248, 'epoch': 2.8}\n","{'loss': 0.1453, 'learning_rate': 3.56e-05, 'epoch': 2.88}\n","{'eval_stsb_spearman': 0.7961953334526772, 'eval_sickr_spearman': 0.7242778375019056, 'eval_avg_sts': 0.7602365854772914, 'epoch': 2.88}\n","{'loss': 0.1474, 'learning_rate': 3.52e-05, 'epoch': 2.96}\n","{'eval_stsb_spearman': 0.7975828653670671, 'eval_sickr_spearman': 0.7248716940400864, 'eval_avg_sts': 0.7612272797035768, 'epoch': 2.96}\n","{'loss': 0.1234, 'learning_rate': 3.48e-05, 'epoch': 3.04}\n","{'eval_stsb_spearman': 0.7948213243153907, 'eval_sickr_spearman': 0.7254316406206519, 'eval_avg_sts': 0.7601264824680213, 'epoch': 3.04}\n","{'loss': 0.0991, 'learning_rate': 3.4399999999999996e-05, 'epoch': 3.12}\n","{'eval_stsb_spearman': 0.7986273493637509, 'eval_sickr_spearman': 0.7326946155935147, 'eval_avg_sts': 0.7656609824786328, 'epoch': 3.12}\n","{'loss': 0.1043, 'learning_rate': 3.4000000000000007e-05, 'epoch': 3.2}\n","{'eval_stsb_spearman': 0.7979943934114897, 'eval_sickr_spearman': 0.7367312934516779, 'eval_avg_sts': 0.7673628434315838, 'epoch': 3.2}\n","{'loss': 0.1056, 'learning_rate': 3.3600000000000004e-05, 'epoch': 3.28}\n","{'eval_stsb_spearman': 0.7952128849010075, 'eval_sickr_spearman': 0.7370782701284668, 'eval_avg_sts': 0.7661455775147372, 'epoch': 3.28}\n","{'loss': 0.1047, 'learning_rate': 3.32e-05, 'epoch': 3.36}\n","{'eval_stsb_spearman': 0.7970956248172941, 'eval_sickr_spearman': 0.732919401148245, 'eval_avg_sts': 0.7650075129827696, 'epoch': 3.36}\n","{'loss': 0.1077, 'learning_rate': 3.2800000000000004e-05, 'epoch': 3.44}\n","{'eval_stsb_spearman': 0.7959998375842113, 'eval_sickr_spearman': 0.7408085575905564, 'eval_avg_sts': 0.7684041975873839, 'epoch': 3.44}\n","{'loss': 0.1057, 'learning_rate': 3.24e-05, 'epoch': 3.52}\n","{'eval_stsb_spearman': 0.8008053366299919, 'eval_sickr_spearman': 0.7388622412980812, 'eval_avg_sts': 0.7698337889640365, 'epoch': 3.52}\n","{'loss': 0.1091, 'learning_rate': 3.2000000000000005e-05, 'epoch': 3.6}\n","{'eval_stsb_spearman': 0.7922247150576774, 'eval_sickr_spearman': 0.7237064595191977, 'eval_avg_sts': 0.7579655872884375, 'epoch': 3.6}\n","{'loss': 0.1029, 'learning_rate': 3.16e-05, 'epoch': 3.68}\n","{'eval_stsb_spearman': 0.7908543454123904, 'eval_sickr_spearman': 0.7202275188109338, 'eval_avg_sts': 0.7555409321116622, 'epoch': 3.68}\n","{'loss': 0.1085, 'learning_rate': 3.12e-05, 'epoch': 3.76}\n","{'eval_stsb_spearman': 0.7937269587914741, 'eval_sickr_spearman': 0.735084739263278, 'eval_avg_sts': 0.7644058490273761, 'epoch': 3.76}\n","{'loss': 0.0955, 'learning_rate': 3.08e-05, 'epoch': 3.84}\n","{'eval_stsb_spearman': 0.7953925275565592, 'eval_sickr_spearman': 0.733258596786601, 'eval_avg_sts': 0.7643255621715801, 'epoch': 3.84}\n","{'loss': 0.0992, 'learning_rate': 3.04e-05, 'epoch': 3.92}\n","{'eval_stsb_spearman': 0.7937972862421431, 'eval_sickr_spearman': 0.7324028746833795, 'eval_avg_sts': 0.7631000804627612, 'epoch': 3.92}\n","{'loss': 0.1053, 'learning_rate': 3e-05, 'epoch': 4.0}\n","{'eval_stsb_spearman': 0.7885882150316491, 'eval_sickr_spearman': 0.733319884472036, 'eval_avg_sts': 0.7609540497518426, 'epoch': 4.0}\n","{'eval_stsb_spearman': 0.7885882150316491, 'eval_sickr_spearman': 0.733319884472036, 'eval_avg_sts': 0.7609540497518426, 'epoch': 4.0}\n","{'loss': 0.0755, 'learning_rate': 2.96e-05, 'epoch': 4.08}\n","{'eval_stsb_spearman': 0.7975018041040148, 'eval_sickr_spearman': 0.7456504288332283, 'eval_avg_sts': 0.7715761164686216, 'epoch': 4.08}\n","{'loss': 0.0756, 'learning_rate': 2.9199999999999998e-05, 'epoch': 4.16}\n","{'eval_stsb_spearman': 0.7909936323586547, 'eval_sickr_spearman': 0.7412071677013914, 'eval_avg_sts': 0.7661004000300231, 'epoch': 4.16}\n","{'loss': 0.0769, 'learning_rate': 2.88e-05, 'epoch': 4.24}\n","{'eval_stsb_spearman': 0.7900911573499845, 'eval_sickr_spearman': 0.7226863749868551, 'eval_avg_sts': 0.7563887661684198, 'epoch': 4.24}\n","{'loss': 0.0793, 'learning_rate': 2.84e-05, 'epoch': 4.32}\n","{'eval_stsb_spearman': 0.795158940206746, 'eval_sickr_spearman': 0.7200878443679518, 'eval_avg_sts': 0.757623392287349, 'epoch': 4.32}\n","{'loss': 0.0778, 'learning_rate': 2.8000000000000003e-05, 'epoch': 4.4}\n","{'eval_stsb_spearman': 0.7941497074876269, 'eval_sickr_spearman': 0.7222752287585449, 'eval_avg_sts': 0.758212468123086, 'epoch': 4.4}\n","{'loss': 0.0807, 'learning_rate': 2.7600000000000003e-05, 'epoch': 4.48}\n","{'eval_stsb_spearman': 0.7897308467908064, 'eval_sickr_spearman': 0.7158643186904561, 'eval_avg_sts': 0.7527975827406312, 'epoch': 4.48}\n","{'loss': 0.0806, 'learning_rate': 2.7200000000000004e-05, 'epoch': 4.56}\n","{'eval_stsb_spearman': 0.7884421270413827, 'eval_sickr_spearman': 0.7182032000097232, 'eval_avg_sts': 0.753322663525553, 'epoch': 4.56}\n","{'loss': 0.0713, 'learning_rate': 2.6800000000000004e-05, 'epoch': 4.64}\n","{'eval_stsb_spearman': 0.7989650702370851, 'eval_sickr_spearman': 0.7321631034250006, 'eval_avg_sts': 0.7655640868310428, 'epoch': 4.64}\n","{'loss': 0.0781, 'learning_rate': 2.64e-05, 'epoch': 4.72}\n","{'eval_stsb_spearman': 0.7964021592180018, 'eval_sickr_spearman': 0.733747889616951, 'eval_avg_sts': 0.7650750244174764, 'epoch': 4.72}\n","{'loss': 0.0729, 'learning_rate': 2.6000000000000002e-05, 'epoch': 4.8}\n","{'eval_stsb_spearman': 0.7941894050238842, 'eval_sickr_spearman': 0.7327200240461754, 'eval_avg_sts': 0.7634547145350299, 'epoch': 4.8}\n","{'loss': 0.0728, 'learning_rate': 2.5600000000000002e-05, 'epoch': 4.88}\n","{'eval_stsb_spearman': 0.7927921193633356, 'eval_sickr_spearman': 0.739239879559416, 'eval_avg_sts': 0.7660159994613758, 'epoch': 4.88}\n","{'loss': 0.0675, 'learning_rate': 2.5200000000000003e-05, 'epoch': 4.96}\n","{'eval_stsb_spearman': 0.7944965084383936, 'eval_sickr_spearman': 0.7294505469712831, 'eval_avg_sts': 0.7619735277048383, 'epoch': 4.96}\n","{'loss': 0.064, 'learning_rate': 2.48e-05, 'epoch': 5.04}\n","{'eval_stsb_spearman': 0.7932808695156516, 'eval_sickr_spearman': 0.725591728281745, 'eval_avg_sts': 0.7594362988986982, 'epoch': 5.04}\n","{'loss': 0.0507, 'learning_rate': 2.44e-05, 'epoch': 5.12}\n","{'eval_stsb_spearman': 0.7923395781261675, 'eval_sickr_spearman': 0.7310039688539945, 'eval_avg_sts': 0.7616717734900811, 'epoch': 5.12}\n","{'loss': 0.0583, 'learning_rate': 2.4e-05, 'epoch': 5.2}\n","{'eval_stsb_spearman': 0.800702989584363, 'eval_sickr_spearman': 0.7321760718223889, 'eval_avg_sts': 0.766439530703376, 'epoch': 5.2}\n","{'loss': 0.0564, 'learning_rate': 2.36e-05, 'epoch': 5.28}\n","{'eval_stsb_spearman': 0.794108504612254, 'eval_sickr_spearman': 0.7329536953546718, 'eval_avg_sts': 0.7635310999834629, 'epoch': 5.28}\n","{'loss': 0.0607, 'learning_rate': 2.32e-05, 'epoch': 5.36}\n","{'eval_stsb_spearman': 0.7925717152968376, 'eval_sickr_spearman': 0.7258953809050368, 'eval_avg_sts': 0.7592335481009371, 'epoch': 5.36}\n","{'loss': 0.0595, 'learning_rate': 2.2800000000000002e-05, 'epoch': 5.44}\n","{'eval_stsb_spearman': 0.7904481035129135, 'eval_sickr_spearman': 0.7245165040449515, 'eval_avg_sts': 0.7574823037789324, 'epoch': 5.44}\n","{'loss': 0.0559, 'learning_rate': 2.2400000000000002e-05, 'epoch': 5.52}\n","{'eval_stsb_spearman': 0.790756065282154, 'eval_sickr_spearman': 0.7256229004665784, 'eval_avg_sts': 0.7581894828743663, 'epoch': 5.52}\n","{'loss': 0.0629, 'learning_rate': 2.2000000000000003e-05, 'epoch': 5.6}\n","{'eval_stsb_spearman': 0.79490579163863, 'eval_sickr_spearman': 0.7272752118262753, 'eval_avg_sts': 0.7610905017324526, 'epoch': 5.6}\n","{'loss': 0.0554, 'learning_rate': 2.16e-05, 'epoch': 5.68}\n","{'eval_stsb_spearman': 0.7963569581192326, 'eval_sickr_spearman': 0.7305824479077736, 'eval_avg_sts': 0.7634697030135031, 'epoch': 5.68}\n","{'loss': 0.0579, 'learning_rate': 2.12e-05, 'epoch': 5.76}\n","{'eval_stsb_spearman': 0.7964263620816581, 'eval_sickr_spearman': 0.7297543436878792, 'eval_avg_sts': 0.7630903528847686, 'epoch': 5.76}\n","{'loss': 0.0605, 'learning_rate': 2.08e-05, 'epoch': 5.84}\n","{'eval_stsb_spearman': 0.7948123652344748, 'eval_sickr_spearman': 0.7261287640269246, 'eval_avg_sts': 0.7604705646306997, 'epoch': 5.84}\n","{'loss': 0.0598, 'learning_rate': 2.04e-05, 'epoch': 5.92}\n","{'eval_stsb_spearman': 0.791879026021534, 'eval_sickr_spearman': 0.718596430637197, 'eval_avg_sts': 0.7552377283293655, 'epoch': 5.92}\n","{'loss': 0.054, 'learning_rate': 2e-05, 'epoch': 6.0}\n","{'eval_stsb_spearman': 0.7864691157044673, 'eval_sickr_spearman': 0.7193221805799268, 'eval_avg_sts': 0.7528956481421971, 'epoch': 6.0}\n","{'eval_stsb_spearman': 0.7864691157044673, 'eval_sickr_spearman': 0.7193221805799268, 'eval_avg_sts': 0.7528956481421971, 'epoch': 6.0}\n","{'loss': 0.0426, 'learning_rate': 1.9600000000000002e-05, 'epoch': 6.08}\n","{'eval_stsb_spearman': 0.788979677233938, 'eval_sickr_spearman': 0.720300670178424, 'eval_avg_sts': 0.754640173706181, 'epoch': 6.08}\n","{'loss': 0.0522, 'learning_rate': 1.9200000000000003e-05, 'epoch': 6.16}\n","{'eval_stsb_spearman': 0.7917675812906536, 'eval_sickr_spearman': 0.721945687371578, 'eval_avg_sts': 0.7568566343311158, 'epoch': 6.16}\n","{'loss': 0.0486, 'learning_rate': 1.88e-05, 'epoch': 6.24}\n","{'eval_stsb_spearman': 0.7919011621578068, 'eval_sickr_spearman': 0.7277130699078609, 'eval_avg_sts': 0.7598071160328339, 'epoch': 6.24}\n","{'loss': 0.047, 'learning_rate': 1.84e-05, 'epoch': 6.32}\n","{'eval_stsb_spearman': 0.7949910158966567, 'eval_sickr_spearman': 0.7296411343817896, 'eval_avg_sts': 0.7623160751392231, 'epoch': 6.32}\n","{'loss': 0.0478, 'learning_rate': 1.8e-05, 'epoch': 6.4}\n","{'eval_stsb_spearman': 0.7947058117801583, 'eval_sickr_spearman': 0.7269428911963006, 'eval_avg_sts': 0.7608243514882295, 'epoch': 6.4}\n","{'loss': 0.0523, 'learning_rate': 1.76e-05, 'epoch': 6.48}\n","{'eval_stsb_spearman': 0.7939342916747704, 'eval_sickr_spearman': 0.7266211308477667, 'eval_avg_sts': 0.7602777112612685, 'epoch': 6.48}\n","{'loss': 0.0487, 'learning_rate': 1.7199999999999998e-05, 'epoch': 6.56}\n","{'eval_stsb_spearman': 0.7993958125268444, 'eval_sickr_spearman': 0.7309358607521553, 'eval_avg_sts': 0.7651658366394999, 'epoch': 6.56}\n","{'loss': 0.0417, 'learning_rate': 1.6800000000000002e-05, 'epoch': 6.64}\n","{'eval_stsb_spearman': 0.7939607945460363, 'eval_sickr_spearman': 0.7250628578238101, 'eval_avg_sts': 0.7595118261849232, 'epoch': 6.64}\n","{'loss': 0.0525, 'learning_rate': 1.6400000000000002e-05, 'epoch': 6.72}\n","{'eval_stsb_spearman': 0.7919881401615289, 'eval_sickr_spearman': 0.7204701719353992, 'eval_avg_sts': 0.756229156048464, 'epoch': 6.72}\n","{'loss': 0.0488, 'learning_rate': 1.6000000000000003e-05, 'epoch': 6.8}\n","{'eval_stsb_spearman': 0.7972658715570634, 'eval_sickr_spearman': 0.730360592250231, 'eval_avg_sts': 0.7638132319036472, 'epoch': 6.8}\n","{'loss': 0.044, 'learning_rate': 1.56e-05, 'epoch': 6.88}\n","{'eval_stsb_spearman': 0.795218573699857, 'eval_sickr_spearman': 0.7262686786254139, 'eval_avg_sts': 0.7607436261626355, 'epoch': 6.88}\n","{'loss': 0.0433, 'learning_rate': 1.52e-05, 'epoch': 6.96}\n","{'eval_stsb_spearman': 0.7919723501150587, 'eval_sickr_spearman': 0.725379911124403, 'eval_avg_sts': 0.7586761306197309, 'epoch': 6.96}\n","{'loss': 0.0452, 'learning_rate': 1.48e-05, 'epoch': 7.04}\n","{'eval_stsb_spearman': 0.7955765401390644, 'eval_sickr_spearman': 0.7312174190687856, 'eval_avg_sts': 0.763396979603925, 'epoch': 7.04}\n","{'loss': 0.0419, 'learning_rate': 1.44e-05, 'epoch': 7.12}\n","{'eval_stsb_spearman': 0.7961269508432688, 'eval_sickr_spearman': 0.7272989937823627, 'eval_avg_sts': 0.7617129723128158, 'epoch': 7.12}\n","{'loss': 0.0417, 'learning_rate': 1.4000000000000001e-05, 'epoch': 7.2}\n","{'eval_stsb_spearman': 0.7993083213633407, 'eval_sickr_spearman': 0.7267667611473271, 'eval_avg_sts': 0.7630375412553339, 'epoch': 7.2}\n","{'loss': 0.0436, 'learning_rate': 1.3600000000000002e-05, 'epoch': 7.28}\n","{'eval_stsb_spearman': 0.7984808937467963, 'eval_sickr_spearman': 0.718646863293707, 'eval_avg_sts': 0.7585638785202516, 'epoch': 7.28}\n","{'loss': 0.0403, 'learning_rate': 1.32e-05, 'epoch': 7.36}\n","{'eval_stsb_spearman': 0.7960311820939889, 'eval_sickr_spearman': 0.7239000248579933, 'eval_avg_sts': 0.7599656034759912, 'epoch': 7.36}\n","{'loss': 0.0392, 'learning_rate': 1.2800000000000001e-05, 'epoch': 7.44}\n","{'eval_stsb_spearman': 0.7955223159023553, 'eval_sickr_spearman': 0.7241028121682651, 'eval_avg_sts': 0.7598125640353102, 'epoch': 7.44}\n","{'loss': 0.0427, 'learning_rate': 1.24e-05, 'epoch': 7.52}\n","{'eval_stsb_spearman': 0.7970111703139021, 'eval_sickr_spearman': 0.7301837417347359, 'eval_avg_sts': 0.763597456024319, 'epoch': 7.52}\n","{'loss': 0.0397, 'learning_rate': 1.2e-05, 'epoch': 7.6}\n","{'eval_stsb_spearman': 0.7981425892431669, 'eval_sickr_spearman': 0.7277337713125805, 'eval_avg_sts': 0.7629381802778737, 'epoch': 7.6}\n","{'loss': 0.0429, 'learning_rate': 1.16e-05, 'epoch': 7.68}\n","{'eval_stsb_spearman': 0.7957220953996559, 'eval_sickr_spearman': 0.7271596075259894, 'eval_avg_sts': 0.7614408514628226, 'epoch': 7.68}\n","{'loss': 0.039, 'learning_rate': 1.1200000000000001e-05, 'epoch': 7.76}\n","{'eval_stsb_spearman': 0.7940813665093643, 'eval_sickr_spearman': 0.7217646101191563, 'eval_avg_sts': 0.7579229883142603, 'epoch': 7.76}\n","{'loss': 0.0412, 'learning_rate': 1.08e-05, 'epoch': 7.84}\n","{'eval_stsb_spearman': 0.7947024640963568, 'eval_sickr_spearman': 0.7261813580829993, 'eval_avg_sts': 0.7604419110896781, 'epoch': 7.84}\n","{'loss': 0.0354, 'learning_rate': 1.04e-05, 'epoch': 7.92}\n","{'eval_stsb_spearman': 0.7967776096547065, 'eval_sickr_spearman': 0.7260391860227425, 'eval_avg_sts': 0.7614083978387245, 'epoch': 7.92}\n","{'loss': 0.0437, 'learning_rate': 1e-05, 'epoch': 8.0}\n","{'eval_stsb_spearman': 0.7938121022727358, 'eval_sickr_spearman': 0.7253468657266136, 'eval_avg_sts': 0.7595794839996747, 'epoch': 8.0}\n","{'eval_stsb_spearman': 0.7938121022727358, 'eval_sickr_spearman': 0.7253468657266136, 'eval_avg_sts': 0.7595794839996747, 'epoch': 8.0}\n","{'loss': 0.0392, 'learning_rate': 9.600000000000001e-06, 'epoch': 8.08}\n","{'eval_stsb_spearman': 0.7942735990320906, 'eval_sickr_spearman': 0.7266846279638679, 'eval_avg_sts': 0.7604791134979793, 'epoch': 8.08}\n","{'loss': 0.0376, 'learning_rate': 9.2e-06, 'epoch': 8.16}\n","{'eval_stsb_spearman': 0.7918028286459078, 'eval_sickr_spearman': 0.7241744745716107, 'eval_avg_sts': 0.7579886516087593, 'epoch': 8.16}\n","{'loss': 0.0356, 'learning_rate': 8.8e-06, 'epoch': 8.24}\n","{'eval_stsb_spearman': 0.7940438860564525, 'eval_sickr_spearman': 0.7271659956624806, 'eval_avg_sts': 0.7606049408594666, 'epoch': 8.24}\n","{'loss': 0.0361, 'learning_rate': 8.400000000000001e-06, 'epoch': 8.32}\n","{'eval_stsb_spearman': 0.7938289891109965, 'eval_sickr_spearman': 0.7317499879215312, 'eval_avg_sts': 0.7627894885162638, 'epoch': 8.32}\n","{'loss': 0.0365, 'learning_rate': 8.000000000000001e-06, 'epoch': 8.4}\n","{'eval_stsb_spearman': 0.79404140670124, 'eval_sickr_spearman': 0.7309742376022043, 'eval_avg_sts': 0.7625078221517221, 'epoch': 8.4}\n","{'loss': 0.0394, 'learning_rate': 7.6e-06, 'epoch': 8.48}\n","{'eval_stsb_spearman': 0.7946994996815023, 'eval_sickr_spearman': 0.7277083148288185, 'eval_avg_sts': 0.7612039072551604, 'epoch': 8.48}\n","{'loss': 0.0372, 'learning_rate': 7.2e-06, 'epoch': 8.56}\n","{'eval_stsb_spearman': 0.7937032249734959, 'eval_sickr_spearman': 0.7292672122570938, 'eval_avg_sts': 0.7614852186152948, 'epoch': 8.56}\n","{'loss': 0.0374, 'learning_rate': 6.800000000000001e-06, 'epoch': 8.64}\n","{'eval_stsb_spearman': 0.7941319733058545, 'eval_sickr_spearman': 0.7315949915571905, 'eval_avg_sts': 0.7628634824315226, 'epoch': 8.64}\n","{'loss': 0.038, 'learning_rate': 6.4000000000000006e-06, 'epoch': 8.72}\n","{'eval_stsb_spearman': 0.7933572140588611, 'eval_sickr_spearman': 0.7290437235421023, 'eval_avg_sts': 0.7612004688004816, 'epoch': 8.72}\n","{'loss': 0.0331, 'learning_rate': 6e-06, 'epoch': 8.8}\n","{'eval_stsb_spearman': 0.7921728004311495, 'eval_sickr_spearman': 0.7291136087946948, 'eval_avg_sts': 0.7606432046129221, 'epoch': 8.8}\n","{'loss': 0.0339, 'learning_rate': 5.600000000000001e-06, 'epoch': 8.88}\n","{'eval_stsb_spearman': 0.7957540270986971, 'eval_sickr_spearman': 0.733574785527368, 'eval_avg_sts': 0.7646644063130326, 'epoch': 8.88}\n","{'loss': 0.0358, 'learning_rate': 5.2e-06, 'epoch': 8.96}\n","{'eval_stsb_spearman': 0.7933128190104695, 'eval_sickr_spearman': 0.7301445003248609, 'eval_avg_sts': 0.7617286596676651, 'epoch': 8.96}\n","{'loss': 0.0306, 'learning_rate': 4.800000000000001e-06, 'epoch': 9.04}\n","{'eval_stsb_spearman': 0.7951347320049864, 'eval_sickr_spearman': 0.7297326336300292, 'eval_avg_sts': 0.7624336828175078, 'epoch': 9.04}\n","{'loss': 0.0336, 'learning_rate': 4.4e-06, 'epoch': 9.12}\n","{'eval_stsb_spearman': 0.7948094001131202, 'eval_sickr_spearman': 0.7318926883239039, 'eval_avg_sts': 0.7633510442185121, 'epoch': 9.12}\n","{'loss': 0.0332, 'learning_rate': 4.000000000000001e-06, 'epoch': 9.2}\n","{'eval_stsb_spearman': 0.7962200993020525, 'eval_sickr_spearman': 0.7303040596438384, 'eval_avg_sts': 0.7632620794729454, 'epoch': 9.2}\n","{'loss': 0.0318, 'learning_rate': 3.6e-06, 'epoch': 9.28}\n","{'eval_stsb_spearman': 0.7958247371118449, 'eval_sickr_spearman': 0.7309794249611596, 'eval_avg_sts': 0.7634020810365023, 'epoch': 9.28}\n","{'loss': 0.0319, 'learning_rate': 3.2000000000000003e-06, 'epoch': 9.36}\n","{'eval_stsb_spearman': 0.7950934928356134, 'eval_sickr_spearman': 0.7293935820849775, 'eval_avg_sts': 0.7622435374602954, 'epoch': 9.36}\n","{'loss': 0.035, 'learning_rate': 2.8000000000000003e-06, 'epoch': 9.44}\n","{'eval_stsb_spearman': 0.7944909888616357, 'eval_sickr_spearman': 0.7292825341784526, 'eval_avg_sts': 0.7618867615200442, 'epoch': 9.44}\n","{'loss': 0.0337, 'learning_rate': 2.4000000000000003e-06, 'epoch': 9.52}\n","{'eval_stsb_spearman': 0.7937998058168356, 'eval_sickr_spearman': 0.7279996234590406, 'eval_avg_sts': 0.7608997146379382, 'epoch': 9.52}\n","{'loss': 0.0363, 'learning_rate': 2.0000000000000003e-06, 'epoch': 9.6}\n","{'eval_stsb_spearman': 0.7939810853013691, 'eval_sickr_spearman': 0.7285835375592238, 'eval_avg_sts': 0.7612823114302965, 'epoch': 9.6}\n","{'loss': 0.0298, 'learning_rate': 1.6000000000000001e-06, 'epoch': 9.68}\n","{'eval_stsb_spearman': 0.7933865646128979, 'eval_sickr_spearman': 0.7274674388551062, 'eval_avg_sts': 0.760427001734002, 'epoch': 9.68}\n","{'loss': 0.0326, 'learning_rate': 1.2000000000000002e-06, 'epoch': 9.76}\n","{'eval_stsb_spearman': 0.79303158820483, 'eval_sickr_spearman': 0.7281213342700847, 'eval_avg_sts': 0.7605764612374574, 'epoch': 9.76}\n","{'loss': 0.0326, 'learning_rate': 8.000000000000001e-07, 'epoch': 9.84}\n","{'eval_stsb_spearman': 0.7935569686449349, 'eval_sickr_spearman': 0.7288346441575422, 'eval_avg_sts': 0.7611958064012385, 'epoch': 9.84}\n","{'loss': 0.0331, 'learning_rate': 4.0000000000000003e-07, 'epoch': 9.92}\n","{'eval_stsb_spearman': 0.7936769366991496, 'eval_sickr_spearman': 0.7288518392918569, 'eval_avg_sts': 0.7612643879955032, 'epoch': 9.92}\n","{'loss': 0.0317, 'learning_rate': 0.0, 'epoch': 10.0}\n","{'eval_stsb_spearman': 0.7937015708735978, 'eval_sickr_spearman': 0.7288895917375873, 'eval_avg_sts': 0.7612955813055926, 'epoch': 10.0}\n","{'eval_stsb_spearman': 0.7937015708735978, 'eval_sickr_spearman': 0.7288895917375873, 'eval_avg_sts': 0.7612955813055926, 'epoch': 10.0}\n","100% 62500/62500 [6:32:05<00:00,  3.28it/s]11/23/2021 10:46:05 - INFO - simcse.trainers -   \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","11/23/2021 10:46:05 - INFO - simcse.trainers -   Loading best model from ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased (score: 0.8082003150363806).\n","[INFO|configuration_utils.py:443] 2021-11-23 10:46:05,513 >> loading configuration file ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased/config.json\n","[INFO|configuration_utils.py:481] 2021-11-23 10:46:05,513 >> Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForCL\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|modeling_utils.py:1025] 2021-11-23 10:46:05,514 >> loading weights file ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased/pytorch_model.bin\n","[INFO|modeling_utils.py:1143] 2021-11-23 10:46:08,763 >> All model checkpoint weights were used when initializing BertForCL.\n","\n","[INFO|modeling_utils.py:1152] 2021-11-23 10:46:08,763 >> All the weights of BertForCL were initialized from the model checkpoint at ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForCL for predictions without further training.\n","{'train_runtime': 23529.2032, 'train_samples_per_second': 2.656, 'epoch': 10.0}\n","100% 62500/62500 [6:32:09<00:00,  2.66it/s]\n","[INFO|trainer.py:1344] 2021-11-23 10:46:08,922 >> Saving model checkpoint to ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased\n","[INFO|configuration_utils.py:300] 2021-11-23 10:46:08,930 >> Configuration saved in ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased/config.json\n","[INFO|modeling_utils.py:817] 2021-11-23 10:46:10,621 >> Model weights saved in ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased/pytorch_model.bin\n","11/23/2021 10:46:11 - INFO - __main__ -   ***** Train results *****\n","11/23/2021 10:46:11 - INFO - __main__ -     epoch = 10.0\n","11/23/2021 10:46:11 - INFO - __main__ -     train_runtime = 23529.2032\n","11/23/2021 10:46:11 - INFO - __main__ -     train_samples_per_second = 2.656\n","11/23/2021 10:46:11 - INFO - __main__ -   *** Evaluate ***\n","11/23/2021 10:46:46 - INFO - root -   Generating sentence embeddings\n","11/23/2021 10:47:00 - INFO - root -   Generated sentence embeddings\n","11/23/2021 10:47:00 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/23/2021 10:47:17 - INFO - root -   Best param found at split 1: l2reg = 1e-05                 with score 80.77\n","11/23/2021 10:47:33 - INFO - root -   Best param found at split 2: l2reg = 0.001                 with score 80.4\n","11/23/2021 10:47:47 - INFO - root -   Best param found at split 3: l2reg = 0.0001                 with score 80.18\n","11/23/2021 10:48:02 - INFO - root -   Best param found at split 4: l2reg = 1e-05                 with score 80.12\n","11/23/2021 10:48:20 - INFO - root -   Best param found at split 5: l2reg = 1e-05                 with score 80.43\n","11/23/2021 10:48:21 - INFO - root -   Generating sentence embeddings\n","11/23/2021 10:48:25 - INFO - root -   Generated sentence embeddings\n","11/23/2021 10:48:25 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/23/2021 10:48:30 - INFO - root -   Best param found at split 1: l2reg = 0.0001                 with score 88.18\n","11/23/2021 10:48:36 - INFO - root -   Best param found at split 2: l2reg = 0.001                 with score 88.28\n","11/23/2021 10:48:41 - INFO - root -   Best param found at split 3: l2reg = 0.001                 with score 87.78\n","11/23/2021 10:48:46 - INFO - root -   Best param found at split 4: l2reg = 0.01                 with score 87.25\n","11/23/2021 10:48:52 - INFO - root -   Best param found at split 5: l2reg = 0.01                 with score 87.42\n","11/23/2021 10:48:52 - INFO - root -   Generating sentence embeddings\n","11/23/2021 10:49:06 - INFO - root -   Generated sentence embeddings\n","11/23/2021 10:49:06 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/23/2021 10:49:20 - INFO - root -   Best param found at split 1: l2reg = 1e-05                 with score 94.0\n","11/23/2021 10:49:36 - INFO - root -   Best param found at split 2: l2reg = 1e-05                 with score 94.61\n","11/23/2021 10:49:52 - INFO - root -   Best param found at split 3: l2reg = 1e-05                 with score 94.52\n","11/23/2021 10:50:07 - INFO - root -   Best param found at split 4: l2reg = 0.0001                 with score 94.18\n","11/23/2021 10:50:23 - INFO - root -   Best param found at split 5: l2reg = 0.0001                 with score 94.21\n","11/23/2021 10:50:24 - INFO - root -   Generating sentence embeddings\n","11/23/2021 10:50:28 - INFO - root -   Generated sentence embeddings\n","11/23/2021 10:50:28 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/23/2021 10:50:42 - INFO - root -   Best param found at split 1: l2reg = 1e-05                 with score 88.37\n","11/23/2021 10:50:58 - INFO - root -   Best param found at split 2: l2reg = 1e-05                 with score 87.79\n","11/23/2021 10:51:15 - INFO - root -   Best param found at split 3: l2reg = 1e-05                 with score 88.46\n","11/23/2021 10:51:31 - INFO - root -   Best param found at split 4: l2reg = 0.001                 with score 87.78\n","11/23/2021 10:51:46 - INFO - root -   Best param found at split 5: l2reg = 0.001                 with score 88.26\n","11/23/2021 10:51:47 - INFO - root -   Computing embedding for train\n","11/23/2021 10:52:34 - INFO - root -   Computed train embeddings\n","11/23/2021 10:52:34 - INFO - root -   Computing embedding for dev\n","11/23/2021 10:52:35 - INFO - root -   Computed dev embeddings\n","11/23/2021 10:52:35 - INFO - root -   Computing embedding for test\n","11/23/2021 10:52:37 - INFO - root -   Computed test embeddings\n","11/23/2021 10:52:37 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..\n","11/23/2021 10:53:03 - INFO - root -   [('reg:1e-05', 84.63), ('reg:0.0001', 84.98), ('reg:0.001', 84.52), ('reg:0.01', 83.72)]\n","11/23/2021 10:53:03 - INFO - root -   Validation : best param found is reg = 0.0001 with score             84.98\n","11/23/2021 10:53:03 - INFO - root -   Evaluating...\n","11/23/2021 10:53:09 - INFO - root -   ***** Transfer task : TREC *****\n","\n","\n","11/23/2021 10:53:13 - INFO - root -   Computed train embeddings\n","11/23/2021 10:53:13 - INFO - root -   Computed test embeddings\n","11/23/2021 10:53:13 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation\n","11/23/2021 10:53:23 - INFO - root -   [('reg:1e-05', 77.71), ('reg:0.0001', 77.46), ('reg:0.001', 76.03), ('reg:0.01', 69.3)]\n","11/23/2021 10:53:23 - INFO - root -   Cross-validation : best param found is reg = 1e-05             with score 77.71\n","11/23/2021 10:53:23 - INFO - root -   Evaluating...\n","11/23/2021 10:53:23 - INFO - root -   ***** Transfer task : MRPC *****\n","\n","\n","11/23/2021 10:53:23 - INFO - root -   Computing embedding for train\n","11/23/2021 10:53:34 - INFO - root -   Computed train embeddings\n","11/23/2021 10:53:34 - INFO - root -   Computing embedding for test\n","11/23/2021 10:53:38 - INFO - root -   Computed test embeddings\n","11/23/2021 10:53:38 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation\n","11/23/2021 10:53:46 - INFO - root -   [('reg:1e-05', 74.71), ('reg:0.0001', 74.75), ('reg:0.001', 74.75), ('reg:0.01', 74.71)]\n","11/23/2021 10:53:46 - INFO - root -   Cross-validation : best param found is reg = 0.0001             with score 74.75\n","11/23/2021 10:53:46 - INFO - root -   Evaluating...\n","11/23/2021 10:53:46 - INFO - __main__ -   ***** Eval results *****\n","11/23/2021 10:53:46 - INFO - __main__ -     epoch = 10.0\n","11/23/2021 10:53:46 - INFO - __main__ -     eval_CR = 87.78\n","11/23/2021 10:53:46 - INFO - __main__ -     eval_MPQA = 88.13\n","11/23/2021 10:53:46 - INFO - __main__ -     eval_MR = 80.38\n","11/23/2021 10:53:46 - INFO - __main__ -     eval_MRPC = 74.75\n","11/23/2021 10:53:46 - INFO - __main__ -     eval_SST2 = 84.98\n","11/23/2021 10:53:46 - INFO - __main__ -     eval_SUBJ = 94.3\n","11/23/2021 10:53:46 - INFO - __main__ -     eval_TREC = 77.71\n","11/23/2021 10:53:46 - INFO - __main__ -     eval_avg_sts = 0.7780040544109015\n","11/23/2021 10:53:46 - INFO - __main__ -     eval_avg_transfer = 84.00428571428571\n","11/23/2021 10:53:46 - INFO - __main__ -     eval_sickr_spearman = 0.7478077937854225\n","11/23/2021 10:53:46 - INFO - __main__ -     eval_stsb_spearman = 0.8082003150363806\n"]}]},{"cell_type":"markdown","metadata":{"id":"lTlcqmg_TJ8V"},"source":["## Training with TwiBot dataset built on *similarity* - 15 epochs - GPU"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1LOlZqX-TNpM","executionInfo":{"status":"ok","timestamp":1637749313968,"user_tz":480,"elapsed":35757613,"user":{"displayName":"zeeshan ahmad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15348670853435150367"}},"outputId":"955d10de-dd5d-4596-bb91-f5f99c178507"},"source":["!cd SimCSE-main && python train.py --model_name_or_path bert-base-uncased \\\n","    --train_file ../train_triplets_with_similarity_only_tweets.csv \\\n","    --output_dir ../twiBot-similarity-15epochs-sup-simcse-bert-base-uncased \\\n","    --num_train_epochs 15 \\\n","    --per_device_train_batch_size 32 \\\n","    --learning_rate 5e-5 \\\n","    --max_seq_length 32 \\\n","    --evaluation_strategy steps \\\n","    --metric_for_best_model stsb_spearman \\\n","    --load_best_model_at_end \\\n","    --overwrite_output_dir \\\n","    --temp 0.05 \\\n","    --do_train \\"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["11/24/2021 00:26:15 - INFO - __main__ -   PyTorch: setting up devices\n","11/24/2021 00:26:15 - INFO - __main__ -   Set device to CUDA\n","11/24/2021 00:26:15 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1 distributed training: False, 16-bits training: False\n","11/24/2021 00:26:15 - INFO - __main__ -   Training/evaluation parameters OurTrainingArguments(output_dir='../twiBot-similarity-15epochs-sup-simcse-bert-base-uncased', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=15.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_steps=0, logging_dir='runs/Nov24_00-26-15_29da3eeace7b', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', fp16_backend='auto', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='../twiBot-similarity-15epochs-sup-simcse-bert-base-uncased', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model='stsb_spearman', greater_is_better=True, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, eval_transfer=False)\n","Downloading: 5.33kB [00:00, 5.85MB/s]       \n","Using custom data configuration default\n","Downloading and preparing dataset csv/default-5a558beb155267f5 (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to ./data/csv/default-5a558beb155267f5/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2...\n","Dataset csv downloaded and prepared to ./data/csv/default-5a558beb155267f5/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2. Subsequent calls will reuse this data.\n","[INFO|file_utils.py:1272] 2021-11-24 00:26:23,274 >> https://huggingface.co/bert-base-uncased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmps2w2ht7o\n","Downloading: 100% 570/570 [00:00<00:00, 430kB/s]\n","[INFO|file_utils.py:1276] 2021-11-24 00:26:24,022 >> storing https://huggingface.co/bert-base-uncased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|file_utils.py:1279] 2021-11-24 00:26:24,023 >> creating metadata file for /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|configuration_utils.py:445] 2021-11-24 00:26:24,023 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|configuration_utils.py:481] 2021-11-24 00:26:24,024 >> Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|configuration_utils.py:445] 2021-11-24 00:26:24,779 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|configuration_utils.py:481] 2021-11-24 00:26:24,780 >> Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|file_utils.py:1272] 2021-11-24 00:26:25,524 >> https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp13eyorhd\n","Downloading: 100% 232k/232k [00:00<00:00, 424kB/s]\n","[INFO|file_utils.py:1276] 2021-11-24 00:26:26,999 >> storing https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","[INFO|file_utils.py:1279] 2021-11-24 00:26:27,000 >> creating metadata file for /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","[INFO|file_utils.py:1272] 2021-11-24 00:26:27,745 >> https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp1cglmjk8\n","Downloading: 100% 466k/466k [00:00<00:00, 513kB/s] \n","[INFO|file_utils.py:1276] 2021-11-24 00:26:29,404 >> storing https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","[INFO|file_utils.py:1279] 2021-11-24 00:26:29,405 >> creating metadata file for /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","[INFO|tokenization_utils_base.py:1766] 2021-11-24 00:26:29,405 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","[INFO|tokenization_utils_base.py:1766] 2021-11-24 00:26:29,405 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","[INFO|file_utils.py:1272] 2021-11-24 00:26:30,172 >> https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp_3yjtuw2\n","Downloading: 100% 440M/440M [00:10<00:00, 43.7MB/s]\n","[INFO|file_utils.py:1276] 2021-11-24 00:26:40,315 >> storing https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","[INFO|file_utils.py:1279] 2021-11-24 00:26:40,316 >> creating metadata file for /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","[INFO|modeling_utils.py:1027] 2021-11-24 00:26:40,316 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","[WARNING|modeling_utils.py:1135] 2021-11-24 00:26:43,775 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForCL: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n","- This IS expected if you are initializing BertForCL from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForCL from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[WARNING|modeling_utils.py:1146] 2021-11-24 00:26:43,775 >> Some weights of BertForCL were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['mlp.dense.weight', 'mlp.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 200/200 [01:09<00:00,  2.88ba/s]\n","/usr/local/lib/python3.7/dist-packages/_distutils_hack/__init__.py:19: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n","  \"Distutils was imported before Setuptools. This usage is discouraged \"\n","[INFO|trainer.py:442] 2021-11-24 00:27:58,831 >> The following columns in the training set don't have a corresponding argument in `BertForCL.forward` and have been ignored: .\n","11/24/2021 00:27:58 - INFO - simcse.trainers -   ***** Running training *****\n","11/24/2021 00:27:58 - INFO - simcse.trainers -     Num examples = 200000\n","11/24/2021 00:27:58 - INFO - simcse.trainers -     Num Epochs = 15\n","11/24/2021 00:27:58 - INFO - simcse.trainers -     Instantaneous batch size per device = 32\n","11/24/2021 00:27:58 - INFO - simcse.trainers -     Total train batch size (w. parallel, distributed & accumulation) = 32\n","11/24/2021 00:27:58 - INFO - simcse.trainers -     Gradient Accumulation steps = 1\n","11/24/2021 00:27:58 - INFO - simcse.trainers -     Total optimization steps = 93750\n","{'loss': 1.148, 'learning_rate': 4.973333333333334e-05, 'epoch': 0.08}\n","{'eval_stsb_spearman': 0.7997028027731191, 'eval_sickr_spearman': 0.7342624468066575, 'eval_avg_sts': 0.7669826247898883, 'epoch': 0.08}\n","  1% 500/93750 [03:15<7:51:58,  3.29it/s][INFO|trainer.py:1344] 2021-11-24 00:31:14,860 >> Saving model checkpoint to ../twiBot-similarity-15epochs-sup-simcse-bert-base-uncased\n","[INFO|configuration_utils.py:300] 2021-11-24 00:31:14,866 >> Configuration saved in ../twiBot-similarity-15epochs-sup-simcse-bert-base-uncased/config.json\n","[INFO|modeling_utils.py:817] 2021-11-24 00:31:16,361 >> Model weights saved in ../twiBot-similarity-15epochs-sup-simcse-bert-base-uncased/pytorch_model.bin\n","{'loss': 1.0117, 'learning_rate': 4.9466666666666665e-05, 'epoch': 0.16}\n","{'eval_stsb_spearman': 0.7992467946305437, 'eval_sickr_spearman': 0.7295109700968923, 'eval_avg_sts': 0.764378882363718, 'epoch': 0.16}\n","{'loss': 0.9474, 'learning_rate': 4.92e-05, 'epoch': 0.24}\n","{'eval_stsb_spearman': 0.8063295931064688, 'eval_sickr_spearman': 0.7353573637950408, 'eval_avg_sts': 0.7708434784507547, 'epoch': 0.24}\n","  2% 1500/93750 [09:34<7:47:23,  3.29it/s][INFO|trainer.py:1344] 2021-11-24 00:37:33,172 >> Saving model checkpoint to ../twiBot-similarity-15epochs-sup-simcse-bert-base-uncased\n","[INFO|configuration_utils.py:300] 2021-11-24 00:37:33,179 >> Configuration saved in ../twiBot-similarity-15epochs-sup-simcse-bert-base-uncased/config.json\n","[INFO|modeling_utils.py:817] 2021-11-24 00:37:34,679 >> Model weights saved in ../twiBot-similarity-15epochs-sup-simcse-bert-base-uncased/pytorch_model.bin\n","{'loss': 0.9225, 'learning_rate': 4.8933333333333335e-05, 'epoch': 0.32}\n","{'eval_stsb_spearman': 0.8017139297829042, 'eval_sickr_spearman': 0.7324621450625541, 'eval_avg_sts': 0.7670880374227291, 'epoch': 0.32}\n","{'loss': 0.8528, 'learning_rate': 4.866666666666667e-05, 'epoch': 0.4}\n","{'eval_stsb_spearman': 0.8028161725354768, 'eval_sickr_spearman': 0.7415040479393803, 'eval_avg_sts': 0.7721601102374285, 'epoch': 0.4}\n","{'loss': 0.8052, 'learning_rate': 4.8400000000000004e-05, 'epoch': 0.48}\n","{'eval_stsb_spearman': 0.7971730191799001, 'eval_sickr_spearman': 0.7372457545791816, 'eval_avg_sts': 0.7672093868795409, 'epoch': 0.48}\n","{'loss': 0.7585, 'learning_rate': 4.8133333333333336e-05, 'epoch': 0.56}\n","{'eval_stsb_spearman': 0.8067132097463071, 'eval_sickr_spearman': 0.738377319297962, 'eval_avg_sts': 0.7725452645221346, 'epoch': 0.56}\n","  4% 3500/93750 [22:04<7:34:37,  3.31it/s][INFO|trainer.py:1344] 2021-11-24 00:50:02,883 >> Saving model checkpoint to ../twiBot-similarity-15epochs-sup-simcse-bert-base-uncased\n","[INFO|configuration_utils.py:300] 2021-11-24 00:50:02,889 >> Configuration saved in ../twiBot-similarity-15epochs-sup-simcse-bert-base-uncased/config.json\n","[INFO|modeling_utils.py:817] 2021-11-24 00:50:04,415 >> Model weights saved in ../twiBot-similarity-15epochs-sup-simcse-bert-base-uncased/pytorch_model.bin\n","{'loss': 0.7385, 'learning_rate': 4.7866666666666674e-05, 'epoch': 0.64}\n","{'eval_stsb_spearman': 0.8106360238413833, 'eval_sickr_spearman': 0.7385742948449597, 'eval_avg_sts': 0.7746051593431715, 'epoch': 0.64}\n","  4% 4000/93750 [25:14<7:34:28,  3.29it/s][INFO|trainer.py:1344] 2021-11-24 00:53:13,793 >> Saving model checkpoint to ../twiBot-similarity-15epochs-sup-simcse-bert-base-uncased\n","[INFO|configuration_utils.py:300] 2021-11-24 00:53:13,798 >> Configuration saved in ../twiBot-similarity-15epochs-sup-simcse-bert-base-uncased/config.json\n","[INFO|modeling_utils.py:817] 2021-11-24 00:53:15,301 >> Model weights saved in ../twiBot-similarity-15epochs-sup-simcse-bert-base-uncased/pytorch_model.bin\n","{'loss': 0.6914, 'learning_rate': 4.76e-05, 'epoch': 0.72}\n","{'eval_stsb_spearman': 0.8010706595889779, 'eval_sickr_spearman': 0.7337371306502288, 'eval_avg_sts': 0.7674038951196034, 'epoch': 0.72}\n","{'loss': 0.6652, 'learning_rate': 4.7333333333333336e-05, 'epoch': 0.8}\n","{'eval_stsb_spearman': 0.7887118959105873, 'eval_sickr_spearman': 0.7205482224752361, 'eval_avg_sts': 0.7546300591929117, 'epoch': 0.8}\n","{'loss': 0.6349, 'learning_rate': 4.706666666666667e-05, 'epoch': 0.88}\n","{'eval_stsb_spearman': 0.8022546792659211, 'eval_sickr_spearman': 0.7504832221977282, 'eval_avg_sts': 0.7763689507318247, 'epoch': 0.88}\n","{'loss': 0.5834, 'learning_rate': 4.6800000000000006e-05, 'epoch': 0.96}\n","{'eval_stsb_spearman': 0.8024051028571407, 'eval_sickr_spearman': 0.7447744856363014, 'eval_avg_sts': 0.7735897942467211, 'epoch': 0.96}\n","{'loss': 0.4519, 'learning_rate': 4.653333333333334e-05, 'epoch': 1.04}\n","{'eval_stsb_spearman': 0.8061207333587852, 'eval_sickr_spearman': 0.7539410292213594, 'eval_avg_sts': 0.7800308812900723, 'epoch': 1.04}\n","{'loss': 0.3478, 'learning_rate': 4.626666666666667e-05, 'epoch': 1.12}\n","{'eval_stsb_spearman': 0.801434500764693, 'eval_sickr_spearman': 0.7479092354716598, 'eval_avg_sts': 0.7746718681181763, 'epoch': 1.12}\n","{'loss': 0.3504, 'learning_rate': 4.600000000000001e-05, 'epoch': 1.2}\n","{'eval_stsb_spearman': 0.8032958294496966, 'eval_sickr_spearman': 0.7435340824416621, 'eval_avg_sts': 0.7734149559456793, 'epoch': 1.2}\n","{'loss': 0.35, 'learning_rate': 4.573333333333333e-05, 'epoch': 1.28}\n","{'eval_stsb_spearman': 0.8044764726121759, 'eval_sickr_spearman': 0.74173214764011, 'eval_avg_sts': 0.773104310126143, 'epoch': 1.28}\n","{'loss': 0.3449, 'learning_rate': 4.546666666666667e-05, 'epoch': 1.36}\n","{'eval_stsb_spearman': 0.8017129066505265, 'eval_sickr_spearman': 0.737684999001833, 'eval_avg_sts': 0.7696989528261797, 'epoch': 1.36}\n","{'loss': 0.3235, 'learning_rate': 4.52e-05, 'epoch': 1.44}\n","{'eval_stsb_spearman': 0.8005909243824626, 'eval_sickr_spearman': 0.7285940083393372, 'eval_avg_sts': 0.7645924663608998, 'epoch': 1.44}\n","{'loss': 0.3317, 'learning_rate': 4.493333333333333e-05, 'epoch': 1.52}\n","{'eval_stsb_spearman': 0.79985892031858, 'eval_sickr_spearman': 0.7332056184817147, 'eval_avg_sts': 0.7665322694001473, 'epoch': 1.52}\n","{'loss': 0.323, 'learning_rate': 4.466666666666667e-05, 'epoch': 1.6}\n","{'eval_stsb_spearman': 0.7959431026696131, 'eval_sickr_spearman': 0.7036154340364467, 'eval_avg_sts': 0.7497792683530299, 'epoch': 1.6}\n","{'loss': 0.3064, 'learning_rate': 4.44e-05, 'epoch': 1.68}\n","{'eval_stsb_spearman': 0.7977108174126637, 'eval_sickr_spearman': 0.7238388332347612, 'eval_avg_sts': 0.7607748253237124, 'epoch': 1.68}\n","{'loss': 0.3089, 'learning_rate': 4.413333333333334e-05, 'epoch': 1.76}\n","{'eval_stsb_spearman': 0.7909056821201015, 'eval_sickr_spearman': 0.7113291328652048, 'eval_avg_sts': 0.7511174074926532, 'epoch': 1.76}\n","{'loss': 0.282, 'learning_rate': 4.3866666666666665e-05, 'epoch': 1.84}\n","{'eval_stsb_spearman': 0.7909950024663605, 'eval_sickr_spearman': 0.7139092195411559, 'eval_avg_sts': 0.7524521110037582, 'epoch': 1.84}\n","{'loss': 0.2711, 'learning_rate': 4.36e-05, 'epoch': 1.92}\n","{'eval_stsb_spearman': 0.802844083586742, 'eval_sickr_spearman': 0.7406842531000346, 'eval_avg_sts': 0.7717641683433882, 'epoch': 1.92}\n","{'loss': 0.2746, 'learning_rate': 4.3333333333333334e-05, 'epoch': 2.0}\n","{'eval_stsb_spearman': 0.7936927238924033, 'eval_sickr_spearman': 0.7387688208057841, 'eval_avg_sts': 0.7662307723490938, 'epoch': 2.0}\n","{'eval_stsb_spearman': 0.7936927238924033, 'eval_sickr_spearman': 0.7387688208057841, 'eval_avg_sts': 0.7662307723490938, 'epoch': 2.0}\n","{'loss': 0.1708, 'learning_rate': 4.3066666666666665e-05, 'epoch': 2.08}\n","{'eval_stsb_spearman': 0.805270547892566, 'eval_sickr_spearman': 0.7376271695557016, 'eval_avg_sts': 0.7714488587241338, 'epoch': 2.08}\n","{'loss': 0.1699, 'learning_rate': 4.2800000000000004e-05, 'epoch': 2.16}\n","{'eval_stsb_spearman': 0.8033369202253481, 'eval_sickr_spearman': 0.7413361312087527, 'eval_avg_sts': 0.7723365257170505, 'epoch': 2.16}\n","{'loss': 0.1813, 'learning_rate': 4.2533333333333335e-05, 'epoch': 2.24}\n","{'eval_stsb_spearman': 0.7973482612935635, 'eval_sickr_spearman': 0.7309779840281165, 'eval_avg_sts': 0.7641631226608401, 'epoch': 2.24}\n","{'loss': 0.1794, 'learning_rate': 4.226666666666667e-05, 'epoch': 2.32}\n","{'eval_stsb_spearman': 0.7933535030177341, 'eval_sickr_spearman': 0.7345428043457518, 'eval_avg_sts': 0.763948153681743, 'epoch': 2.32}\n","{'loss': 0.1782, 'learning_rate': 4.2e-05, 'epoch': 2.4}\n","{'eval_stsb_spearman': 0.7962908299597766, 'eval_sickr_spearman': 0.7351854604829937, 'eval_avg_sts': 0.7657381452213852, 'epoch': 2.4}\n","{'loss': 0.1834, 'learning_rate': 4.1733333333333336e-05, 'epoch': 2.48}\n","{'eval_stsb_spearman': 0.8022831597125966, 'eval_sickr_spearman': 0.7381257323886293, 'eval_avg_sts': 0.770204446050613, 'epoch': 2.48}\n","{'loss': 0.177, 'learning_rate': 4.146666666666667e-05, 'epoch': 2.56}\n","{'eval_stsb_spearman': 0.8038866259451177, 'eval_sickr_spearman': 0.7342368942606924, 'eval_avg_sts': 0.7690617601029051, 'epoch': 2.56}\n","{'loss': 0.1668, 'learning_rate': 4.12e-05, 'epoch': 2.64}\n","{'eval_stsb_spearman': 0.805611101508066, 'eval_sickr_spearman': 0.7271073016565234, 'eval_avg_sts': 0.7663592015822946, 'epoch': 2.64}\n","{'loss': 0.1746, 'learning_rate': 4.093333333333334e-05, 'epoch': 2.72}\n","{'eval_stsb_spearman': 0.797964783070797, 'eval_sickr_spearman': 0.7310068507200808, 'eval_avg_sts': 0.7644858168954389, 'epoch': 2.72}\n","{'loss': 0.1741, 'learning_rate': 4.066666666666667e-05, 'epoch': 2.8}\n","{'eval_stsb_spearman': 0.7918743838553675, 'eval_sickr_spearman': 0.7338204646112241, 'eval_avg_sts': 0.7628474242332958, 'epoch': 2.8}\n","{'loss': 0.156, 'learning_rate': 4.0400000000000006e-05, 'epoch': 2.88}\n","{'eval_stsb_spearman': 0.7988682908109518, 'eval_sickr_spearman': 0.7336509148231475, 'eval_avg_sts': 0.7662596028170496, 'epoch': 2.88}\n","{'loss': 0.1568, 'learning_rate': 4.013333333333333e-05, 'epoch': 2.96}\n","{'eval_stsb_spearman': 0.7982531866437972, 'eval_sickr_spearman': 0.7218564455851059, 'eval_avg_sts': 0.7600548161144516, 'epoch': 2.96}\n","{'loss': 0.1308, 'learning_rate': 3.986666666666667e-05, 'epoch': 3.04}\n","{'eval_stsb_spearman': 0.7990431147748607, 'eval_sickr_spearman': 0.722547901321409, 'eval_avg_sts': 0.7607955080481348, 'epoch': 3.04}\n","{'loss': 0.1034, 'learning_rate': 3.960000000000001e-05, 'epoch': 3.12}\n","{'eval_stsb_spearman': 0.792504381435305, 'eval_sickr_spearman': 0.7296834978132579, 'eval_avg_sts': 0.7610939396242815, 'epoch': 3.12}\n","{'loss': 0.1127, 'learning_rate': 3.933333333333333e-05, 'epoch': 3.2}\n","{'eval_stsb_spearman': 0.7921648306747668, 'eval_sickr_spearman': 0.7309942185404026, 'eval_avg_sts': 0.7615795246075847, 'epoch': 3.2}\n","{'loss': 0.1125, 'learning_rate': 3.906666666666667e-05, 'epoch': 3.28}\n","{'eval_stsb_spearman': 0.788476345548553, 'eval_sickr_spearman': 0.7323602710964039, 'eval_avg_sts': 0.7604183083224785, 'epoch': 3.28}\n","{'loss': 0.1125, 'learning_rate': 3.88e-05, 'epoch': 3.36}\n","{'eval_stsb_spearman': 0.7924832881896284, 'eval_sickr_spearman': 0.731130098526371, 'eval_avg_sts': 0.7618066933579997, 'epoch': 3.36}\n","{'loss': 0.1144, 'learning_rate': 3.853333333333334e-05, 'epoch': 3.44}\n","{'eval_stsb_spearman': 0.7923164019536103, 'eval_sickr_spearman': 0.7255853401452539, 'eval_avg_sts': 0.7589508710494322, 'epoch': 3.44}\n","{'loss': 0.1149, 'learning_rate': 3.8266666666666664e-05, 'epoch': 3.52}\n","{'eval_stsb_spearman': 0.7929239902658067, 'eval_sickr_spearman': 0.7305588166058661, 'eval_avg_sts': 0.7617414034358364, 'epoch': 3.52}\n","{'loss': 0.1138, 'learning_rate': 3.8e-05, 'epoch': 3.6}\n","{'eval_stsb_spearman': 0.7922183075799517, 'eval_sickr_spearman': 0.7214319467105959, 'eval_avg_sts': 0.7568251271452737, 'epoch': 3.6}\n","{'loss': 0.114, 'learning_rate': 3.773333333333334e-05, 'epoch': 3.68}\n","{'eval_stsb_spearman': 0.7947697132530268, 'eval_sickr_spearman': 0.7265978357635693, 'eval_avg_sts': 0.760683774508298, 'epoch': 3.68}\n","{'loss': 0.117, 'learning_rate': 3.7466666666666665e-05, 'epoch': 3.76}\n","{'eval_stsb_spearman': 0.7920002682837668, 'eval_sickr_spearman': 0.7326378908627162, 'eval_avg_sts': 0.7623190795732415, 'epoch': 3.76}\n","{'loss': 0.1004, 'learning_rate': 3.72e-05, 'epoch': 3.84}\n","{'eval_stsb_spearman': 0.7916084726400672, 'eval_sickr_spearman': 0.7336325189112965, 'eval_avg_sts': 0.7626204957756819, 'epoch': 3.84}\n","{'loss': 0.1077, 'learning_rate': 3.6933333333333334e-05, 'epoch': 3.92}\n","{'eval_stsb_spearman': 0.7932813926476852, 'eval_sickr_spearman': 0.7299849890369849, 'eval_avg_sts': 0.761633190842335, 'epoch': 3.92}\n","{'loss': 0.1141, 'learning_rate': 3.6666666666666666e-05, 'epoch': 4.0}\n","{'eval_stsb_spearman': 0.7903607778299507, 'eval_sickr_spearman': 0.7298717797308953, 'eval_avg_sts': 0.760116278780423, 'epoch': 4.0}\n","{'eval_stsb_spearman': 0.7903607778299507, 'eval_sickr_spearman': 0.7298717797308953, 'eval_avg_sts': 0.760116278780423, 'epoch': 4.0}\n","{'loss': 0.0814, 'learning_rate': 3.6400000000000004e-05, 'epoch': 4.08}\n","{'eval_stsb_spearman': 0.7887013656542194, 'eval_sickr_spearman': 0.733405619988103, 'eval_avg_sts': 0.7610534928211612, 'epoch': 4.08}\n","{'loss': 0.0851, 'learning_rate': 3.6133333333333335e-05, 'epoch': 4.16}\n","{'eval_stsb_spearman': 0.7860159972553623, 'eval_sickr_spearman': 0.7325947109025233, 'eval_avg_sts': 0.7593053540789427, 'epoch': 4.16}\n","{'loss': 0.0829, 'learning_rate': 3.586666666666667e-05, 'epoch': 4.24}\n","{'eval_stsb_spearman': 0.7847216867547543, 'eval_sickr_spearman': 0.719941733757377, 'eval_avg_sts': 0.7523317102560656, 'epoch': 4.24}\n","{'loss': 0.0872, 'learning_rate': 3.56e-05, 'epoch': 4.32}\n","{'eval_stsb_spearman': 0.7843031740107902, 'eval_sickr_spearman': 0.7218380496732552, 'eval_avg_sts': 0.7530706118420227, 'epoch': 4.32}\n","{'loss': 0.0862, 'learning_rate': 3.5333333333333336e-05, 'epoch': 4.4}\n","{'eval_stsb_spearman': 0.7896804517382794, 'eval_sickr_spearman': 0.7150141750297396, 'eval_avg_sts': 0.7523473133840095, 'epoch': 4.4}\n","{'loss': 0.0915, 'learning_rate': 3.506666666666667e-05, 'epoch': 4.48}\n","{'eval_stsb_spearman': 0.7806430323065553, 'eval_sickr_spearman': 0.724045895313061, 'eval_avg_sts': 0.7523444638098081, 'epoch': 4.48}\n","{'loss': 0.085, 'learning_rate': 3.48e-05, 'epoch': 4.56}\n","{'eval_stsb_spearman': 0.785896897529148, 'eval_sickr_spearman': 0.734676474901054, 'eval_avg_sts': 0.760286686215101, 'epoch': 4.56}\n","{'loss': 0.081, 'learning_rate': 3.453333333333334e-05, 'epoch': 4.64}\n","{'eval_stsb_spearman': 0.7944318642657254, 'eval_sickr_spearman': 0.7390112337747422, 'eval_avg_sts': 0.7667215490202338, 'epoch': 4.64}\n","{'loss': 0.0884, 'learning_rate': 3.426666666666667e-05, 'epoch': 4.72}\n","{'eval_stsb_spearman': 0.7943436649166804, 'eval_sickr_spearman': 0.7345774347698887, 'eval_avg_sts': 0.7644605498432846, 'epoch': 4.72}\n","{'loss': 0.0808, 'learning_rate': 3.4000000000000007e-05, 'epoch': 4.8}\n","{'eval_stsb_spearman': 0.793388505710929, 'eval_sickr_spearman': 0.734078967999164, 'eval_avg_sts': 0.7637337368550465, 'epoch': 4.8}\n","{'loss': 0.0809, 'learning_rate': 3.373333333333333e-05, 'epoch': 4.88}\n","{'eval_stsb_spearman': 0.7978924278582796, 'eval_sickr_spearman': 0.7376663629344751, 'eval_avg_sts': 0.7677793953963774, 'epoch': 4.88}\n","{'loss': 0.0768, 'learning_rate': 3.346666666666667e-05, 'epoch': 4.96}\n","{'eval_stsb_spearman': 0.7887470792088578, 'eval_sickr_spearman': 0.726602302656003, 'eval_avg_sts': 0.7576746909324303, 'epoch': 4.96}\n","{'loss': 0.0727, 'learning_rate': 3.32e-05, 'epoch': 5.04}\n","{'eval_stsb_spearman': 0.7930829608313662, 'eval_sickr_spearman': 0.7312039703603829, 'eval_avg_sts': 0.7621434655958745, 'epoch': 5.04}\n","{'loss': 0.0563, 'learning_rate': 3.293333333333333e-05, 'epoch': 5.12}\n","{'eval_stsb_spearman': 0.7910904242403124, 'eval_sickr_spearman': 0.7311072357220865, 'eval_avg_sts': 0.7610988299811994, 'epoch': 5.12}\n","{'loss': 0.066, 'learning_rate': 3.266666666666667e-05, 'epoch': 5.2}\n","{'eval_stsb_spearman': 0.79403282910932, 'eval_sickr_spearman': 0.7413548633383136, 'eval_avg_sts': 0.7676938462238168, 'epoch': 5.2}\n","{'loss': 0.0666, 'learning_rate': 3.24e-05, 'epoch': 5.28}\n","{'eval_stsb_spearman': 0.789152846392436, 'eval_sickr_spearman': 0.7332081160989895, 'eval_avg_sts': 0.7611804812457128, 'epoch': 5.28}\n","{'loss': 0.0701, 'learning_rate': 3.213333333333334e-05, 'epoch': 5.36}\n","{'eval_stsb_spearman': 0.7827393455308304, 'eval_sickr_spearman': 0.7205264163551832, 'eval_avg_sts': 0.7516328809430068, 'epoch': 5.36}\n","{'loss': 0.0676, 'learning_rate': 3.1866666666666664e-05, 'epoch': 5.44}\n","{'eval_stsb_spearman': 0.7924331724967245, 'eval_sickr_spearman': 0.7318278463369624, 'eval_avg_sts': 0.7621305094168435, 'epoch': 5.44}\n","{'loss': 0.0665, 'learning_rate': 3.16e-05, 'epoch': 5.52}\n","{'eval_stsb_spearman': 0.7949152489405218, 'eval_sickr_spearman': 0.7321653608867681, 'eval_avg_sts': 0.7635403049136449, 'epoch': 5.52}\n","{'loss': 0.0719, 'learning_rate': 3.1333333333333334e-05, 'epoch': 5.6}\n","{'eval_stsb_spearman': 0.792081266560233, 'eval_sickr_spearman': 0.7345445334654036, 'eval_avg_sts': 0.7633129000128183, 'epoch': 5.6}\n","{'loss': 0.0655, 'learning_rate': 3.1066666666666665e-05, 'epoch': 5.68}\n","{'eval_stsb_spearman': 0.7915020302097638, 'eval_sickr_spearman': 0.724296857818075, 'eval_avg_sts': 0.7578994440139194, 'epoch': 5.68}\n","{'loss': 0.0671, 'learning_rate': 3.08e-05, 'epoch': 5.76}\n","{'eval_stsb_spearman': 0.788698133256971, 'eval_sickr_spearman': 0.7241925342657515, 'eval_avg_sts': 0.7564453337613612, 'epoch': 5.76}\n","{'loss': 0.0706, 'learning_rate': 3.0533333333333335e-05, 'epoch': 5.84}\n","{'eval_stsb_spearman': 0.7934592781861454, 'eval_sickr_spearman': 0.7211267570920581, 'eval_avg_sts': 0.7572930176391017, 'epoch': 5.84}\n","{'loss': 0.0695, 'learning_rate': 3.0266666666666666e-05, 'epoch': 5.92}\n","{'eval_stsb_spearman': 0.7854554986484138, 'eval_sickr_spearman': 0.715918792794225, 'eval_avg_sts': 0.7506871457213193, 'epoch': 5.92}\n","{'loss': 0.0641, 'learning_rate': 3e-05, 'epoch': 6.0}\n","{'eval_stsb_spearman': 0.7840160143674278, 'eval_sickr_spearman': 0.7215271443536463, 'eval_avg_sts': 0.7527715793605371, 'epoch': 6.0}\n","{'eval_stsb_spearman': 0.7840160143674278, 'eval_sickr_spearman': 0.7215271443536463, 'eval_avg_sts': 0.7527715793605371, 'epoch': 6.0}\n","{'loss': 0.0499, 'learning_rate': 2.9733333333333336e-05, 'epoch': 6.08}\n","{'eval_stsb_spearman': 0.7909703430101007, 'eval_sickr_spearman': 0.7075567221271539, 'eval_avg_sts': 0.7492635325686273, 'epoch': 6.08}\n","{'loss': 0.059, 'learning_rate': 2.946666666666667e-05, 'epoch': 6.16}\n","{'eval_stsb_spearman': 0.794272549025643, 'eval_sickr_spearman': 0.7175523305541353, 'eval_avg_sts': 0.7559124397898891, 'epoch': 6.16}\n","{'loss': 0.0556, 'learning_rate': 2.9199999999999998e-05, 'epoch': 6.24}\n","{'eval_stsb_spearman': 0.7870985923075602, 'eval_sickr_spearman': 0.7203949071994457, 'eval_avg_sts': 0.7537467497535029, 'epoch': 6.24}\n","{'loss': 0.0556, 'learning_rate': 2.8933333333333333e-05, 'epoch': 6.32}\n","{'eval_stsb_spearman': 0.7899822206295392, 'eval_sickr_spearman': 0.723310395056739, 'eval_avg_sts': 0.7566463078431391, 'epoch': 6.32}\n","{'loss': 0.0572, 'learning_rate': 2.8666666666666668e-05, 'epoch': 6.4}\n","{'eval_stsb_spearman': 0.7890966192970951, 'eval_sickr_spearman': 0.7240598723635794, 'eval_avg_sts': 0.7565782458303372, 'epoch': 6.4}\n","{'loss': 0.0578, 'learning_rate': 2.84e-05, 'epoch': 6.48}\n","{'eval_stsb_spearman': 0.7854178313626662, 'eval_sickr_spearman': 0.7247860545862221, 'eval_avg_sts': 0.7551019429744441, 'epoch': 6.48}\n","{'loss': 0.0569, 'learning_rate': 2.8133333333333334e-05, 'epoch': 6.56}\n","{'eval_stsb_spearman': 0.7887837660668833, 'eval_sickr_spearman': 0.7212630693579395, 'eval_avg_sts': 0.7550234177124113, 'epoch': 6.56}\n","{'loss': 0.0491, 'learning_rate': 2.786666666666667e-05, 'epoch': 6.64}\n","{'eval_stsb_spearman': 0.7915617580089899, 'eval_sickr_spearman': 0.7142854471587206, 'eval_avg_sts': 0.7529236025838553, 'epoch': 6.64}\n","{'loss': 0.0652, 'learning_rate': 2.7600000000000003e-05, 'epoch': 6.72}\n","{'eval_stsb_spearman': 0.7927448826759748, 'eval_sickr_spearman': 0.7030347380200599, 'eval_avg_sts': 0.7478898103480174, 'epoch': 6.72}\n","{'loss': 0.0571, 'learning_rate': 2.733333333333333e-05, 'epoch': 6.8}\n","{'eval_stsb_spearman': 0.7964489190367066, 'eval_sickr_spearman': 0.7172096766764757, 'eval_avg_sts': 0.7568292978565911, 'epoch': 6.8}\n","{'loss': 0.0545, 'learning_rate': 2.706666666666667e-05, 'epoch': 6.88}\n","{'eval_stsb_spearman': 0.7993672342153328, 'eval_sickr_spearman': 0.7203430816409939, 'eval_avg_sts': 0.7598551579281634, 'epoch': 6.88}\n","{'loss': 0.0511, 'learning_rate': 2.6800000000000004e-05, 'epoch': 6.96}\n","{'eval_stsb_spearman': 0.7944544308237594, 'eval_sickr_spearman': 0.7195294347826323, 'eval_avg_sts': 0.7569919328031959, 'epoch': 6.96}\n","{'loss': 0.051, 'learning_rate': 2.6533333333333332e-05, 'epoch': 7.04}\n","{'eval_stsb_spearman': 0.7926261779678263, 'eval_sickr_spearman': 0.7215310348728627, 'eval_avg_sts': 0.7570786064203445, 'epoch': 7.04}\n","{'loss': 0.0487, 'learning_rate': 2.6266666666666667e-05, 'epoch': 7.12}\n","{'eval_stsb_spearman': 0.7910813459422404, 'eval_sickr_spearman': 0.7213391506226176, 'eval_avg_sts': 0.756210248282429, 'epoch': 7.12}\n","{'loss': 0.0489, 'learning_rate': 2.6000000000000002e-05, 'epoch': 7.2}\n","{'eval_stsb_spearman': 0.7933247449907705, 'eval_sickr_spearman': 0.7212424159843212, 'eval_avg_sts': 0.7572835804875458, 'epoch': 7.2}\n","{'loss': 0.0507, 'learning_rate': 2.5733333333333337e-05, 'epoch': 7.28}\n","{'eval_stsb_spearman': 0.7911798502721216, 'eval_sickr_spearman': 0.7208636427183802, 'eval_avg_sts': 0.7560217464952509, 'epoch': 7.28}\n","{'loss': 0.0486, 'learning_rate': 2.5466666666666668e-05, 'epoch': 7.36}\n","{'eval_stsb_spearman': 0.7916954175398493, 'eval_sickr_spearman': 0.7248484469869902, 'eval_avg_sts': 0.7582719322634197, 'epoch': 7.36}\n","{'loss': 0.0476, 'learning_rate': 2.5200000000000003e-05, 'epoch': 7.44}\n","{'eval_stsb_spearman': 0.7857252699954019, 'eval_sickr_spearman': 0.7215972697617459, 'eval_avg_sts': 0.7536612698785738, 'epoch': 7.44}\n","{'loss': 0.0509, 'learning_rate': 2.4933333333333334e-05, 'epoch': 7.52}\n","{'eval_stsb_spearman': 0.7937123210651743, 'eval_sickr_spearman': 0.7352866620137238, 'eval_avg_sts': 0.7644994915394491, 'epoch': 7.52}\n","{'loss': 0.0497, 'learning_rate': 2.466666666666667e-05, 'epoch': 7.6}\n","{'eval_stsb_spearman': 0.7936634402485665, 'eval_sickr_spearman': 0.7292019379902394, 'eval_avg_sts': 0.761432689119403, 'epoch': 7.6}\n","{'loss': 0.0494, 'learning_rate': 2.44e-05, 'epoch': 7.68}\n","{'eval_stsb_spearman': 0.7907451517603501, 'eval_sickr_spearman': 0.7302012730867609, 'eval_avg_sts': 0.7604732124235555, 'epoch': 7.68}\n","{'loss': 0.0464, 'learning_rate': 2.4133333333333335e-05, 'epoch': 7.76}\n","{'eval_stsb_spearman': 0.7905242850600814, 'eval_sickr_spearman': 0.7165737448934351, 'eval_avg_sts': 0.7535490149767583, 'epoch': 7.76}\n","{'loss': 0.0503, 'learning_rate': 2.3866666666666666e-05, 'epoch': 7.84}\n","{'eval_stsb_spearman': 0.7911784296390458, 'eval_sickr_spearman': 0.723880908479621, 'eval_avg_sts': 0.7575296690593334, 'epoch': 7.84}\n","{'loss': 0.0447, 'learning_rate': 2.36e-05, 'epoch': 7.92}\n","{'eval_stsb_spearman': 0.7939798123527381, 'eval_sickr_spearman': 0.7256888951999544, 'eval_avg_sts': 0.7598343537763462, 'epoch': 7.92}\n","{'loss': 0.0529, 'learning_rate': 2.3333333333333336e-05, 'epoch': 8.0}\n","{'eval_stsb_spearman': 0.7910258548007919, 'eval_sickr_spearman': 0.7233376767223559, 'eval_avg_sts': 0.7571817657615739, 'epoch': 8.0}\n","{'eval_stsb_spearman': 0.7910258548007919, 'eval_sickr_spearman': 0.7233376767223559, 'eval_avg_sts': 0.7571817657615739, 'epoch': 8.0}\n","{'loss': 0.0441, 'learning_rate': 2.3066666666666667e-05, 'epoch': 8.08}\n","{'eval_stsb_spearman': 0.7848809704803575, 'eval_sickr_spearman': 0.7296902221674593, 'eval_avg_sts': 0.7572855963239085, 'epoch': 8.08}\n","{'loss': 0.0427, 'learning_rate': 2.2800000000000002e-05, 'epoch': 8.16}\n","{'eval_stsb_spearman': 0.787376773993951, 'eval_sickr_spearman': 0.728113793387159, 'eval_avg_sts': 0.7577452836905549, 'epoch': 8.16}\n","{'loss': 0.0417, 'learning_rate': 2.2533333333333333e-05, 'epoch': 8.24}\n","{'eval_stsb_spearman': 0.7879831285043903, 'eval_sickr_spearman': 0.7218438614365291, 'eval_avg_sts': 0.7549134949704597, 'epoch': 8.24}\n","{'loss': 0.0446, 'learning_rate': 2.2266666666666668e-05, 'epoch': 8.32}\n","{'eval_stsb_spearman': 0.7855069097158759, 'eval_sickr_spearman': 0.7174509368989994, 'eval_avg_sts': 0.7514789233074377, 'epoch': 8.32}\n","{'loss': 0.0431, 'learning_rate': 2.2000000000000003e-05, 'epoch': 8.4}\n","{'eval_stsb_spearman': 0.7836966522404489, 'eval_sickr_spearman': 0.7257960045561613, 'eval_avg_sts': 0.7547463283983051, 'epoch': 8.4}\n","{'loss': 0.0488, 'learning_rate': 2.1733333333333334e-05, 'epoch': 8.48}\n","{'eval_stsb_spearman': 0.7870291830070528, 'eval_sickr_spearman': 0.7140872399412481, 'eval_avg_sts': 0.7505582114741505, 'epoch': 8.48}\n","{'loss': 0.0444, 'learning_rate': 2.146666666666667e-05, 'epoch': 8.56}\n","{'eval_stsb_spearman': 0.7916494993587351, 'eval_sickr_spearman': 0.7232638529194456, 'eval_avg_sts': 0.7574566761390904, 'epoch': 8.56}\n","{'loss': 0.0468, 'learning_rate': 2.12e-05, 'epoch': 8.64}\n","{'eval_stsb_spearman': 0.7885707043434081, 'eval_sickr_spearman': 0.7164593348098096, 'eval_avg_sts': 0.7525150195766088, 'epoch': 8.64}\n","{'loss': 0.0446, 'learning_rate': 2.0933333333333335e-05, 'epoch': 8.72}\n","{'eval_stsb_spearman': 0.7847711369667724, 'eval_sickr_spearman': 0.71688551477287, 'eval_avg_sts': 0.7508283258698212, 'epoch': 8.72}\n","{'loss': 0.0406, 'learning_rate': 2.0666666666666666e-05, 'epoch': 8.8}\n","{'eval_stsb_spearman': 0.7858950879193599, 'eval_sickr_spearman': 0.7168059752688885, 'eval_avg_sts': 0.7513505315941242, 'epoch': 8.8}\n","{'loss': 0.0438, 'learning_rate': 2.04e-05, 'epoch': 8.88}\n","{'eval_stsb_spearman': 0.7901507385392798, 'eval_sickr_spearman': 0.7231379634025763, 'eval_avg_sts': 0.756644350970928, 'epoch': 8.88}\n","{'loss': 0.0454, 'learning_rate': 2.0133333333333336e-05, 'epoch': 8.96}\n","{'eval_stsb_spearman': 0.790408012737951, 'eval_sickr_spearman': 0.7189698724508783, 'eval_avg_sts': 0.7546889425944147, 'epoch': 8.96}\n","{'loss': 0.0371, 'learning_rate': 1.9866666666666667e-05, 'epoch': 9.04}\n","{'eval_stsb_spearman': 0.7909103102371704, 'eval_sickr_spearman': 0.7138550404587337, 'eval_avg_sts': 0.7523826753479521, 'epoch': 9.04}\n","{'loss': 0.039, 'learning_rate': 1.9600000000000002e-05, 'epoch': 9.12}\n","{'eval_stsb_spearman': 0.7941915302864572, 'eval_sickr_spearman': 0.7211614355472965, 'eval_avg_sts': 0.7576764829168768, 'epoch': 9.12}\n","{'loss': 0.0377, 'learning_rate': 1.9333333333333333e-05, 'epoch': 9.2}\n","{'eval_stsb_spearman': 0.7895767844070433, 'eval_sickr_spearman': 0.718559494720191, 'eval_avg_sts': 0.7540681395636171, 'epoch': 9.2}\n","{'loss': 0.039, 'learning_rate': 1.9066666666666668e-05, 'epoch': 9.28}\n","{'eval_stsb_spearman': 0.7902237403689535, 'eval_sickr_spearman': 0.7208779079555073, 'eval_avg_sts': 0.7555508241622304, 'epoch': 9.28}\n","{'loss': 0.0381, 'learning_rate': 1.88e-05, 'epoch': 9.36}\n","{'eval_stsb_spearman': 0.7858527782816582, 'eval_sickr_spearman': 0.7168378198891419, 'eval_avg_sts': 0.7513452990854, 'epoch': 9.36}\n","{'loss': 0.0421, 'learning_rate': 1.8533333333333334e-05, 'epoch': 9.44}\n","{'eval_stsb_spearman': 0.7871677667324608, 'eval_sickr_spearman': 0.7226748475225099, 'eval_avg_sts': 0.7549213071274854, 'epoch': 9.44}\n","{'loss': 0.043, 'learning_rate': 1.826666666666667e-05, 'epoch': 9.52}\n","{'eval_stsb_spearman': 0.7857345600374003, 'eval_sickr_spearman': 0.7229001133882548, 'eval_avg_sts': 0.7543173367128275, 'epoch': 9.52}\n","{'loss': 0.0467, 'learning_rate': 1.8e-05, 'epoch': 9.6}\n","{'eval_stsb_spearman': 0.7864926737404818, 'eval_sickr_spearman': 0.7192044563503021, 'eval_avg_sts': 0.752848565045392, 'epoch': 9.6}\n","{'loss': 0.0358, 'learning_rate': 1.7733333333333335e-05, 'epoch': 9.68}\n","{'eval_stsb_spearman': 0.7856690219272513, 'eval_sickr_spearman': 0.719256089784348, 'eval_avg_sts': 0.7524625558557996, 'epoch': 9.68}\n","{'loss': 0.0421, 'learning_rate': 1.7466666666666667e-05, 'epoch': 9.76}\n","{'eval_stsb_spearman': 0.7891184289206871, 'eval_sickr_spearman': 0.7283756589521995, 'eval_avg_sts': 0.7587470439364432, 'epoch': 9.76}\n","{'loss': 0.0401, 'learning_rate': 1.7199999999999998e-05, 'epoch': 9.84}\n","{'eval_stsb_spearman': 0.7867735927829176, 'eval_sickr_spearman': 0.7280244555384842, 'eval_avg_sts': 0.7573990241607009, 'epoch': 9.84}\n","{'loss': 0.0404, 'learning_rate': 1.6933333333333333e-05, 'epoch': 9.92}\n","{'eval_stsb_spearman': 0.785867947331259, 'eval_sickr_spearman': 0.7300871511897438, 'eval_avg_sts': 0.7579775492605014, 'epoch': 9.92}\n","{'loss': 0.04, 'learning_rate': 1.6666666666666667e-05, 'epoch': 10.0}\n","{'eval_stsb_spearman': 0.7860408175571664, 'eval_sickr_spearman': 0.7294233613678691, 'eval_avg_sts': 0.7577320894625177, 'epoch': 10.0}\n","{'eval_stsb_spearman': 0.7860408175571664, 'eval_sickr_spearman': 0.7294233613678691, 'eval_avg_sts': 0.7577320894625177, 'epoch': 10.0}\n","{'loss': 0.0357, 'learning_rate': 1.6400000000000002e-05, 'epoch': 10.08}\n","{'eval_stsb_spearman': 0.7896571954944928, 'eval_sickr_spearman': 0.7317668948692375, 'eval_avg_sts': 0.7607120451818652, 'epoch': 10.08}\n","{'loss': 0.0307, 'learning_rate': 1.6133333333333334e-05, 'epoch': 10.16}\n","{'eval_stsb_spearman': 0.7874950730078696, 'eval_sickr_spearman': 0.7300859023811065, 'eval_avg_sts': 0.758790487694488, 'epoch': 10.16}\n","{'loss': 0.0398, 'learning_rate': 1.586666666666667e-05, 'epoch': 10.24}\n","{'eval_stsb_spearman': 0.7895990032835669, 'eval_sickr_spearman': 0.7323486956009573, 'eval_avg_sts': 0.7609738494422621, 'epoch': 10.24}\n","{'loss': 0.0389, 'learning_rate': 1.56e-05, 'epoch': 10.32}\n","{'eval_stsb_spearman': 0.788310314483995, 'eval_sickr_spearman': 0.7326213681638215, 'eval_avg_sts': 0.7604658413239083, 'epoch': 10.32}\n","{'loss': 0.0315, 'learning_rate': 1.5333333333333334e-05, 'epoch': 10.4}\n","{'eval_stsb_spearman': 0.7944924806720821, 'eval_sickr_spearman': 0.7300521365167956, 'eval_avg_sts': 0.7622723085944388, 'epoch': 10.4}\n","{'loss': 0.0381, 'learning_rate': 1.5066666666666668e-05, 'epoch': 10.48}\n","{'eval_stsb_spearman': 0.7890686584237064, 'eval_sickr_spearman': 0.725244079169536, 'eval_avg_sts': 0.7571563687966212, 'epoch': 10.48}\n","{'loss': 0.0398, 'learning_rate': 1.48e-05, 'epoch': 10.56}\n","{'eval_stsb_spearman': 0.788728201971648, 'eval_sickr_spearman': 0.7267962522436101, 'eval_avg_sts': 0.757762227107629, 'epoch': 10.56}\n","{'loss': 0.0301, 'learning_rate': 1.4533333333333335e-05, 'epoch': 10.64}\n","{'eval_stsb_spearman': 0.7882081738441117, 'eval_sickr_spearman': 0.7329766542211592, 'eval_avg_sts': 0.7605924140326354, 'epoch': 10.64}\n","{'loss': 0.0419, 'learning_rate': 1.4266666666666667e-05, 'epoch': 10.72}\n","{'eval_stsb_spearman': 0.7869223064086782, 'eval_sickr_spearman': 0.7293523233688421, 'eval_avg_sts': 0.7581373148887602, 'epoch': 10.72}\n","{'loss': 0.0401, 'learning_rate': 1.4000000000000001e-05, 'epoch': 10.8}\n","{'eval_stsb_spearman': 0.786076170593434, 'eval_sickr_spearman': 0.7319340911333436, 'eval_avg_sts': 0.7590051308633888, 'epoch': 10.8}\n","{'loss': 0.0398, 'learning_rate': 1.3733333333333335e-05, 'epoch': 10.88}\n","{'eval_stsb_spearman': 0.7834660898039604, 'eval_sickr_spearman': 0.7245862932353411, 'eval_avg_sts': 0.7540261915196507, 'epoch': 10.88}\n","{'loss': 0.0339, 'learning_rate': 1.3466666666666666e-05, 'epoch': 10.96}\n","{'eval_stsb_spearman': 0.783592210887327, 'eval_sickr_spearman': 0.7280856951928176, 'eval_avg_sts': 0.7558389530400723, 'epoch': 10.96}\n","{'loss': 0.0357, 'learning_rate': 1.32e-05, 'epoch': 11.04}\n","{'eval_stsb_spearman': 0.7858951590937862, 'eval_sickr_spearman': 0.7272280998766402, 'eval_avg_sts': 0.7565616294852131, 'epoch': 11.04}\n","{'loss': 0.0332, 'learning_rate': 1.2933333333333334e-05, 'epoch': 11.12}\n","{'eval_stsb_spearman': 0.7858215843099806, 'eval_sickr_spearman': 0.7269695964887002, 'eval_avg_sts': 0.7563955903993405, 'epoch': 11.12}\n","{'loss': 0.0329, 'learning_rate': 1.2666666666666668e-05, 'epoch': 11.2}\n","{'eval_stsb_spearman': 0.7854699239252599, 'eval_sickr_spearman': 0.7278357413409337, 'eval_avg_sts': 0.7566528326330968, 'epoch': 11.2}\n","{'loss': 0.0326, 'learning_rate': 1.24e-05, 'epoch': 11.28}\n","{'eval_stsb_spearman': 0.7847565817965982, 'eval_sickr_spearman': 0.7309261584696648, 'eval_avg_sts': 0.7578413701331315, 'epoch': 11.28}\n","{'loss': 0.0327, 'learning_rate': 1.2133333333333335e-05, 'epoch': 11.36}\n","{'eval_stsb_spearman': 0.7886151641498146, 'eval_sickr_spearman': 0.7316752034965921, 'eval_avg_sts': 0.7601451838232034, 'epoch': 11.36}\n","{'loss': 0.0324, 'learning_rate': 1.1866666666666668e-05, 'epoch': 11.44}\n","{'eval_stsb_spearman': 0.7834208940432731, 'eval_sickr_spearman': 0.7283043807976655, 'eval_avg_sts': 0.7558626374204693, 'epoch': 11.44}\n","{'loss': 0.0304, 'learning_rate': 1.16e-05, 'epoch': 11.52}\n","{'eval_stsb_spearman': 0.7859516758455971, 'eval_sickr_spearman': 0.726452541681719, 'eval_avg_sts': 0.7562021087636581, 'epoch': 11.52}\n","{'loss': 0.0317, 'learning_rate': 1.1333333333333334e-05, 'epoch': 11.6}\n","{'eval_stsb_spearman': 0.785082772412875, 'eval_sickr_spearman': 0.7242746674492105, 'eval_avg_sts': 0.7546787199310427, 'epoch': 11.6}\n","{'loss': 0.0369, 'learning_rate': 1.1066666666666667e-05, 'epoch': 11.68}\n","{'eval_stsb_spearman': 0.7836945294631853, 'eval_sickr_spearman': 0.7257337082175961, 'eval_avg_sts': 0.7547141188403907, 'epoch': 11.68}\n","{'loss': 0.0349, 'learning_rate': 1.08e-05, 'epoch': 11.76}\n","{'eval_stsb_spearman': 0.7846159151372977, 'eval_sickr_spearman': 0.7299635191346421, 'eval_avg_sts': 0.7572897171359698, 'epoch': 11.76}\n","{'loss': 0.035, 'learning_rate': 1.0533333333333335e-05, 'epoch': 11.84}\n","{'eval_stsb_spearman': 0.7879593633634558, 'eval_sickr_spearman': 0.7332188750657116, 'eval_avg_sts': 0.7605891192145837, 'epoch': 11.84}\n","{'loss': 0.0378, 'learning_rate': 1.0266666666666668e-05, 'epoch': 11.92}\n","{'eval_stsb_spearman': 0.7870722506523943, 'eval_sickr_spearman': 0.7273344887663256, 'eval_avg_sts': 0.7572033697093599, 'epoch': 11.92}\n","{'loss': 0.0318, 'learning_rate': 1e-05, 'epoch': 12.0}\n","{'eval_stsb_spearman': 0.7868357647242784, 'eval_sickr_spearman': 0.7287733084410056, 'eval_avg_sts': 0.757804536582642, 'epoch': 12.0}\n","{'eval_stsb_spearman': 0.7868357647242784, 'eval_sickr_spearman': 0.7287733084410056, 'eval_avg_sts': 0.757804536582642, 'epoch': 12.0}\n","{'loss': 0.032, 'learning_rate': 9.733333333333334e-06, 'epoch': 12.08}\n","{'eval_stsb_spearman': 0.7879473099743654, 'eval_sickr_spearman': 0.7278971250885716, 'eval_avg_sts': 0.7579222175314685, 'epoch': 12.08}\n","{'loss': 0.0305, 'learning_rate': 9.466666666666667e-06, 'epoch': 12.16}\n","{'eval_stsb_spearman': 0.7883003119970216, 'eval_sickr_spearman': 0.7263800627496488, 'eval_avg_sts': 0.7573401873733352, 'epoch': 12.16}\n","{'loss': 0.0321, 'learning_rate': 9.2e-06, 'epoch': 12.24}\n","{'eval_stsb_spearman': 0.7881507129503648, 'eval_sickr_spearman': 0.727146398973094, 'eval_avg_sts': 0.7576485559617294, 'epoch': 12.24}\n","{'loss': 0.0313, 'learning_rate': 8.933333333333333e-06, 'epoch': 12.32}\n","{'eval_stsb_spearman': 0.7885823128923446, 'eval_sickr_spearman': 0.7248471501472515, 'eval_avg_sts': 0.7567147315197981, 'epoch': 12.32}\n","{'loss': 0.0333, 'learning_rate': 8.666666666666668e-06, 'epoch': 12.4}\n","{'eval_stsb_spearman': 0.7893463500845217, 'eval_sickr_spearman': 0.7268868869320237, 'eval_avg_sts': 0.7581166185082727, 'epoch': 12.4}\n","{'loss': 0.0326, 'learning_rate': 8.400000000000001e-06, 'epoch': 12.48}\n","{'eval_stsb_spearman': 0.7858667656446511, 'eval_sickr_spearman': 0.7248547390612787, 'eval_avg_sts': 0.7553607523529648, 'epoch': 12.48}\n","{'loss': 0.0328, 'learning_rate': 8.133333333333332e-06, 'epoch': 12.56}\n","{'eval_stsb_spearman': 0.7859837781809187, 'eval_sickr_spearman': 0.7274468815436909, 'eval_avg_sts': 0.7567153298623048, 'epoch': 12.56}\n","{'loss': 0.0312, 'learning_rate': 7.866666666666667e-06, 'epoch': 12.64}\n","{'eval_stsb_spearman': 0.7848689270697587, 'eval_sickr_spearman': 0.7267909207913503, 'eval_avg_sts': 0.7558299239305546, 'epoch': 12.64}\n","{'loss': 0.0339, 'learning_rate': 7.6e-06, 'epoch': 12.72}\n","{'eval_stsb_spearman': 0.7866882290354051, 'eval_sickr_spearman': 0.7266497573842239, 'eval_avg_sts': 0.7566689932098145, 'epoch': 12.72}\n","{'loss': 0.0288, 'learning_rate': 7.333333333333334e-06, 'epoch': 12.8}\n","{'eval_stsb_spearman': 0.7881594122446244, 'eval_sickr_spearman': 0.727826663462762, 'eval_avg_sts': 0.7579930378536932, 'epoch': 12.8}\n","{'loss': 0.0306, 'learning_rate': 7.066666666666667e-06, 'epoch': 12.88}\n","{'eval_stsb_spearman': 0.788192185587979, 'eval_sickr_spearman': 0.7261168523137681, 'eval_avg_sts': 0.7571545189508735, 'epoch': 12.88}\n","{'loss': 0.0332, 'learning_rate': 6.800000000000001e-06, 'epoch': 12.96}\n","{'eval_stsb_spearman': 0.7876006834009431, 'eval_sickr_spearman': 0.7221592816796732, 'eval_avg_sts': 0.7548799825403082, 'epoch': 12.96}\n","{'loss': 0.0267, 'learning_rate': 6.533333333333333e-06, 'epoch': 13.04}\n","{'eval_stsb_spearman': 0.7874799918469236, 'eval_sickr_spearman': 0.7210157572166347, 'eval_avg_sts': 0.7542478745317791, 'epoch': 13.04}\n","{'loss': 0.0286, 'learning_rate': 6.266666666666666e-06, 'epoch': 13.12}\n","{'eval_stsb_spearman': 0.7850000773241202, 'eval_sickr_spearman': 0.719978669674383, 'eval_avg_sts': 0.7524893734992516, 'epoch': 13.12}\n","{'loss': 0.0293, 'learning_rate': 6e-06, 'epoch': 13.2}\n","{'eval_stsb_spearman': 0.7872223539586958, 'eval_sickr_spearman': 0.7236395521948945, 'eval_avg_sts': 0.7554309530767951, 'epoch': 13.2}\n","{'loss': 0.031, 'learning_rate': 5.733333333333333e-06, 'epoch': 13.28}\n","{'eval_stsb_spearman': 0.7864206932638249, 'eval_sickr_spearman': 0.724780002667441, 'eval_avg_sts': 0.755600347965633, 'epoch': 13.28}\n","{'loss': 0.0286, 'learning_rate': 5.466666666666667e-06, 'epoch': 13.36}\n","{'eval_stsb_spearman': 0.7868725341323368, 'eval_sickr_spearman': 0.7248178992064757, 'eval_avg_sts': 0.7558452166694063, 'epoch': 13.36}\n","{'loss': 0.0313, 'learning_rate': 5.2e-06, 'epoch': 13.44}\n","{'eval_stsb_spearman': 0.786107344992172, 'eval_sickr_spearman': 0.7240429654158731, 'eval_avg_sts': 0.7550751552040226, 'epoch': 13.44}\n","{'loss': 0.0296, 'learning_rate': 4.933333333333333e-06, 'epoch': 13.52}\n","{'eval_stsb_spearman': 0.7867851639652803, 'eval_sickr_spearman': 0.7250848080371672, 'eval_avg_sts': 0.7559349860012238, 'epoch': 13.52}\n","{'loss': 0.0264, 'learning_rate': 4.666666666666667e-06, 'epoch': 13.6}\n","{'eval_stsb_spearman': 0.7865390954806616, 'eval_sickr_spearman': 0.7245648713640996, 'eval_avg_sts': 0.7555519834223806, 'epoch': 13.6}\n","{'loss': 0.0287, 'learning_rate': 4.4e-06, 'epoch': 13.68}\n","{'eval_stsb_spearman': 0.7862277216005754, 'eval_sickr_spearman': 0.7229007377925735, 'eval_avg_sts': 0.7545642296965744, 'epoch': 13.68}\n","{'loss': 0.0284, 'learning_rate': 4.133333333333333e-06, 'epoch': 13.76}\n","{'eval_stsb_spearman': 0.7862135703452706, 'eval_sickr_spearman': 0.7241115057976254, 'eval_avg_sts': 0.755162538071448, 'epoch': 13.76}\n","{'loss': 0.028, 'learning_rate': 3.866666666666667e-06, 'epoch': 13.84}\n","{'eval_stsb_spearman': 0.7862596564851843, 'eval_sickr_spearman': 0.7255729000899814, 'eval_avg_sts': 0.7559162782875828, 'epoch': 13.84}\n","{'loss': 0.0254, 'learning_rate': 3.6e-06, 'epoch': 13.92}\n","{'eval_stsb_spearman': 0.7866905155138492, 'eval_sickr_spearman': 0.7262979295661897, 'eval_avg_sts': 0.7564942225400194, 'epoch': 13.92}\n","{'loss': 0.0329, 'learning_rate': 3.3333333333333333e-06, 'epoch': 14.0}\n","{'eval_stsb_spearman': 0.7874932972059339, 'eval_sickr_spearman': 0.7272096079025865, 'eval_avg_sts': 0.7573514525542602, 'epoch': 14.0}\n","{'eval_stsb_spearman': 0.7874932972059339, 'eval_sickr_spearman': 0.7272096079025865, 'eval_avg_sts': 0.7573514525542602, 'epoch': 14.0}\n","{'loss': 0.029, 'learning_rate': 3.066666666666667e-06, 'epoch': 14.08}\n","{'eval_stsb_spearman': 0.7887307286637808, 'eval_sickr_spearman': 0.7258477820835117, 'eval_avg_sts': 0.7572892553736463, 'epoch': 14.08}\n","{'loss': 0.0265, 'learning_rate': 2.8000000000000003e-06, 'epoch': 14.16}\n","{'eval_stsb_spearman': 0.7874568790313675, 'eval_sickr_spearman': 0.7275830977473692, 'eval_avg_sts': 0.7575199883893684, 'epoch': 14.16}\n","{'loss': 0.0287, 'learning_rate': 2.5333333333333334e-06, 'epoch': 14.24}\n","{'eval_stsb_spearman': 0.7876924937729329, 'eval_sickr_spearman': 0.7282373293800578, 'eval_avg_sts': 0.7579649115764954, 'epoch': 14.24}\n","{'loss': 0.025, 'learning_rate': 2.266666666666667e-06, 'epoch': 14.32}\n","{'eval_stsb_spearman': 0.7879101629622945, 'eval_sickr_spearman': 0.7281479435002814, 'eval_avg_sts': 0.758029053231288, 'epoch': 14.32}\n","{'loss': 0.0303, 'learning_rate': 2.0000000000000003e-06, 'epoch': 14.4}\n","{'eval_stsb_spearman': 0.7881583296927586, 'eval_sickr_spearman': 0.7278996227058464, 'eval_avg_sts': 0.7580289761993024, 'epoch': 14.4}\n","{'loss': 0.0291, 'learning_rate': 1.7333333333333334e-06, 'epoch': 14.48}\n","{'eval_stsb_spearman': 0.788682901228682, 'eval_sickr_spearman': 0.7276163833006659, 'eval_avg_sts': 0.758149642264674, 'epoch': 14.48}\n","{'loss': 0.0317, 'learning_rate': 1.4666666666666667e-06, 'epoch': 14.56}\n","{'eval_stsb_spearman': 0.7885833228682354, 'eval_sickr_spearman': 0.7276051440229293, 'eval_avg_sts': 0.7580942334455824, 'epoch': 14.56}\n","{'loss': 0.0285, 'learning_rate': 1.2000000000000002e-06, 'epoch': 14.64}\n","{'eval_stsb_spearman': 0.7887505382859751, 'eval_sickr_spearman': 0.7280928998580334, 'eval_avg_sts': 0.7584217190720042, 'epoch': 14.64}\n","{'loss': 0.0287, 'learning_rate': 9.333333333333334e-07, 'epoch': 14.72}\n","{'eval_stsb_spearman': 0.7889957875653263, 'eval_sickr_spearman': 0.7281592788402208, 'eval_avg_sts': 0.7585775332027735, 'epoch': 14.72}\n","{'loss': 0.0259, 'learning_rate': 6.666666666666667e-07, 'epoch': 14.8}\n","{'eval_stsb_spearman': 0.788686178811012, 'eval_sickr_spearman': 0.7271039875105242, 'eval_avg_sts': 0.757895083160768, 'epoch': 14.8}\n","{'loss': 0.0254, 'learning_rate': 4.0000000000000003e-07, 'epoch': 14.88}\n","{'eval_stsb_spearman': 0.7887810258514716, 'eval_sickr_spearman': 0.7270039387262285, 'eval_avg_sts': 0.75789248228885, 'epoch': 14.88}\n","{'loss': 0.0288, 'learning_rate': 1.3333333333333334e-07, 'epoch': 14.96}\n","{'eval_stsb_spearman': 0.7886546645544162, 'eval_sickr_spearman': 0.7270193567097901, 'eval_avg_sts': 0.7578370106321032, 'epoch': 14.96}\n","100% 93750/93750 [9:45:58<00:00,  3.29it/s]11/24/2021 10:13:57 - INFO - simcse.trainers -   \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","11/24/2021 10:13:57 - INFO - simcse.trainers -   Loading best model from ../twiBot-similarity-15epochs-sup-simcse-bert-base-uncased (score: 0.8106360238413833).\n","[INFO|configuration_utils.py:443] 2021-11-24 10:13:57,595 >> loading configuration file ../twiBot-similarity-15epochs-sup-simcse-bert-base-uncased/config.json\n","[INFO|configuration_utils.py:481] 2021-11-24 10:13:57,596 >> Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForCL\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|modeling_utils.py:1025] 2021-11-24 10:13:57,597 >> loading weights file ../twiBot-similarity-15epochs-sup-simcse-bert-base-uncased/pytorch_model.bin\n","[INFO|modeling_utils.py:1143] 2021-11-24 10:14:00,832 >> All model checkpoint weights were used when initializing BertForCL.\n","\n","[INFO|modeling_utils.py:1152] 2021-11-24 10:14:00,832 >> All the weights of BertForCL were initialized from the model checkpoint at ../twiBot-similarity-15epochs-sup-simcse-bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForCL for predictions without further training.\n","{'train_runtime': 35162.1141, 'train_samples_per_second': 2.666, 'epoch': 15.0}\n","100% 93750/93750 [9:46:02<00:00,  2.67it/s]\n","[INFO|trainer.py:1344] 2021-11-24 10:14:00,956 >> Saving model checkpoint to ../twiBot-similarity-15epochs-sup-simcse-bert-base-uncased\n","[INFO|configuration_utils.py:300] 2021-11-24 10:14:00,964 >> Configuration saved in ../twiBot-similarity-15epochs-sup-simcse-bert-base-uncased/config.json\n","[INFO|modeling_utils.py:817] 2021-11-24 10:14:03,277 >> Model weights saved in ../twiBot-similarity-15epochs-sup-simcse-bert-base-uncased/pytorch_model.bin\n","11/24/2021 10:14:03 - INFO - __main__ -   ***** Train results *****\n","11/24/2021 10:14:03 - INFO - __main__ -     epoch = 15.0\n","11/24/2021 10:14:03 - INFO - __main__ -     train_runtime = 35162.1141\n","11/24/2021 10:14:03 - INFO - __main__ -     train_samples_per_second = 2.666\n","11/24/2021 10:14:03 - INFO - __main__ -   *** Evaluate ***\n","11/24/2021 10:14:40 - INFO - root -   Generating sentence embeddings\n","11/24/2021 10:14:54 - INFO - root -   Generated sentence embeddings\n","11/24/2021 10:14:54 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/24/2021 10:15:10 - INFO - root -   Best param found at split 1: l2reg = 0.001                 with score 80.75\n","11/24/2021 10:15:26 - INFO - root -   Best param found at split 2: l2reg = 0.001                 with score 80.1\n","11/24/2021 10:15:41 - INFO - root -   Best param found at split 3: l2reg = 0.001                 with score 80.25\n","11/24/2021 10:15:56 - INFO - root -   Best param found at split 4: l2reg = 1e-05                 with score 79.77\n","11/24/2021 10:16:12 - INFO - root -   Best param found at split 5: l2reg = 0.001                 with score 80.25\n","11/24/2021 10:16:15 - INFO - root -   Generating sentence embeddings\n","11/24/2021 10:16:19 - INFO - root -   Generated sentence embeddings\n","11/24/2021 10:16:19 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/24/2021 10:16:24 - INFO - root -   Best param found at split 1: l2reg = 1e-05                 with score 88.05\n","11/24/2021 10:16:30 - INFO - root -   Best param found at split 2: l2reg = 1e-05                 with score 87.85\n","11/24/2021 10:16:35 - INFO - root -   Best param found at split 3: l2reg = 0.0001                 with score 87.32\n","11/24/2021 10:16:41 - INFO - root -   Best param found at split 4: l2reg = 0.01                 with score 86.99\n","11/24/2021 10:16:46 - INFO - root -   Best param found at split 5: l2reg = 0.01                 with score 86.66\n","11/24/2021 10:16:49 - INFO - root -   Generating sentence embeddings\n","11/24/2021 10:17:03 - INFO - root -   Generated sentence embeddings\n","11/24/2021 10:17:03 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/24/2021 10:17:17 - INFO - root -   Best param found at split 1: l2reg = 1e-05                 with score 94.24\n","11/24/2021 10:17:36 - INFO - root -   Best param found at split 2: l2reg = 1e-05                 with score 94.96\n","11/24/2021 10:17:50 - INFO - root -   Best param found at split 3: l2reg = 1e-05                 with score 94.52\n","11/24/2021 10:18:06 - INFO - root -   Best param found at split 4: l2reg = 1e-05                 with score 94.34\n","11/24/2021 10:18:22 - INFO - root -   Best param found at split 5: l2reg = 1e-05                 with score 94.3\n","11/24/2021 10:18:24 - INFO - root -   Generating sentence embeddings\n","11/24/2021 10:18:28 - INFO - root -   Generated sentence embeddings\n","11/24/2021 10:18:28 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/24/2021 10:18:42 - INFO - root -   Best param found at split 1: l2reg = 0.0001                 with score 89.06\n","11/24/2021 10:18:57 - INFO - root -   Best param found at split 2: l2reg = 1e-05                 with score 87.81\n","11/24/2021 10:19:13 - INFO - root -   Best param found at split 3: l2reg = 1e-05                 with score 88.47\n","11/24/2021 10:19:29 - INFO - root -   Best param found at split 4: l2reg = 1e-05                 with score 87.99\n","11/24/2021 10:19:44 - INFO - root -   Best param found at split 5: l2reg = 0.0001                 with score 88.51\n","11/24/2021 10:19:48 - INFO - root -   Computing embedding for train\n","11/24/2021 10:20:35 - INFO - root -   Computed train embeddings\n","11/24/2021 10:20:35 - INFO - root -   Computing embedding for dev\n","11/24/2021 10:20:36 - INFO - root -   Computed dev embeddings\n","11/24/2021 10:20:36 - INFO - root -   Computing embedding for test\n","11/24/2021 10:20:38 - INFO - root -   Computed test embeddings\n","11/24/2021 10:20:38 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..\n","11/24/2021 10:21:04 - INFO - root -   [('reg:1e-05', 84.52), ('reg:0.0001', 84.63), ('reg:0.001', 84.29), ('reg:0.01', 82.8)]\n","11/24/2021 10:21:04 - INFO - root -   Validation : best param found is reg = 0.0001 with score             84.63\n","11/24/2021 10:21:04 - INFO - root -   Evaluating...\n","11/24/2021 10:21:11 - INFO - root -   ***** Transfer task : TREC *****\n","\n","\n","11/24/2021 10:21:16 - INFO - root -   Computed train embeddings\n","11/24/2021 10:21:16 - INFO - root -   Computed test embeddings\n","11/24/2021 10:21:16 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation\n","11/24/2021 10:21:26 - INFO - root -   [('reg:1e-05', 75.15), ('reg:0.0001', 75.04), ('reg:0.001', 73.7), ('reg:0.01', 67.44)]\n","11/24/2021 10:21:26 - INFO - root -   Cross-validation : best param found is reg = 1e-05             with score 75.15\n","11/24/2021 10:21:26 - INFO - root -   Evaluating...\n","11/24/2021 10:21:27 - INFO - root -   ***** Transfer task : MRPC *****\n","\n","\n","11/24/2021 10:21:29 - INFO - root -   Computing embedding for train\n","11/24/2021 10:21:39 - INFO - root -   Computed train embeddings\n","11/24/2021 10:21:39 - INFO - root -   Computing embedding for test\n","11/24/2021 10:21:44 - INFO - root -   Computed test embeddings\n","11/24/2021 10:21:44 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation\n","11/24/2021 10:21:51 - INFO - root -   [('reg:1e-05', 74.75), ('reg:0.0001', 73.97), ('reg:0.001', 74.95), ('reg:0.01', 74.36)]\n","11/24/2021 10:21:51 - INFO - root -   Cross-validation : best param found is reg = 0.001             with score 74.95\n","11/24/2021 10:21:51 - INFO - root -   Evaluating...\n","11/24/2021 10:21:51 - INFO - __main__ -   ***** Eval results *****\n","11/24/2021 10:21:51 - INFO - __main__ -     epoch = 15.0\n","11/24/2021 10:21:51 - INFO - __main__ -     eval_CR = 87.37\n","11/24/2021 10:21:51 - INFO - __main__ -     eval_MPQA = 88.37\n","11/24/2021 10:21:51 - INFO - __main__ -     eval_MR = 80.22\n","11/24/2021 10:21:51 - INFO - __main__ -     eval_MRPC = 74.95\n","11/24/2021 10:21:51 - INFO - __main__ -     eval_SST2 = 84.63\n","11/24/2021 10:21:51 - INFO - __main__ -     eval_SUBJ = 94.47\n","11/24/2021 10:21:51 - INFO - __main__ -     eval_TREC = 75.15\n","11/24/2021 10:21:51 - INFO - __main__ -     eval_avg_sts = 0.7746051593431715\n","11/24/2021 10:21:51 - INFO - __main__ -     eval_avg_transfer = 83.59428571428573\n","11/24/2021 10:21:51 - INFO - __main__ -     eval_sickr_spearman = 0.7385742948449597\n","11/24/2021 10:21:51 - INFO - __main__ -     eval_stsb_spearman = 0.8106360238413833\n"]}]},{"cell_type":"markdown","metadata":{"id":"alqwVnA_gm1-"},"source":["## Training with TwiBot dataset built on *similarity* - 20 epochs - GPU"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"90tBnjgRgeQv","executionInfo":{"status":"ok","timestamp":1637691015974,"user_tz":480,"elapsed":24072724,"user":{"displayName":"zeeshan ahmad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15348670853435150367"}},"outputId":"6d2e975e-2e1b-4172-80cf-37ea8dddbd04"},"source":["!cd SimCSE-main && python train.py --model_name_or_path ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased \\\n","    --train_file ../train_triplets_with_similarity_only_tweets.csv \\\n","    --output_dir ../twiBot-similarity-20epochs-sup-simcse-bert-base-uncased \\\n","    --num_train_epochs 20 \\\n","    --per_device_train_batch_size 32 \\\n","    --learning_rate 5e-5 \\\n","    --max_seq_length 32 \\\n","    --evaluation_strategy steps \\\n","    --metric_for_best_model stsb_spearman \\\n","    --load_best_model_at_end \\\n","    --overwrite_output_dir \\\n","    --temp 0.05 \\\n","    --do_train \\"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["11/23/2021 11:29:08 - INFO - __main__ -   PyTorch: setting up devices\n","11/23/2021 11:29:08 - INFO - __main__ -   Set device to CUDA\n","11/23/2021 11:29:08 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1 distributed training: False, 16-bits training: False\n","11/23/2021 11:29:08 - INFO - __main__ -   Training/evaluation parameters OurTrainingArguments(output_dir='../twiBot-similarity-20epochs-sup-simcse-bert-base-uncased', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=20.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_steps=0, logging_dir='runs/Nov23_11-29-08_84244e99f0ca', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', fp16_backend='auto', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='../twiBot-similarity-20epochs-sup-simcse-bert-base-uncased', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model='stsb_spearman', greater_is_better=True, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, eval_transfer=False)\n","Using custom data configuration default\n","Reusing dataset csv (./data/csv/default-b99d57eeab534056/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2)\n","[INFO|configuration_utils.py:443] 2021-11-23 11:29:08,627 >> loading configuration file ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased/config.json\n","[INFO|configuration_utils.py:481] 2021-11-23 11:29:08,628 >> Model config BertConfig {\n","  \"_name_or_path\": \"../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForCL\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|configuration_utils.py:443] 2021-11-23 11:29:08,629 >> loading configuration file ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased/config.json\n","[INFO|configuration_utils.py:481] 2021-11-23 11:29:08,629 >> Model config BertConfig {\n","  \"_name_or_path\": \"../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForCL\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|tokenization_utils_base.py:1685] 2021-11-23 11:29:08,629 >> Model name '../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming '../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased' is a path, a model identifier, or url to a directory containing tokenizer files.\n","[INFO|tokenization_utils_base.py:1718] 2021-11-23 11:29:08,630 >> Didn't find file ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased/tokenizer.json. We won't load it.\n","[INFO|tokenization_utils_base.py:1718] 2021-11-23 11:29:08,630 >> Didn't find file ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased/added_tokens.json. We won't load it.\n","[INFO|tokenization_utils_base.py:1764] 2021-11-23 11:29:08,631 >> loading file ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased/vocab.txt\n","[INFO|tokenization_utils_base.py:1764] 2021-11-23 11:29:08,631 >> loading file None\n","[INFO|tokenization_utils_base.py:1764] 2021-11-23 11:29:08,631 >> loading file None\n","[INFO|tokenization_utils_base.py:1764] 2021-11-23 11:29:08,631 >> loading file ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:1764] 2021-11-23 11:29:08,631 >> loading file ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased/tokenizer_config.json\n","[INFO|modeling_utils.py:1025] 2021-11-23 11:29:08,685 >> loading weights file ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased/pytorch_model.bin\n","[INFO|modeling_utils.py:1143] 2021-11-23 11:29:12,110 >> All model checkpoint weights were used when initializing BertForCL.\n","\n","[INFO|modeling_utils.py:1152] 2021-11-23 11:29:12,110 >> All the weights of BertForCL were initialized from the model checkpoint at ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForCL for predictions without further training.\n","Loading cached processed dataset at ./data/csv/default-b99d57eeab534056/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2/cache-7ce8f636a9a330c4.arrow\n","/usr/local/lib/python3.7/dist-packages/_distutils_hack/__init__.py:19: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n","  \"Distutils was imported before Setuptools. This usage is discouraged \"\n","[INFO|trainer.py:442] 2021-11-23 11:29:16,113 >> The following columns in the training set don't have a corresponding argument in `BertForCL.forward` and have been ignored: .\n","11/23/2021 11:29:17 - INFO - simcse.trainers -   ***** Running training *****\n","11/23/2021 11:29:17 - INFO - simcse.trainers -     Num examples = 200000\n","11/23/2021 11:29:17 - INFO - simcse.trainers -     Num Epochs = 20\n","11/23/2021 11:29:17 - INFO - simcse.trainers -     Instantaneous batch size per device = 32\n","11/23/2021 11:29:17 - INFO - simcse.trainers -     Total train batch size (w. parallel, distributed & accumulation) = 32\n","11/23/2021 11:29:17 - INFO - simcse.trainers -     Gradient Accumulation steps = 1\n","11/23/2021 11:29:17 - INFO - simcse.trainers -     Total optimization steps = 125000\n","11/23/2021 11:29:17 - INFO - simcse.trainers -     Continuing training from checkpoint, will skip to saved global_step\n","11/23/2021 11:29:17 - INFO - simcse.trainers -     Continuing training from epoch 10\n","11/23/2021 11:29:17 - INFO - simcse.trainers -     Continuing training from global step 62500\n","11/23/2021 11:29:17 - INFO - simcse.trainers -     Will skip the first 10 epochs then the first 0 batches in the first epoch.\n","{'loss': 0.0041, 'learning_rate': 4.82e-05, 'epoch': 10.08}\n","{'eval_stsb_spearman': 0.7954904877711526, 'eval_sickr_spearman': 0.7527474083195209, 'eval_avg_sts': 0.7741189480453368, 'epoch': 10.08}\n","{'loss': 0.5201, 'learning_rate': 4.8e-05, 'epoch': 10.16}\n","{'eval_stsb_spearman': 0.7952060071480361, 'eval_sickr_spearman': 0.7447929776103551, 'eval_avg_sts': 0.7699994923791956, 'epoch': 10.16}\n","{'loss': 0.5134, 'learning_rate': 4.78e-05, 'epoch': 10.24}\n","{'eval_stsb_spearman': 0.7973417274812311, 'eval_sickr_spearman': 0.7411788773826443, 'eval_avg_sts': 0.7692603024319378, 'epoch': 10.24}\n","{'loss': 0.5051, 'learning_rate': 4.76e-05, 'epoch': 10.32}\n","{'eval_stsb_spearman': 0.8048994764624384, 'eval_sickr_spearman': 0.7564031034810771, 'eval_avg_sts': 0.7806512899717577, 'epoch': 10.32}\n","{'loss': 0.4833, 'learning_rate': 4.74e-05, 'epoch': 10.4}\n","{'eval_stsb_spearman': 0.8030330427917098, 'eval_sickr_spearman': 0.7360253803538421, 'eval_avg_sts': 0.769529211572776, 'epoch': 10.4}\n","{'loss': 0.4785, 'learning_rate': 4.72e-05, 'epoch': 10.48}\n","{'eval_stsb_spearman': 0.8029572171166734, 'eval_sickr_spearman': 0.7513831809453743, 'eval_avg_sts': 0.7771701990310238, 'epoch': 10.48}\n","{'loss': 0.4662, 'learning_rate': 4.7e-05, 'epoch': 10.56}\n","{'eval_stsb_spearman': 0.805324501666407, 'eval_sickr_spearman': 0.7422772526103311, 'eval_avg_sts': 0.7738008771383691, 'epoch': 10.56}\n","{'loss': 0.4238, 'learning_rate': 4.6800000000000006e-05, 'epoch': 10.64}\n","{'eval_stsb_spearman': 0.8027338326210749, 'eval_sickr_spearman': 0.7525267534395141, 'eval_avg_sts': 0.7776302930302945, 'epoch': 10.64}\n","{'loss': 0.4303, 'learning_rate': 4.660000000000001e-05, 'epoch': 10.72}\n","{'eval_stsb_spearman': 0.7996498251574315, 'eval_sickr_spearman': 0.7377401387062841, 'eval_avg_sts': 0.7686949819318578, 'epoch': 10.72}\n","{'loss': 0.4112, 'learning_rate': 4.64e-05, 'epoch': 10.8}\n","{'eval_stsb_spearman': 0.8058744486646595, 'eval_sickr_spearman': 0.7470787296966934, 'eval_avg_sts': 0.7764765891806764, 'epoch': 10.8}\n","{'loss': 0.391, 'learning_rate': 4.6200000000000005e-05, 'epoch': 10.88}\n","{'eval_stsb_spearman': 0.7972572647895655, 'eval_sickr_spearman': 0.7375518087575452, 'eval_avg_sts': 0.7674045367735554, 'epoch': 10.88}\n","{'loss': 0.368, 'learning_rate': 4.600000000000001e-05, 'epoch': 10.96}\n","{'eval_stsb_spearman': 0.7883672949503642, 'eval_sickr_spearman': 0.7363036725555744, 'eval_avg_sts': 0.7623354837529692, 'epoch': 10.96}\n","{'loss': 0.2826, 'learning_rate': 4.58e-05, 'epoch': 11.04}\n","{'eval_stsb_spearman': 0.8007236639758364, 'eval_sickr_spearman': 0.7450105584998699, 'eval_avg_sts': 0.7728671112378531, 'epoch': 11.04}\n","{'loss': 0.2205, 'learning_rate': 4.5600000000000004e-05, 'epoch': 11.12}\n","{'eval_stsb_spearman': 0.7961454640192294, 'eval_sickr_spearman': 0.7269412581388517, 'eval_avg_sts': 0.7615433610790405, 'epoch': 11.12}\n","{'loss': 0.2263, 'learning_rate': 4.5400000000000006e-05, 'epoch': 11.2}\n","{'eval_stsb_spearman': 0.7930227316219227, 'eval_sickr_spearman': 0.7203277116885336, 'eval_avg_sts': 0.7566752216552282, 'epoch': 11.2}\n","{'loss': 0.228, 'learning_rate': 4.52e-05, 'epoch': 11.28}\n","{'eval_stsb_spearman': 0.7954223709935246, 'eval_sickr_spearman': 0.7347824315108266, 'eval_avg_sts': 0.7651024012521757, 'epoch': 11.28}\n","{'loss': 0.2276, 'learning_rate': 4.5e-05, 'epoch': 11.36}\n","{'eval_stsb_spearman': 0.7934974152231064, 'eval_sickr_spearman': 0.7339135488858111, 'eval_avg_sts': 0.7637054820544587, 'epoch': 11.36}\n","{'loss': 0.2244, 'learning_rate': 4.4800000000000005e-05, 'epoch': 11.44}\n","{'eval_stsb_spearman': 0.7977918388208904, 'eval_sickr_spearman': 0.7384789531086051, 'eval_avg_sts': 0.7681353959647478, 'epoch': 11.44}\n","{'loss': 0.2184, 'learning_rate': 4.46e-05, 'epoch': 11.52}\n","{'eval_stsb_spearman': 0.8033050323030144, 'eval_sickr_spearman': 0.7441826944354825, 'eval_avg_sts': 0.7737438633692484, 'epoch': 11.52}\n","{'loss': 0.2146, 'learning_rate': 4.44e-05, 'epoch': 11.6}\n","{'eval_stsb_spearman': 0.8022658625476501, 'eval_sickr_spearman': 0.7376370159314963, 'eval_avg_sts': 0.7699514392395732, 'epoch': 11.6}\n","{'loss': 0.2194, 'learning_rate': 4.4200000000000004e-05, 'epoch': 11.68}\n","{'eval_stsb_spearman': 0.8001839625362469, 'eval_sickr_spearman': 0.7389113771148524, 'eval_avg_sts': 0.7695476698255497, 'epoch': 11.68}\n","{'loss': 0.2154, 'learning_rate': 4.4000000000000006e-05, 'epoch': 11.76}\n","{'eval_stsb_spearman': 0.8032341995139815, 'eval_sickr_spearman': 0.7438643923262521, 'eval_avg_sts': 0.7735492959201168, 'epoch': 11.76}\n","{'loss': 0.2045, 'learning_rate': 4.38e-05, 'epoch': 11.84}\n","{'eval_stsb_spearman': 0.801760031950842, 'eval_sickr_spearman': 0.7520102750057501, 'eval_avg_sts': 0.7768851534782961, 'epoch': 11.84}\n","{'loss': 0.1996, 'learning_rate': 4.36e-05, 'epoch': 11.92}\n","{'eval_stsb_spearman': 0.802013510060556, 'eval_sickr_spearman': 0.7472027940317081, 'eval_avg_sts': 0.7746081520461321, 'epoch': 11.92}\n","{'loss': 0.1894, 'learning_rate': 4.3400000000000005e-05, 'epoch': 12.0}\n","{'eval_stsb_spearman': 0.8010014826726533, 'eval_sickr_spearman': 0.7500856207400236, 'eval_avg_sts': 0.7755435517063385, 'epoch': 12.0}\n","{'eval_stsb_spearman': 0.8010014826726533, 'eval_sickr_spearman': 0.7500856207400236, 'eval_avg_sts': 0.7755435517063385, 'epoch': 12.0}\n","{'loss': 0.1315, 'learning_rate': 4.32e-05, 'epoch': 12.08}\n","{'eval_stsb_spearman': 0.8042495710354475, 'eval_sickr_spearman': 0.7421633228377199, 'eval_avg_sts': 0.7732064469365837, 'epoch': 12.08}\n","{'loss': 0.1261, 'learning_rate': 4.3e-05, 'epoch': 12.16}\n","{'eval_stsb_spearman': 0.8031853756369145, 'eval_sickr_spearman': 0.732017569187643, 'eval_avg_sts': 0.7676014724122788, 'epoch': 12.16}\n","{'loss': 0.1359, 'learning_rate': 4.2800000000000004e-05, 'epoch': 12.24}\n","{'eval_stsb_spearman': 0.7938247197191544, 'eval_sickr_spearman': 0.7423775895812353, 'eval_avg_sts': 0.7681011546501948, 'epoch': 12.24}\n","{'loss': 0.1373, 'learning_rate': 4.26e-05, 'epoch': 12.32}\n","{'eval_stsb_spearman': 0.8026245834354577, 'eval_sickr_spearman': 0.7388876497507421, 'eval_avg_sts': 0.7707561165930998, 'epoch': 12.32}\n","{'loss': 0.14, 'learning_rate': 4.24e-05, 'epoch': 12.4}\n","{'eval_stsb_spearman': 0.8002556761088051, 'eval_sickr_spearman': 0.7524404895813315, 'eval_avg_sts': 0.7763480828450683, 'epoch': 12.4}\n","{'loss': 0.142, 'learning_rate': 4.22e-05, 'epoch': 12.48}\n","{'eval_stsb_spearman': 0.7974330086829341, 'eval_sickr_spearman': 0.7329992768699366, 'eval_avg_sts': 0.7652161427764353, 'epoch': 12.48}\n","{'loss': 0.1389, 'learning_rate': 4.2e-05, 'epoch': 12.56}\n","{'eval_stsb_spearman': 0.7996878508055052, 'eval_sickr_spearman': 0.727461915278441, 'eval_avg_sts': 0.7635748830419731, 'epoch': 12.56}\n","{'loss': 0.1401, 'learning_rate': 4.18e-05, 'epoch': 12.64}\n","{'eval_stsb_spearman': 0.7942569175259314, 'eval_sickr_spearman': 0.7262242498565836, 'eval_avg_sts': 0.7602405836912576, 'epoch': 12.64}\n","{'loss': 0.1412, 'learning_rate': 4.16e-05, 'epoch': 12.72}\n","{'eval_stsb_spearman': 0.8007975793293478, 'eval_sickr_spearman': 0.7363026158713427, 'eval_avg_sts': 0.7685500976003452, 'epoch': 12.72}\n","{'loss': 0.1283, 'learning_rate': 4.14e-05, 'epoch': 12.8}\n","{'eval_stsb_spearman': 0.7958244595315824, 'eval_sickr_spearman': 0.7272922213970601, 'eval_avg_sts': 0.7615583404643212, 'epoch': 12.8}\n","{'loss': 0.129, 'learning_rate': 4.12e-05, 'epoch': 12.88}\n","{'eval_stsb_spearman': 0.8081459929348837, 'eval_sickr_spearman': 0.739749135586136, 'eval_avg_sts': 0.7739475642605098, 'epoch': 12.88}\n","{'loss': 0.1297, 'learning_rate': 4.1e-05, 'epoch': 12.96}\n","{'eval_stsb_spearman': 0.7962582267344588, 'eval_sickr_spearman': 0.7246557462080206, 'eval_avg_sts': 0.7604569864712397, 'epoch': 12.96}\n","{'loss': 0.1008, 'learning_rate': 4.08e-05, 'epoch': 13.04}\n","{'eval_stsb_spearman': 0.8059408045822797, 'eval_sickr_spearman': 0.7296805198849687, 'eval_avg_sts': 0.7678106622336243, 'epoch': 13.04}\n","{'loss': 0.0941, 'learning_rate': 4.0600000000000004e-05, 'epoch': 13.12}\n","{'eval_stsb_spearman': 0.8064697426692552, 'eval_sickr_spearman': 0.7295412777218996, 'eval_avg_sts': 0.7680055101955774, 'epoch': 13.12}\n","{'loss': 0.1002, 'learning_rate': 4.0400000000000006e-05, 'epoch': 13.2}\n","{'eval_stsb_spearman': 0.8001956394121633, 'eval_sickr_spearman': 0.7333646974896778, 'eval_avg_sts': 0.7667801684509206, 'epoch': 13.2}\n","{'loss': 0.1001, 'learning_rate': 4.02e-05, 'epoch': 13.28}\n","{'eval_stsb_spearman': 0.8047220030305112, 'eval_sickr_spearman': 0.7326592166717548, 'eval_avg_sts': 0.768690609851133, 'epoch': 13.28}\n","{'loss': 0.0977, 'learning_rate': 4e-05, 'epoch': 13.36}\n","{'eval_stsb_spearman': 0.8001658041607423, 'eval_sickr_spearman': 0.7409940056732089, 'eval_avg_sts': 0.7705799049169757, 'epoch': 13.36}\n","{'loss': 0.1036, 'learning_rate': 3.9800000000000005e-05, 'epoch': 13.44}\n","{'eval_stsb_spearman': 0.804272958237034, 'eval_sickr_spearman': 0.7335967357407253, 'eval_avg_sts': 0.7689348469888797, 'epoch': 13.44}\n","{'loss': 0.1037, 'learning_rate': 3.960000000000001e-05, 'epoch': 13.52}\n","{'eval_stsb_spearman': 0.7987548654658727, 'eval_sickr_spearman': 0.7327361144651572, 'eval_avg_sts': 0.765745489965515, 'epoch': 13.52}\n","{'loss': 0.0938, 'learning_rate': 3.94e-05, 'epoch': 13.6}\n","{'eval_stsb_spearman': 0.8065529135450837, 'eval_sickr_spearman': 0.7378605046464879, 'eval_avg_sts': 0.7722067090957858, 'epoch': 13.6}\n","{'loss': 0.0959, 'learning_rate': 3.9200000000000004e-05, 'epoch': 13.68}\n","{'eval_stsb_spearman': 0.7947236089454653, 'eval_sickr_spearman': 0.7259112311685114, 'eval_avg_sts': 0.7603174200569884, 'epoch': 13.68}\n","{'loss': 0.0993, 'learning_rate': 3.9000000000000006e-05, 'epoch': 13.76}\n","{'eval_stsb_spearman': 0.7945286170014488, 'eval_sickr_spearman': 0.7359502116800913, 'eval_avg_sts': 0.7652394143407701, 'epoch': 13.76}\n","{'loss': 0.0995, 'learning_rate': 3.88e-05, 'epoch': 13.84}\n","{'eval_stsb_spearman': 0.7938843877257403, 'eval_sickr_spearman': 0.7337012033863533, 'eval_avg_sts': 0.7637927955560468, 'epoch': 13.84}\n","{'loss': 0.0945, 'learning_rate': 3.86e-05, 'epoch': 13.92}\n","{'eval_stsb_spearman': 0.799798704263601, 'eval_sickr_spearman': 0.7363394076950445, 'eval_avg_sts': 0.7680690559793227, 'epoch': 13.92}\n","{'loss': 0.1034, 'learning_rate': 3.8400000000000005e-05, 'epoch': 14.0}\n","{'eval_stsb_spearman': 0.7924285853049509, 'eval_sickr_spearman': 0.7250109362031554, 'eval_avg_sts': 0.7587197607540531, 'epoch': 14.0}\n","{'eval_stsb_spearman': 0.7924285853049509, 'eval_sickr_spearman': 0.7250109362031554, 'eval_avg_sts': 0.7587197607540531, 'epoch': 14.0}\n","{'loss': 0.0706, 'learning_rate': 3.82e-05, 'epoch': 14.08}\n","{'eval_stsb_spearman': 0.7954327393280821, 'eval_sickr_spearman': 0.7167689913207811, 'eval_avg_sts': 0.7561008653244317, 'epoch': 14.08}\n","{'loss': 0.0718, 'learning_rate': 3.8e-05, 'epoch': 14.16}\n","{'eval_stsb_spearman': 0.7993756370669115, 'eval_sickr_spearman': 0.7242308564507586, 'eval_avg_sts': 0.761803246758835, 'epoch': 14.16}\n","{'loss': 0.0754, 'learning_rate': 3.7800000000000004e-05, 'epoch': 14.24}\n","{'eval_stsb_spearman': 0.798446285182018, 'eval_sickr_spearman': 0.7250218392631819, 'eval_avg_sts': 0.7617340622225999, 'epoch': 14.24}\n","{'loss': 0.0742, 'learning_rate': 3.76e-05, 'epoch': 14.32}\n","{'eval_stsb_spearman': 0.802189302533097, 'eval_sickr_spearman': 0.7261237687923751, 'eval_avg_sts': 0.764156535662736, 'epoch': 14.32}\n","{'loss': 0.0792, 'learning_rate': 3.74e-05, 'epoch': 14.4}\n","{'eval_stsb_spearman': 0.803931853734337, 'eval_sickr_spearman': 0.7256758787714647, 'eval_avg_sts': 0.7648038662529009, 'epoch': 14.4}\n","{'loss': 0.0796, 'learning_rate': 3.72e-05, 'epoch': 14.48}\n","{'eval_stsb_spearman': 0.8065257407557228, 'eval_sickr_spearman': 0.7191604598613847, 'eval_avg_sts': 0.7628431003085537, 'epoch': 14.48}\n","{'loss': 0.0823, 'learning_rate': 3.7e-05, 'epoch': 14.56}\n","{'eval_stsb_spearman': 0.8016899714042718, 'eval_sickr_spearman': 0.7220421338232657, 'eval_avg_sts': 0.7618660526137687, 'epoch': 14.56}\n","{'loss': 0.082, 'learning_rate': 3.68e-05, 'epoch': 14.64}\n","{'eval_stsb_spearman': 0.8001753023879293, 'eval_sickr_spearman': 0.7182387910558888, 'eval_avg_sts': 0.7592070467219091, 'epoch': 14.64}\n","{'loss': 0.0801, 'learning_rate': 3.66e-05, 'epoch': 14.72}\n","{'eval_stsb_spearman': 0.8076418306656958, 'eval_sickr_spearman': 0.7225909371882976, 'eval_avg_sts': 0.7651163839269968, 'epoch': 14.72}\n","{'loss': 0.0757, 'learning_rate': 3.6400000000000004e-05, 'epoch': 14.8}\n","{'eval_stsb_spearman': 0.8070427768720319, 'eval_sickr_spearman': 0.7189008997892131, 'eval_avg_sts': 0.7629718383306225, 'epoch': 14.8}\n","{'loss': 0.0739, 'learning_rate': 3.62e-05, 'epoch': 14.88}\n","{'eval_stsb_spearman': 0.7915549252640609, 'eval_sickr_spearman': 0.715327097655609, 'eval_avg_sts': 0.7534410114598349, 'epoch': 14.88}\n","{'loss': 0.076, 'learning_rate': 3.6e-05, 'epoch': 14.96}\n","{'eval_stsb_spearman': 0.8006705091349304, 'eval_sickr_spearman': 0.7285092814764004, 'eval_avg_sts': 0.7645898953056653, 'epoch': 14.96}\n","{'loss': 0.0673, 'learning_rate': 3.58e-05, 'epoch': 15.04}\n","{'eval_stsb_spearman': 0.8041854944787721, 'eval_sickr_spearman': 0.7312009924320937, 'eval_avg_sts': 0.7676932434554329, 'epoch': 15.04}\n","{'loss': 0.0593, 'learning_rate': 3.56e-05, 'epoch': 15.12}\n","{'eval_stsb_spearman': 0.8059410679276569, 'eval_sickr_spearman': 0.7307909028880151, 'eval_avg_sts': 0.768365985407836, 'epoch': 15.12}\n","{'loss': 0.0628, 'learning_rate': 3.54e-05, 'epoch': 15.2}\n","{'eval_stsb_spearman': 0.7935797711517539, 'eval_sickr_spearman': 0.7238266813660974, 'eval_avg_sts': 0.7587032262589257, 'epoch': 15.2}\n","{'loss': 0.0657, 'learning_rate': 3.52e-05, 'epoch': 15.28}\n","{'eval_stsb_spearman': 0.796727672606071, 'eval_sickr_spearman': 0.7292870010708864, 'eval_avg_sts': 0.7630073368384787, 'epoch': 15.28}\n","{'loss': 0.0607, 'learning_rate': 3.5e-05, 'epoch': 15.36}\n","{'eval_stsb_spearman': 0.7960348386801388, 'eval_sickr_spearman': 0.7296974748637765, 'eval_avg_sts': 0.7628661567719577, 'epoch': 15.36}\n","{'loss': 0.0637, 'learning_rate': 3.48e-05, 'epoch': 15.44}\n","{'eval_stsb_spearman': 0.7924074649983152, 'eval_sickr_spearman': 0.7286863721474026, 'eval_avg_sts': 0.7605469185728588, 'epoch': 15.44}\n","{'loss': 0.0661, 'learning_rate': 3.46e-05, 'epoch': 15.52}\n","{'eval_stsb_spearman': 0.7962866680351999, 'eval_sickr_spearman': 0.7311173702844899, 'eval_avg_sts': 0.7637020191598449, 'epoch': 15.52}\n","{'loss': 0.0699, 'learning_rate': 3.4399999999999996e-05, 'epoch': 15.6}\n","{'eval_stsb_spearman': 0.7940424084812898, 'eval_sickr_spearman': 0.7353534732758242, 'eval_avg_sts': 0.764697940878557, 'epoch': 15.6}\n","{'loss': 0.0661, 'learning_rate': 3.4200000000000005e-05, 'epoch': 15.68}\n","{'eval_stsb_spearman': 0.7999587620244925, 'eval_sickr_spearman': 0.7244174158826846, 'eval_avg_sts': 0.7621880889535886, 'epoch': 15.68}\n","{'loss': 0.0641, 'learning_rate': 3.4000000000000007e-05, 'epoch': 15.76}\n","{'eval_stsb_spearman': 0.795380543562524, 'eval_sickr_spearman': 0.719728379604789, 'eval_avg_sts': 0.7575544615836565, 'epoch': 15.76}\n","{'loss': 0.0696, 'learning_rate': 3.38e-05, 'epoch': 15.84}\n","{'eval_stsb_spearman': 0.7961465850164442, 'eval_sickr_spearman': 0.7285614912836637, 'eval_avg_sts': 0.762354038150054, 'epoch': 15.84}\n","{'loss': 0.0631, 'learning_rate': 3.3600000000000004e-05, 'epoch': 15.92}\n","{'eval_stsb_spearman': 0.7957573883109781, 'eval_sickr_spearman': 0.7239258175594656, 'eval_avg_sts': 0.7598416029352218, 'epoch': 15.92}\n","{'loss': 0.0696, 'learning_rate': 3.3400000000000005e-05, 'epoch': 16.0}\n","{'eval_stsb_spearman': 0.7934536856556006, 'eval_sickr_spearman': 0.7258908179504002, 'eval_avg_sts': 0.7596722518030004, 'epoch': 16.0}\n","{'eval_stsb_spearman': 0.7934536856556006, 'eval_sickr_spearman': 0.7258908179504002, 'eval_avg_sts': 0.7596722518030004, 'epoch': 16.0}\n","{'loss': 0.0534, 'learning_rate': 3.32e-05, 'epoch': 16.08}\n","{'eval_stsb_spearman': 0.7893313322805767, 'eval_sickr_spearman': 0.7175970955406756, 'eval_avg_sts': 0.7534642139106262, 'epoch': 16.08}\n","{'loss': 0.0508, 'learning_rate': 3.3e-05, 'epoch': 16.16}\n","{'eval_stsb_spearman': 0.7984868784464523, 'eval_sickr_spearman': 0.7262434622971589, 'eval_avg_sts': 0.7623651703718055, 'epoch': 16.16}\n","{'loss': 0.0535, 'learning_rate': 3.2800000000000004e-05, 'epoch': 16.24}\n","{'eval_stsb_spearman': 0.7978827276736494, 'eval_sickr_spearman': 0.7302124643333958, 'eval_avg_sts': 0.7640475960035227, 'epoch': 16.24}\n","{'loss': 0.0558, 'learning_rate': 3.26e-05, 'epoch': 16.32}\n","{'eval_stsb_spearman': 0.7986949141772085, 'eval_sickr_spearman': 0.7345526026904452, 'eval_avg_sts': 0.7666237584338269, 'epoch': 16.32}\n","{'loss': 0.0621, 'learning_rate': 3.24e-05, 'epoch': 16.4}\n","{'eval_stsb_spearman': 0.8013188458807107, 'eval_sickr_spearman': 0.734743334194256, 'eval_avg_sts': 0.7680310900374834, 'epoch': 16.4}\n","{'loss': 0.0679, 'learning_rate': 3.2200000000000003e-05, 'epoch': 16.48}\n","{'eval_stsb_spearman': 0.8012808145382784, 'eval_sickr_spearman': 0.7331766557275475, 'eval_avg_sts': 0.767228735132913, 'epoch': 16.48}\n","{'loss': 0.0574, 'learning_rate': 3.2000000000000005e-05, 'epoch': 16.56}\n","{'eval_stsb_spearman': 0.7979246887371133, 'eval_sickr_spearman': 0.730177803402495, 'eval_avg_sts': 0.7640512460698041, 'epoch': 16.56}\n","{'loss': 0.0557, 'learning_rate': 3.18e-05, 'epoch': 16.64}\n","{'eval_stsb_spearman': 0.7999083342323987, 'eval_sickr_spearman': 0.7294434383682702, 'eval_avg_sts': 0.7646758863003345, 'epoch': 16.64}\n","{'loss': 0.0592, 'learning_rate': 3.16e-05, 'epoch': 16.72}\n","{'eval_stsb_spearman': 0.7986860736035132, 'eval_sickr_spearman': 0.734755630156224, 'eval_avg_sts': 0.7667208518798686, 'epoch': 16.72}\n","{'loss': 0.0519, 'learning_rate': 3.1400000000000004e-05, 'epoch': 16.8}\n","{'eval_stsb_spearman': 0.798257986829417, 'eval_sickr_spearman': 0.7320438422001297, 'eval_avg_sts': 0.7651509145147734, 'epoch': 16.8}\n","{'loss': 0.0556, 'learning_rate': 3.12e-05, 'epoch': 16.88}\n","{'eval_stsb_spearman': 0.799350047370747, 'eval_sickr_spearman': 0.7255202580028053, 'eval_avg_sts': 0.7624351526867761, 'epoch': 16.88}\n","{'loss': 0.0527, 'learning_rate': 3.1e-05, 'epoch': 16.96}\n","{'eval_stsb_spearman': 0.8022683846148287, 'eval_sickr_spearman': 0.7238237034378082, 'eval_avg_sts': 0.7630460440263185, 'epoch': 16.96}\n","{'loss': 0.0506, 'learning_rate': 3.08e-05, 'epoch': 17.04}\n","{'eval_stsb_spearman': 0.7993915748003303, 'eval_sickr_spearman': 0.7276006771304955, 'eval_avg_sts': 0.7634961259654129, 'epoch': 17.04}\n","{'loss': 0.0456, 'learning_rate': 3.06e-05, 'epoch': 17.12}\n","{'eval_stsb_spearman': 0.7928801728048069, 'eval_sickr_spearman': 0.7237575646111278, 'eval_avg_sts': 0.7583188687079674, 'epoch': 17.12}\n","{'loss': 0.0525, 'learning_rate': 3.04e-05, 'epoch': 17.2}\n","{'eval_stsb_spearman': 0.7952577385004165, 'eval_sickr_spearman': 0.7290598619921854, 'eval_avg_sts': 0.7621588002463009, 'epoch': 17.2}\n","{'loss': 0.0487, 'learning_rate': 3.02e-05, 'epoch': 17.28}\n","{'eval_stsb_spearman': 0.7960551668038893, 'eval_sickr_spearman': 0.722417881129816, 'eval_avg_sts': 0.7592365239668526, 'epoch': 17.28}\n","{'loss': 0.0526, 'learning_rate': 3e-05, 'epoch': 17.36}\n","{'eval_stsb_spearman': 0.7962326704851053, 'eval_sickr_spearman': 0.7277882866127129, 'eval_avg_sts': 0.762010478548909, 'epoch': 17.36}\n","{'loss': 0.0514, 'learning_rate': 2.98e-05, 'epoch': 17.44}\n","{'eval_stsb_spearman': 0.802694942914556, 'eval_sickr_spearman': 0.7411044772065166, 'eval_avg_sts': 0.7718997100605363, 'epoch': 17.44}\n","{'loss': 0.0574, 'learning_rate': 2.96e-05, 'epoch': 17.52}\n","{'eval_stsb_spearman': 0.8023627006926849, 'eval_sickr_spearman': 0.728008653306111, 'eval_avg_sts': 0.7651856769993979, 'epoch': 17.52}\n","{'loss': 0.0498, 'learning_rate': 2.94e-05, 'epoch': 17.6}\n","{'eval_stsb_spearman': 0.7983167495055506, 'eval_sickr_spearman': 0.7386432194755235, 'eval_avg_sts': 0.768479984490537, 'epoch': 17.6}\n","{'loss': 0.0515, 'learning_rate': 2.9199999999999998e-05, 'epoch': 17.68}\n","{'eval_stsb_spearman': 0.8015415762840692, 'eval_sickr_spearman': 0.7360573210362984, 'eval_avg_sts': 0.7687994486601838, 'epoch': 17.68}\n","{'loss': 0.0516, 'learning_rate': 2.9e-05, 'epoch': 17.76}\n","{'eval_stsb_spearman': 0.7993058131753089, 'eval_sickr_spearman': 0.7404714272895624, 'eval_avg_sts': 0.7698886202324356, 'epoch': 17.76}\n","{'loss': 0.0488, 'learning_rate': 2.88e-05, 'epoch': 17.84}\n","{'eval_stsb_spearman': 0.8020834343092568, 'eval_sickr_spearman': 0.742542768539081, 'eval_avg_sts': 0.7723131014241689, 'epoch': 17.84}\n","{'loss': 0.0548, 'learning_rate': 2.86e-05, 'epoch': 17.92}\n","{'eval_stsb_spearman': 0.7979529894683625, 'eval_sickr_spearman': 0.7299910889868676, 'eval_avg_sts': 0.763972039227615, 'epoch': 17.92}\n","{'loss': 0.0533, 'learning_rate': 2.84e-05, 'epoch': 18.0}\n","{'eval_stsb_spearman': 0.7963422025891642, 'eval_sickr_spearman': 0.7259077729292078, 'eval_avg_sts': 0.761124987759186, 'epoch': 18.0}\n","{'eval_stsb_spearman': 0.7963422025891642, 'eval_sickr_spearman': 0.7259077729292078, 'eval_avg_sts': 0.761124987759186, 'epoch': 18.0}\n","{'loss': 0.0413, 'learning_rate': 2.8199999999999998e-05, 'epoch': 18.08}\n","{'eval_stsb_spearman': 0.7961871430555731, 'eval_sickr_spearman': 0.7287348355287537, 'eval_avg_sts': 0.7624609892921634, 'epoch': 18.08}\n","{'loss': 0.0486, 'learning_rate': 2.8000000000000003e-05, 'epoch': 18.16}\n","{'eval_stsb_spearman': 0.7930008561620058, 'eval_sickr_spearman': 0.7289181222118416, 'eval_avg_sts': 0.7609594891869237, 'epoch': 18.16}\n","{'loss': 0.0499, 'learning_rate': 2.7800000000000005e-05, 'epoch': 18.24}\n","{'eval_stsb_spearman': 0.7979096709331683, 'eval_sickr_spearman': 0.7348585127755044, 'eval_avg_sts': 0.7663840918543363, 'epoch': 18.24}\n","{'loss': 0.0472, 'learning_rate': 2.7600000000000003e-05, 'epoch': 18.32}\n","{'eval_stsb_spearman': 0.7927986254106077, 'eval_sickr_spearman': 0.7363663051118498, 'eval_avg_sts': 0.7645824652612287, 'epoch': 18.32}\n","{'loss': 0.0502, 'learning_rate': 2.7400000000000002e-05, 'epoch': 18.4}\n","{'eval_stsb_spearman': 0.7925900854162603, 'eval_sickr_spearman': 0.7368408523940583, 'eval_avg_sts': 0.7647154689051593, 'epoch': 18.4}\n","{'loss': 0.0433, 'learning_rate': 2.7200000000000004e-05, 'epoch': 18.48}\n","{'eval_stsb_spearman': 0.7953765588670076, 'eval_sickr_spearman': 0.7362689460692347, 'eval_avg_sts': 0.7658227524681211, 'epoch': 18.48}\n","{'loss': 0.0461, 'learning_rate': 2.7000000000000002e-05, 'epoch': 18.56}\n","{'eval_stsb_spearman': 0.7893894415632317, 'eval_sickr_spearman': 0.721636847389331, 'eval_avg_sts': 0.7555131444762813, 'epoch': 18.56}\n","{'loss': 0.0443, 'learning_rate': 2.6800000000000004e-05, 'epoch': 18.64}\n","{'eval_stsb_spearman': 0.7952262925663939, 'eval_sickr_spearman': 0.7233055919465953, 'eval_avg_sts': 0.7592659422564946, 'epoch': 18.64}\n","{'loss': 0.049, 'learning_rate': 2.6600000000000003e-05, 'epoch': 18.72}\n","{'eval_stsb_spearman': 0.7918768180207463, 'eval_sickr_spearman': 0.7265478834180736, 'eval_avg_sts': 0.75921235071941, 'epoch': 18.72}\n","{'loss': 0.0472, 'learning_rate': 2.64e-05, 'epoch': 18.8}\n","{'eval_stsb_spearman': 0.7923584962886724, 'eval_sickr_spearman': 0.7300961810368142, 'eval_avg_sts': 0.7612273386627433, 'epoch': 18.8}\n","{'loss': 0.0414, 'learning_rate': 2.6200000000000003e-05, 'epoch': 18.88}\n","{'eval_stsb_spearman': 0.7941607181713723, 'eval_sickr_spearman': 0.7267386629529857, 'eval_avg_sts': 0.760449690562179, 'epoch': 18.88}\n","{'loss': 0.0472, 'learning_rate': 2.6000000000000002e-05, 'epoch': 18.96}\n","{'eval_stsb_spearman': 0.782956820769687, 'eval_sickr_spearman': 0.7230422854485115, 'eval_avg_sts': 0.7529995531090992, 'epoch': 18.96}\n","{'loss': 0.0412, 'learning_rate': 2.58e-05, 'epoch': 19.04}\n","{'eval_stsb_spearman': 0.7951408743579798, 'eval_sickr_spearman': 0.7300274004995548, 'eval_avg_sts': 0.7625841374287673, 'epoch': 19.04}\n","{'loss': 0.04, 'learning_rate': 2.5600000000000002e-05, 'epoch': 19.12}\n","{'eval_stsb_spearman': 0.7904537643617893, 'eval_sickr_spearman': 0.7180460422458176, 'eval_avg_sts': 0.7542499033038035, 'epoch': 19.12}\n","{'loss': 0.0401, 'learning_rate': 2.54e-05, 'epoch': 19.2}\n","{'eval_stsb_spearman': 0.79384938165786, 'eval_sickr_spearman': 0.7286784470156654, 'eval_avg_sts': 0.7612639143367628, 'epoch': 19.2}\n","{'loss': 0.0434, 'learning_rate': 2.5200000000000003e-05, 'epoch': 19.28}\n","{'eval_stsb_spearman': 0.7938399990891158, 'eval_sickr_spearman': 0.7226680751372072, 'eval_avg_sts': 0.7582540371131615, 'epoch': 19.28}\n","{'loss': 0.0419, 'learning_rate': 2.5e-05, 'epoch': 19.36}\n","{'eval_stsb_spearman': 0.7922630745147208, 'eval_sickr_spearman': 0.7239730801632808, 'eval_avg_sts': 0.7581180773390008, 'epoch': 19.36}\n","{'loss': 0.0464, 'learning_rate': 2.48e-05, 'epoch': 19.44}\n","{'eval_stsb_spearman': 0.7990274101377023, 'eval_sickr_spearman': 0.726864552469855, 'eval_avg_sts': 0.7629459813037787, 'epoch': 19.44}\n","{'loss': 0.0426, 'learning_rate': 2.46e-05, 'epoch': 19.52}\n","{'eval_stsb_spearman': 0.7943392396467265, 'eval_sickr_spearman': 0.7206156101105538, 'eval_avg_sts': 0.7574774248786401, 'epoch': 19.52}\n","{'loss': 0.0441, 'learning_rate': 2.44e-05, 'epoch': 19.6}\n","{'eval_stsb_spearman': 0.7959221980331095, 'eval_sickr_spearman': 0.717836146332533, 'eval_avg_sts': 0.7568791721828212, 'epoch': 19.6}\n","{'loss': 0.0473, 'learning_rate': 2.4200000000000002e-05, 'epoch': 19.68}\n","{'eval_stsb_spearman': 0.7934678458077086, 'eval_sickr_spearman': 0.7182885993080801, 'eval_avg_sts': 0.7558782225578944, 'epoch': 19.68}\n","{'loss': 0.0462, 'learning_rate': 2.4e-05, 'epoch': 19.76}\n","{'eval_stsb_spearman': 0.7948315591978988, 'eval_sickr_spearman': 0.7154639382636062, 'eval_avg_sts': 0.7551477487307525, 'epoch': 19.76}\n","{'loss': 0.0403, 'learning_rate': 2.38e-05, 'epoch': 19.84}\n","{'eval_stsb_spearman': 0.7963633816112042, 'eval_sickr_spearman': 0.7182918173918764, 'eval_avg_sts': 0.7573275995015403, 'epoch': 19.84}\n","{'loss': 0.0457, 'learning_rate': 2.36e-05, 'epoch': 19.92}\n","{'eval_stsb_spearman': 0.7965637554147866, 'eval_sickr_spearman': 0.7272064858809929, 'eval_avg_sts': 0.7618851206478898, 'epoch': 19.92}\n","{'loss': 0.0426, 'learning_rate': 2.3400000000000003e-05, 'epoch': 20.0}\n","{'eval_stsb_spearman': 0.7966919654675647, 'eval_sickr_spearman': 0.7214382868159858, 'eval_avg_sts': 0.7590651261417752, 'epoch': 20.0}\n","{'eval_stsb_spearman': 0.7966919654675647, 'eval_sickr_spearman': 0.7214382868159858, 'eval_avg_sts': 0.7590651261417752, 'epoch': 20.0}\n","100% 125000/125000 [6:33:09<00:00,  3.27it/s]11/23/2021 18:02:26 - INFO - simcse.trainers -   \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","11/23/2021 18:02:26 - INFO - simcse.trainers -   Loading best model from ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased (score: 0.8082003150363806).\n","[INFO|configuration_utils.py:443] 2021-11-23 18:02:26,825 >> loading configuration file ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased/config.json\n","[INFO|configuration_utils.py:481] 2021-11-23 18:02:26,826 >> Model config BertConfig {\n","  \"_name_or_path\": \"../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForCL\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|modeling_utils.py:1025] 2021-11-23 18:02:26,827 >> loading weights file ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased/pytorch_model.bin\n","[INFO|modeling_utils.py:1143] 2021-11-23 18:02:30,047 >> All model checkpoint weights were used when initializing BertForCL.\n","\n","[INFO|modeling_utils.py:1152] 2021-11-23 18:02:30,047 >> All the weights of BertForCL were initialized from the model checkpoint at ../twiBot-similarity-10epochs-sup-simcse-bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForCL for predictions without further training.\n","{'train_runtime': 23592.7403, 'train_samples_per_second': 5.298, 'epoch': 20.0}\n","100% 125000/125000 [6:33:12<00:00,  5.30it/s]\n","[INFO|trainer.py:1344] 2021-11-23 18:02:30,161 >> Saving model checkpoint to ../twiBot-similarity-20epochs-sup-simcse-bert-base-uncased\n","[INFO|configuration_utils.py:300] 2021-11-23 18:02:30,169 >> Configuration saved in ../twiBot-similarity-20epochs-sup-simcse-bert-base-uncased/config.json\n","[INFO|modeling_utils.py:817] 2021-11-23 18:02:31,727 >> Model weights saved in ../twiBot-similarity-20epochs-sup-simcse-bert-base-uncased/pytorch_model.bin\n","11/23/2021 18:02:31 - INFO - __main__ -   ***** Train results *****\n","11/23/2021 18:02:31 - INFO - __main__ -     epoch = 20.0\n","11/23/2021 18:02:31 - INFO - __main__ -     train_runtime = 23592.7403\n","11/23/2021 18:02:31 - INFO - __main__ -     train_samples_per_second = 5.298\n","11/23/2021 18:02:32 - INFO - __main__ -   *** Evaluate ***\n","11/23/2021 18:03:07 - INFO - root -   Generating sentence embeddings\n","11/23/2021 18:03:22 - INFO - root -   Generated sentence embeddings\n","11/23/2021 18:03:22 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/23/2021 18:03:39 - INFO - root -   Best param found at split 1: l2reg = 1e-05                 with score 80.77\n","11/23/2021 18:03:55 - INFO - root -   Best param found at split 2: l2reg = 0.001                 with score 80.4\n","11/23/2021 18:04:10 - INFO - root -   Best param found at split 3: l2reg = 0.0001                 with score 80.18\n","11/23/2021 18:04:25 - INFO - root -   Best param found at split 4: l2reg = 1e-05                 with score 80.12\n","11/23/2021 18:04:43 - INFO - root -   Best param found at split 5: l2reg = 1e-05                 with score 80.43\n","11/23/2021 18:04:43 - INFO - root -   Generating sentence embeddings\n","11/23/2021 18:04:47 - INFO - root -   Generated sentence embeddings\n","11/23/2021 18:04:47 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/23/2021 18:04:53 - INFO - root -   Best param found at split 1: l2reg = 0.0001                 with score 88.18\n","11/23/2021 18:04:59 - INFO - root -   Best param found at split 2: l2reg = 0.001                 with score 88.28\n","11/23/2021 18:05:04 - INFO - root -   Best param found at split 3: l2reg = 0.001                 with score 87.78\n","11/23/2021 18:05:09 - INFO - root -   Best param found at split 4: l2reg = 0.01                 with score 87.25\n","11/23/2021 18:05:15 - INFO - root -   Best param found at split 5: l2reg = 0.01                 with score 87.42\n","11/23/2021 18:05:16 - INFO - root -   Generating sentence embeddings\n","11/23/2021 18:05:30 - INFO - root -   Generated sentence embeddings\n","11/23/2021 18:05:30 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/23/2021 18:05:44 - INFO - root -   Best param found at split 1: l2reg = 1e-05                 with score 94.0\n","11/23/2021 18:06:01 - INFO - root -   Best param found at split 2: l2reg = 1e-05                 with score 94.61\n","11/23/2021 18:06:17 - INFO - root -   Best param found at split 3: l2reg = 1e-05                 with score 94.52\n","11/23/2021 18:06:32 - INFO - root -   Best param found at split 4: l2reg = 0.0001                 with score 94.18\n","11/23/2021 18:06:48 - INFO - root -   Best param found at split 5: l2reg = 0.0001                 with score 94.21\n","11/23/2021 18:06:49 - INFO - root -   Generating sentence embeddings\n","11/23/2021 18:06:53 - INFO - root -   Generated sentence embeddings\n","11/23/2021 18:06:53 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/23/2021 18:07:07 - INFO - root -   Best param found at split 1: l2reg = 1e-05                 with score 88.37\n","11/23/2021 18:07:23 - INFO - root -   Best param found at split 2: l2reg = 1e-05                 with score 87.79\n","11/23/2021 18:07:41 - INFO - root -   Best param found at split 3: l2reg = 1e-05                 with score 88.46\n","11/23/2021 18:07:56 - INFO - root -   Best param found at split 4: l2reg = 0.001                 with score 87.78\n","11/23/2021 18:08:12 - INFO - root -   Best param found at split 5: l2reg = 0.001                 with score 88.26\n","11/23/2021 18:08:13 - INFO - root -   Computing embedding for train\n","11/23/2021 18:09:00 - INFO - root -   Computed train embeddings\n","11/23/2021 18:09:00 - INFO - root -   Computing embedding for dev\n","11/23/2021 18:09:01 - INFO - root -   Computed dev embeddings\n","11/23/2021 18:09:01 - INFO - root -   Computing embedding for test\n","11/23/2021 18:09:03 - INFO - root -   Computed test embeddings\n","11/23/2021 18:09:03 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..\n","11/23/2021 18:09:29 - INFO - root -   [('reg:1e-05', 84.63), ('reg:0.0001', 84.98), ('reg:0.001', 84.52), ('reg:0.01', 83.72)]\n","11/23/2021 18:09:29 - INFO - root -   Validation : best param found is reg = 0.0001 with score             84.98\n","11/23/2021 18:09:29 - INFO - root -   Evaluating...\n","11/23/2021 18:09:36 - INFO - root -   ***** Transfer task : TREC *****\n","\n","\n","11/23/2021 18:09:39 - INFO - root -   Computed train embeddings\n","11/23/2021 18:09:40 - INFO - root -   Computed test embeddings\n","11/23/2021 18:09:40 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation\n","11/23/2021 18:09:50 - INFO - root -   [('reg:1e-05', 77.71), ('reg:0.0001', 77.46), ('reg:0.001', 76.03), ('reg:0.01', 69.3)]\n","11/23/2021 18:09:50 - INFO - root -   Cross-validation : best param found is reg = 1e-05             with score 77.71\n","11/23/2021 18:09:50 - INFO - root -   Evaluating...\n","11/23/2021 18:09:50 - INFO - root -   ***** Transfer task : MRPC *****\n","\n","\n","11/23/2021 18:09:50 - INFO - root -   Computing embedding for train\n","11/23/2021 18:10:01 - INFO - root -   Computed train embeddings\n","11/23/2021 18:10:01 - INFO - root -   Computing embedding for test\n","11/23/2021 18:10:05 - INFO - root -   Computed test embeddings\n","11/23/2021 18:10:05 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation\n","11/23/2021 18:10:13 - INFO - root -   [('reg:1e-05', 74.71), ('reg:0.0001', 74.75), ('reg:0.001', 74.75), ('reg:0.01', 74.71)]\n","11/23/2021 18:10:13 - INFO - root -   Cross-validation : best param found is reg = 0.0001             with score 74.75\n","11/23/2021 18:10:13 - INFO - root -   Evaluating...\n","11/23/2021 18:10:13 - INFO - __main__ -   ***** Eval results *****\n","11/23/2021 18:10:13 - INFO - __main__ -     epoch = 20.0\n","11/23/2021 18:10:13 - INFO - __main__ -     eval_CR = 87.78\n","11/23/2021 18:10:13 - INFO - __main__ -     eval_MPQA = 88.13\n","11/23/2021 18:10:13 - INFO - __main__ -     eval_MR = 80.38\n","11/23/2021 18:10:13 - INFO - __main__ -     eval_MRPC = 74.75\n","11/23/2021 18:10:13 - INFO - __main__ -     eval_SST2 = 84.98\n","11/23/2021 18:10:13 - INFO - __main__ -     eval_SUBJ = 94.3\n","11/23/2021 18:10:13 - INFO - __main__ -     eval_TREC = 77.71\n","11/23/2021 18:10:13 - INFO - __main__ -     eval_avg_sts = 0.7780040544109015\n","11/23/2021 18:10:13 - INFO - __main__ -     eval_avg_transfer = 84.00428571428571\n","11/23/2021 18:10:13 - INFO - __main__ -     eval_sickr_spearman = 0.7478077937854225\n","11/23/2021 18:10:13 - INFO - __main__ -     eval_stsb_spearman = 0.8082003150363806\n"]}]},{"cell_type":"markdown","metadata":{"id":"ENpMrKTNxSaQ"},"source":["## Training with 360k TwiBot dataset built on *similarity* with metadata - 1 epoch"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uGFOr0ABxwq3","executionInfo":{"status":"ok","timestamp":1638022977153,"user_tz":480,"elapsed":224,"user":{"displayName":"zeeshan ahmad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15348670853435150367"}},"outputId":"35d49092-76ea-45fc-c822-d508e19e982f"},"source":["!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1ygEmNCP-_htwwx_sBJE2NdJ3Nb7aJhr3/CSCI_544_NLP_Project/Twitter_Bot_Detection/Data/Model_TwiBot_Similarity_With_Metadata_360k_Tweets\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DtNG9ZhIxdvG","executionInfo":{"status":"ok","timestamp":1638046505366,"user_tz":480,"elapsed":23333793,"user":{"displayName":"zeeshan ahmad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15348670853435150367"}},"outputId":"7eb27b2c-7be8-4214-881c-2fd57183a6a9"},"source":["!cd ../SimCSE-main && python train.py --model_name_or_path bert-base-uncased \\\n","    --train_file ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/train_all_data_triplets_with_similarity_for_simcse.csv \\\n","    --output_dir ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch \\\n","    --num_train_epochs 1 \\\n","    --per_device_train_batch_size 32 \\\n","    --learning_rate 5e-5 \\\n","    --max_seq_length 48 \\\n","    --evaluation_strategy steps \\\n","    --metric_for_best_model stsb_spearman \\\n","    --load_best_model_at_end \\\n","    --overwrite_output_dir \\\n","    --temp 0.05 \\\n","    --do_train \\"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["11/27/2021 14:26:21 - INFO - __main__ -   PyTorch: setting up devices\n","11/27/2021 14:26:21 - INFO - __main__ -   Set device to CUDA\n","11/27/2021 14:26:21 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1 distributed training: False, 16-bits training: False\n","11/27/2021 14:26:21 - INFO - __main__ -   Training/evaluation parameters OurTrainingArguments(output_dir='../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_steps=0, logging_dir='runs/Nov27_14-26-21_4febbff4fc23', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', fp16_backend='auto', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model='stsb_spearman', greater_is_better=True, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, eval_transfer=False)\n","Downloading: 5.33kB [00:00, 4.62MB/s]       \n","Using custom data configuration default\n","Downloading and preparing dataset csv/default-b5c1b8fe87996e56 (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to ./data/csv/default-b5c1b8fe87996e56/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2...\n","Dataset csv downloaded and prepared to ./data/csv/default-b5c1b8fe87996e56/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2. Subsequent calls will reuse this data.\n","[INFO|file_utils.py:1272] 2021-11-27 14:26:45,621 >> https://huggingface.co/bert-base-uncased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpwvam6m35\n","Downloading: 100% 570/570 [00:00<00:00, 654kB/s]\n","[INFO|file_utils.py:1276] 2021-11-27 14:26:45,719 >> storing https://huggingface.co/bert-base-uncased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|file_utils.py:1279] 2021-11-27 14:26:45,719 >> creating metadata file for /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|configuration_utils.py:445] 2021-11-27 14:26:45,720 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|configuration_utils.py:481] 2021-11-27 14:26:45,720 >> Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|configuration_utils.py:445] 2021-11-27 14:26:45,819 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|configuration_utils.py:481] 2021-11-27 14:26:45,820 >> Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|file_utils.py:1272] 2021-11-27 14:26:45,924 >> https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpowpxtyo9\n","Downloading: 100% 232k/232k [00:00<00:00, 4.07MB/s]\n","[INFO|file_utils.py:1276] 2021-11-27 14:26:46,100 >> storing https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","[INFO|file_utils.py:1279] 2021-11-27 14:26:46,101 >> creating metadata file for /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","[INFO|file_utils.py:1272] 2021-11-27 14:26:46,198 >> https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpi6u0ucci\n","Downloading: 100% 466k/466k [00:00<00:00, 4.77MB/s]\n","[INFO|file_utils.py:1276] 2021-11-27 14:26:46,396 >> storing https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","[INFO|file_utils.py:1279] 2021-11-27 14:26:46,396 >> creating metadata file for /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","[INFO|tokenization_utils_base.py:1766] 2021-11-27 14:26:46,397 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","[INFO|tokenization_utils_base.py:1766] 2021-11-27 14:26:46,397 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","[INFO|file_utils.py:1272] 2021-11-27 14:26:46,515 >> https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp41m0xr40\n","Downloading: 100% 440M/440M [00:11<00:00, 37.8MB/s]\n","[INFO|file_utils.py:1276] 2021-11-27 14:26:58,291 >> storing https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","[INFO|file_utils.py:1279] 2021-11-27 14:26:58,291 >> creating metadata file for /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","[INFO|modeling_utils.py:1027] 2021-11-27 14:26:58,292 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","[WARNING|modeling_utils.py:1135] 2021-11-27 14:27:02,031 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForCL: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n","- This IS expected if you are initializing BertForCL from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForCL from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[WARNING|modeling_utils.py:1146] 2021-11-27 14:27:02,031 >> Some weights of BertForCL were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['mlp.dense.weight', 'mlp.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 1440/1440 [06:23<00:00,  3.76ba/s]\n","/usr/local/lib/python3.7/dist-packages/_distutils_hack/__init__.py:19: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n","  \"Distutils was imported before Setuptools. This usage is discouraged \"\n","[INFO|trainer.py:442] 2021-11-27 14:33:40,070 >> The following columns in the training set don't have a corresponding argument in `BertForCL.forward` and have been ignored: .\n","11/27/2021 14:33:40 - INFO - simcse.trainers -   ***** Running training *****\n","11/27/2021 14:33:40 - INFO - simcse.trainers -     Num examples = 1440000\n","11/27/2021 14:33:40 - INFO - simcse.trainers -     Num Epochs = 1\n","11/27/2021 14:33:40 - INFO - simcse.trainers -     Instantaneous batch size per device = 32\n","11/27/2021 14:33:40 - INFO - simcse.trainers -     Total train batch size (w. parallel, distributed & accumulation) = 32\n","11/27/2021 14:33:40 - INFO - simcse.trainers -     Gradient Accumulation steps = 1\n","11/27/2021 14:33:40 - INFO - simcse.trainers -     Total optimization steps = 45000\n","{'loss': 0.6864, 'learning_rate': 4.9444444444444446e-05, 'epoch': 0.01}\n","{'eval_stsb_spearman': 0.7676090753162416, 'eval_sickr_spearman': 0.6825103759401343, 'eval_avg_sts': 0.7250597256281879, 'epoch': 0.01}\n","  1% 500/45000 [04:17<5:19:57,  2.32it/s][INFO|trainer.py:1344] 2021-11-27 14:37:57,641 >> Saving model checkpoint to ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch\n","[INFO|configuration_utils.py:300] 2021-11-27 14:37:57,648 >> Configuration saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/config.json\n","[INFO|modeling_utils.py:817] 2021-11-27 14:37:59,389 >> Model weights saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/pytorch_model.bin\n","{'loss': 0.5383, 'learning_rate': 4.888888888888889e-05, 'epoch': 0.02}\n","{'eval_stsb_spearman': 0.7770045248522883, 'eval_sickr_spearman': 0.7018158047277635, 'eval_avg_sts': 0.739410164790026, 'epoch': 0.02}\n","  2% 1000/45000 [08:35<5:13:29,  2.34it/s][INFO|trainer.py:1344] 2021-11-27 14:42:15,460 >> Saving model checkpoint to ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch\n","[INFO|configuration_utils.py:300] 2021-11-27 14:42:15,467 >> Configuration saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/config.json\n","[INFO|modeling_utils.py:817] 2021-11-27 14:42:17,091 >> Model weights saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/pytorch_model.bin\n","{'loss': 0.471, 'learning_rate': 4.8333333333333334e-05, 'epoch': 0.03}\n","{'eval_stsb_spearman': 0.7873339269893309, 'eval_sickr_spearman': 0.7108082355701084, 'eval_avg_sts': 0.7490710812797197, 'epoch': 0.03}\n","  3% 1500/45000 [12:53<5:11:06,  2.33it/s][INFO|trainer.py:1344] 2021-11-27 14:46:33,903 >> Saving model checkpoint to ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch\n","[INFO|configuration_utils.py:300] 2021-11-27 14:46:33,909 >> Configuration saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/config.json\n","[INFO|modeling_utils.py:817] 2021-11-27 14:46:36,653 >> Model weights saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/pytorch_model.bin\n","{'loss': 0.4244, 'learning_rate': 4.7777777777777784e-05, 'epoch': 0.04}\n","{'eval_stsb_spearman': 0.7885967285714249, 'eval_sickr_spearman': 0.7108404644391734, 'eval_avg_sts': 0.7497185965052992, 'epoch': 0.04}\n","  4% 2000/45000 [17:11<5:04:30,  2.35it/s][INFO|trainer.py:1344] 2021-11-27 14:50:51,739 >> Saving model checkpoint to ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch\n","[INFO|configuration_utils.py:300] 2021-11-27 14:50:51,745 >> Configuration saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/config.json\n","[INFO|modeling_utils.py:817] 2021-11-27 14:50:53,299 >> Model weights saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/pytorch_model.bin\n","{'loss': 0.3734, 'learning_rate': 4.722222222222222e-05, 'epoch': 0.06}\n","{'eval_stsb_spearman': 0.7960752629031671, 'eval_sickr_spearman': 0.7318676160889531, 'eval_avg_sts': 0.7639714394960602, 'epoch': 0.06}\n","  6% 2500/45000 [21:27<5:03:57,  2.33it/s][INFO|trainer.py:1344] 2021-11-27 14:55:07,564 >> Saving model checkpoint to ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch\n","[INFO|configuration_utils.py:300] 2021-11-27 14:55:07,570 >> Configuration saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/config.json\n","[INFO|modeling_utils.py:817] 2021-11-27 14:55:09,212 >> Model weights saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/pytorch_model.bin\n","{'loss': 0.3318, 'learning_rate': 4.666666666666667e-05, 'epoch': 0.07}\n","{'eval_stsb_spearman': 0.8045377271027924, 'eval_sickr_spearman': 0.7347129305070456, 'eval_avg_sts': 0.769625328804919, 'epoch': 0.07}\n","  7% 3000/45000 [25:43<4:57:43,  2.35it/s][INFO|trainer.py:1344] 2021-11-27 14:59:23,224 >> Saving model checkpoint to ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch\n","[INFO|configuration_utils.py:300] 2021-11-27 14:59:23,232 >> Configuration saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/config.json\n","[INFO|modeling_utils.py:817] 2021-11-27 14:59:24,857 >> Model weights saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/pytorch_model.bin\n","{'loss': 0.3086, 'learning_rate': 4.6111111111111115e-05, 'epoch': 0.08}\n","{'eval_stsb_spearman': 0.8120980093901299, 'eval_sickr_spearman': 0.7691367248455381, 'eval_avg_sts': 0.790617367117834, 'epoch': 0.08}\n","  8% 3500/45000 [29:59<4:58:03,  2.32it/s][INFO|trainer.py:1344] 2021-11-27 15:03:39,786 >> Saving model checkpoint to ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch\n","[INFO|configuration_utils.py:300] 2021-11-27 15:03:39,793 >> Configuration saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/config.json\n","[INFO|modeling_utils.py:817] 2021-11-27 15:03:41,598 >> Model weights saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/pytorch_model.bin\n","{'loss': 0.2879, 'learning_rate': 4.555555555555556e-05, 'epoch': 0.09}\n","{'eval_stsb_spearman': 0.8026164624334193, 'eval_sickr_spearman': 0.7657561998641207, 'eval_avg_sts': 0.78418633114877, 'epoch': 0.09}\n","{'loss': 0.2686, 'learning_rate': 4.5e-05, 'epoch': 0.1}\n","{'eval_stsb_spearman': 0.8011052094348851, 'eval_sickr_spearman': 0.7757380233649894, 'eval_avg_sts': 0.7884216163999372, 'epoch': 0.1}\n","{'loss': 0.2709, 'learning_rate': 4.4444444444444447e-05, 'epoch': 0.11}\n","{'eval_stsb_spearman': 0.8054430967701445, 'eval_sickr_spearman': 0.7621080455854904, 'eval_avg_sts': 0.7837755711778174, 'epoch': 0.11}\n","{'loss': 0.2502, 'learning_rate': 4.388888888888889e-05, 'epoch': 0.12}\n","{'eval_stsb_spearman': 0.8062464791701813, 'eval_sickr_spearman': 0.7641128157284157, 'eval_avg_sts': 0.7851796474492985, 'epoch': 0.12}\n","{'loss': 0.2476, 'learning_rate': 4.3333333333333334e-05, 'epoch': 0.13}\n","{'eval_stsb_spearman': 0.7924953938846185, 'eval_sickr_spearman': 0.7581273719916038, 'eval_avg_sts': 0.7753113829381112, 'epoch': 0.13}\n","{'loss': 0.2317, 'learning_rate': 4.277777777777778e-05, 'epoch': 0.14}\n","{'eval_stsb_spearman': 0.8060085110346383, 'eval_sickr_spearman': 0.7590370330217403, 'eval_avg_sts': 0.7825227720281893, 'epoch': 0.14}\n","{'loss': 0.2411, 'learning_rate': 4.222222222222222e-05, 'epoch': 0.16}\n","{'eval_stsb_spearman': 0.816034873816912, 'eval_sickr_spearman': 0.7784980345469276, 'eval_avg_sts': 0.7972664541819198, 'epoch': 0.16}\n"," 16% 7000/45000 [59:03<4:29:19,  2.35it/s][INFO|trainer.py:1344] 2021-11-27 15:32:43,860 >> Saving model checkpoint to ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch\n","[INFO|configuration_utils.py:300] 2021-11-27 15:32:43,866 >> Configuration saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/config.json\n","[INFO|modeling_utils.py:817] 2021-11-27 15:32:45,459 >> Model weights saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/pytorch_model.bin\n","{'loss': 0.2294, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.17}\n","{'eval_stsb_spearman': 0.805400360085847, 'eval_sickr_spearman': 0.7634831760196636, 'eval_avg_sts': 0.7844417680527553, 'epoch': 0.17}\n","{'loss': 0.2207, 'learning_rate': 4.111111111111111e-05, 'epoch': 0.18}\n","{'eval_stsb_spearman': 0.8040411856603218, 'eval_sickr_spearman': 0.7592339125065352, 'eval_avg_sts': 0.7816375490834284, 'epoch': 0.18}\n","{'loss': 0.2057, 'learning_rate': 4.055555555555556e-05, 'epoch': 0.19}\n","{'eval_stsb_spearman': 0.8026732888088483, 'eval_sickr_spearman': 0.7477507808680155, 'eval_avg_sts': 0.7752120348384319, 'epoch': 0.19}\n","{'loss': 0.2074, 'learning_rate': 4e-05, 'epoch': 0.2}\n","{'eval_stsb_spearman': 0.8052921279786138, 'eval_sickr_spearman': 0.7561053586832622, 'eval_avg_sts': 0.780698743330938, 'epoch': 0.2}\n","{'loss': 0.2029, 'learning_rate': 3.944444444444445e-05, 'epoch': 0.21}\n","{'eval_stsb_spearman': 0.7983980289210008, 'eval_sickr_spearman': 0.7597896803812756, 'eval_avg_sts': 0.7790938546511381, 'epoch': 0.21}\n","{'loss': 0.2068, 'learning_rate': 3.888888888888889e-05, 'epoch': 0.22}\n","{'eval_stsb_spearman': 0.8023247380330684, 'eval_sickr_spearman': 0.7508579308407096, 'eval_avg_sts': 0.776591334436889, 'epoch': 0.22}\n","{'loss': 0.1861, 'learning_rate': 3.8333333333333334e-05, 'epoch': 0.23}\n","{'eval_stsb_spearman': 0.8024957274747613, 'eval_sickr_spearman': 0.7634255386979379, 'eval_avg_sts': 0.7829606330863497, 'epoch': 0.23}\n","{'loss': 0.1891, 'learning_rate': 3.777777777777778e-05, 'epoch': 0.24}\n","{'eval_stsb_spearman': 0.803661632192919, 'eval_sickr_spearman': 0.7687746183717962, 'eval_avg_sts': 0.7862181252823576, 'epoch': 0.24}\n","{'loss': 0.2018, 'learning_rate': 3.722222222222222e-05, 'epoch': 0.26}\n","{'eval_stsb_spearman': 0.8099491703342565, 'eval_sickr_spearman': 0.7686068457344728, 'eval_avg_sts': 0.7892780080343647, 'epoch': 0.26}\n","{'loss': 0.1881, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.27}\n","{'eval_stsb_spearman': 0.8027723493754317, 'eval_sickr_spearman': 0.7553979566212817, 'eval_avg_sts': 0.7790851529983567, 'epoch': 0.27}\n","{'loss': 0.1928, 'learning_rate': 3.611111111111111e-05, 'epoch': 0.28}\n","{'eval_stsb_spearman': 0.8033189209270039, 'eval_sickr_spearman': 0.7678164459292072, 'eval_avg_sts': 0.7855676834281056, 'epoch': 0.28}\n","{'loss': 0.182, 'learning_rate': 3.555555555555556e-05, 'epoch': 0.29}\n","{'eval_stsb_spearman': 0.7978632136057752, 'eval_sickr_spearman': 0.7607045287703672, 'eval_avg_sts': 0.7792838711880712, 'epoch': 0.29}\n","{'loss': 0.1826, 'learning_rate': 3.5e-05, 'epoch': 0.3}\n","{'eval_stsb_spearman': 0.8033610020924797, 'eval_sickr_spearman': 0.762835188430162, 'eval_avg_sts': 0.7830980952613209, 'epoch': 0.3}\n","{'loss': 0.1778, 'learning_rate': 3.444444444444445e-05, 'epoch': 0.31}\n","{'eval_stsb_spearman': 0.8088810493206481, 'eval_sickr_spearman': 0.7722629251448405, 'eval_avg_sts': 0.7905719872327444, 'epoch': 0.31}\n","{'loss': 0.1683, 'learning_rate': 3.388888888888889e-05, 'epoch': 0.32}\n","{'eval_stsb_spearman': 0.8105792899856306, 'eval_sickr_spearman': 0.7671856534740206, 'eval_avg_sts': 0.7888824717298255, 'epoch': 0.32}\n","{'loss': 0.1719, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.33}\n","{'eval_stsb_spearman': 0.8084455134328916, 'eval_sickr_spearman': 0.7738702379233654, 'eval_avg_sts': 0.7911578756781286, 'epoch': 0.33}\n","{'loss': 0.1683, 'learning_rate': 3.277777777777778e-05, 'epoch': 0.34}\n","{'eval_stsb_spearman': 0.80443458468295, 'eval_sickr_spearman': 0.7727036105005352, 'eval_avg_sts': 0.7885690975917425, 'epoch': 0.34}\n","{'loss': 0.1701, 'learning_rate': 3.222222222222223e-05, 'epoch': 0.36}\n","{'eval_stsb_spearman': 0.8101693865086756, 'eval_sickr_spearman': 0.7710489870870937, 'eval_avg_sts': 0.7906091867978846, 'epoch': 0.36}\n","{'loss': 0.1621, 'learning_rate': 3.1666666666666666e-05, 'epoch': 0.37}\n","{'eval_stsb_spearman': 0.8094833219782758, 'eval_sickr_spearman': 0.771429345379382, 'eval_avg_sts': 0.7904563336788288, 'epoch': 0.37}\n","{'loss': 0.1627, 'learning_rate': 3.111111111111111e-05, 'epoch': 0.38}\n","{'eval_stsb_spearman': 0.8081233861577367, 'eval_sickr_spearman': 0.7663657145413704, 'eval_avg_sts': 0.7872445503495535, 'epoch': 0.38}\n","{'loss': 0.1606, 'learning_rate': 3.055555555555556e-05, 'epoch': 0.39}\n","{'eval_stsb_spearman': 0.8114353215460121, 'eval_sickr_spearman': 0.7752445037977127, 'eval_avg_sts': 0.7933399126718623, 'epoch': 0.39}\n","{'loss': 0.1512, 'learning_rate': 3e-05, 'epoch': 0.4}\n","{'eval_stsb_spearman': 0.8073318044792558, 'eval_sickr_spearman': 0.7734489091015503, 'eval_avg_sts': 0.790390356790403, 'epoch': 0.4}\n","{'loss': 0.151, 'learning_rate': 2.9444444444444448e-05, 'epoch': 0.41}\n","{'eval_stsb_spearman': 0.8107986620229474, 'eval_sickr_spearman': 0.7664014496808403, 'eval_avg_sts': 0.7886000558518939, 'epoch': 0.41}\n","{'loss': 0.1597, 'learning_rate': 2.8888888888888888e-05, 'epoch': 0.42}\n","{'eval_stsb_spearman': 0.8078919820836572, 'eval_sickr_spearman': 0.7649846282506189, 'eval_avg_sts': 0.786438305167138, 'epoch': 0.42}\n","{'loss': 0.1456, 'learning_rate': 2.8333333333333335e-05, 'epoch': 0.43}\n","{'eval_stsb_spearman': 0.8131878352109566, 'eval_sickr_spearman': 0.7693764480728157, 'eval_avg_sts': 0.7912821416418861, 'epoch': 0.43}\n","{'loss': 0.1477, 'learning_rate': 2.777777777777778e-05, 'epoch': 0.44}\n","{'eval_stsb_spearman': 0.8070966238842335, 'eval_sickr_spearman': 0.7731084646545571, 'eval_avg_sts': 0.7901025442693953, 'epoch': 0.44}\n","{'loss': 0.142, 'learning_rate': 2.7222222222222223e-05, 'epoch': 0.46}\n","{'eval_stsb_spearman': 0.8091564384711624, 'eval_sickr_spearman': 0.7706682445459937, 'eval_avg_sts': 0.789912341508578, 'epoch': 0.46}\n","{'loss': 0.1334, 'learning_rate': 2.6666666666666667e-05, 'epoch': 0.47}\n","{'eval_stsb_spearman': 0.8098732546317141, 'eval_sickr_spearman': 0.7699640125367081, 'eval_avg_sts': 0.7899186335842111, 'epoch': 0.47}\n","{'loss': 0.1448, 'learning_rate': 2.6111111111111114e-05, 'epoch': 0.48}\n","{'eval_stsb_spearman': 0.8147294743406899, 'eval_sickr_spearman': 0.7695074769175387, 'eval_avg_sts': 0.7921184756291143, 'epoch': 0.48}\n","{'loss': 0.1328, 'learning_rate': 2.5555555555555554e-05, 'epoch': 0.49}\n","{'eval_stsb_spearman': 0.8050627388564098, 'eval_sickr_spearman': 0.7690750529112915, 'eval_avg_sts': 0.7870688958838506, 'epoch': 0.49}\n","{'loss': 0.1307, 'learning_rate': 2.5e-05, 'epoch': 0.5}\n","{'eval_stsb_spearman': 0.8090496782700548, 'eval_sickr_spearman': 0.7733774868537119, 'eval_avg_sts': 0.7912135825618833, 'epoch': 0.5}\n","{'loss': 0.1281, 'learning_rate': 2.4444444444444445e-05, 'epoch': 0.51}\n","{'eval_stsb_spearman': 0.8110629255502794, 'eval_sickr_spearman': 0.7701653589139367, 'eval_avg_sts': 0.790614142232108, 'epoch': 0.51}\n","{'loss': 0.127, 'learning_rate': 2.3888888888888892e-05, 'epoch': 0.52}\n","{'eval_stsb_spearman': 0.8100671561806995, 'eval_sickr_spearman': 0.769871264479831, 'eval_avg_sts': 0.7899692103302652, 'epoch': 0.52}\n","{'loss': 0.1259, 'learning_rate': 2.3333333333333336e-05, 'epoch': 0.53}\n","{'eval_stsb_spearman': 0.8126310494068653, 'eval_sickr_spearman': 0.7734001575335906, 'eval_avg_sts': 0.7930156034702279, 'epoch': 0.53}\n","{'loss': 0.1233, 'learning_rate': 2.277777777777778e-05, 'epoch': 0.54}\n","{'eval_stsb_spearman': 0.8111050252234234, 'eval_sickr_spearman': 0.7697851447149525, 'eval_avg_sts': 0.790445084969188, 'epoch': 0.54}\n","{'loss': 0.1247, 'learning_rate': 2.2222222222222223e-05, 'epoch': 0.56}\n","{'eval_stsb_spearman': 0.80889726569467, 'eval_sickr_spearman': 0.7797061608414004, 'eval_avg_sts': 0.7943017132680352, 'epoch': 0.56}\n","{'loss': 0.1225, 'learning_rate': 2.1666666666666667e-05, 'epoch': 0.57}\n","{'eval_stsb_spearman': 0.8106777277758958, 'eval_sickr_spearman': 0.7671757110360228, 'eval_avg_sts': 0.7889267194059593, 'epoch': 0.57}\n","{'loss': 0.1231, 'learning_rate': 2.111111111111111e-05, 'epoch': 0.58}\n","{'eval_stsb_spearman': 0.8126246988686804, 'eval_sickr_spearman': 0.770220546649489, 'eval_avg_sts': 0.7914226227590847, 'epoch': 0.58}\n","{'loss': 0.1164, 'learning_rate': 2.0555555555555555e-05, 'epoch': 0.59}\n","{'eval_stsb_spearman': 0.8087936997869911, 'eval_sickr_spearman': 0.770164302229705, 'eval_avg_sts': 0.7894790010083481, 'epoch': 0.59}\n","{'loss': 0.1165, 'learning_rate': 2e-05, 'epoch': 0.6}\n","{'eval_stsb_spearman': 0.8122402591019368, 'eval_sickr_spearman': 0.766561249155325, 'eval_avg_sts': 0.7894007541286309, 'epoch': 0.6}\n","{'loss': 0.1124, 'learning_rate': 1.9444444444444445e-05, 'epoch': 0.61}\n","{'eval_stsb_spearman': 0.8122717573442867, 'eval_sickr_spearman': 0.770810800855062, 'eval_avg_sts': 0.7915412790996743, 'epoch': 0.61}\n","{'loss': 0.1197, 'learning_rate': 1.888888888888889e-05, 'epoch': 0.62}\n","{'eval_stsb_spearman': 0.810250827846018, 'eval_sickr_spearman': 0.7625844180495536, 'eval_avg_sts': 0.7864176229477857, 'epoch': 0.62}\n","{'loss': 0.1118, 'learning_rate': 1.8333333333333333e-05, 'epoch': 0.63}\n","{'eval_stsb_spearman': 0.8114835753063924, 'eval_sickr_spearman': 0.7642789072771887, 'eval_avg_sts': 0.7878812412917906, 'epoch': 0.63}\n","{'loss': 0.1103, 'learning_rate': 1.777777777777778e-05, 'epoch': 0.64}\n","{'eval_stsb_spearman': 0.8148945161040577, 'eval_sickr_spearman': 0.7712801607783152, 'eval_avg_sts': 0.7930873384411865, 'epoch': 0.64}\n","{'loss': 0.1107, 'learning_rate': 1.7222222222222224e-05, 'epoch': 0.66}\n","{'eval_stsb_spearman': 0.8129365994395209, 'eval_sickr_spearman': 0.7667781576094196, 'eval_avg_sts': 0.7898573785244702, 'epoch': 0.66}\n","{'loss': 0.1017, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.67}\n","{'eval_stsb_spearman': 0.8141049828070738, 'eval_sickr_spearman': 0.7736423783781431, 'eval_avg_sts': 0.7938736805926084, 'epoch': 0.67}\n","{'loss': 0.1031, 'learning_rate': 1.6111111111111115e-05, 'epoch': 0.68}\n","{'eval_stsb_spearman': 0.8101867292168484, 'eval_sickr_spearman': 0.7675970398578379, 'eval_avg_sts': 0.7888918845373432, 'epoch': 0.68}\n","{'loss': 0.1052, 'learning_rate': 1.5555555555555555e-05, 'epoch': 0.69}\n","{'eval_stsb_spearman': 0.8118664641923027, 'eval_sickr_spearman': 0.7705415865315014, 'eval_avg_sts': 0.791204025361902, 'epoch': 0.69}\n","{'loss': 0.1034, 'learning_rate': 1.5e-05, 'epoch': 0.7}\n","{'eval_stsb_spearman': 0.8106130444572934, 'eval_sickr_spearman': 0.772856205309804, 'eval_avg_sts': 0.7917346248835487, 'epoch': 0.7}\n","{'loss': 0.1031, 'learning_rate': 1.4444444444444444e-05, 'epoch': 0.71}\n","{'eval_stsb_spearman': 0.8095844939263298, 'eval_sickr_spearman': 0.7700779423093194, 'eval_avg_sts': 0.7898312181178246, 'epoch': 0.71}\n","{'loss': 0.0958, 'learning_rate': 1.388888888888889e-05, 'epoch': 0.72}\n","{'eval_stsb_spearman': 0.8100639942568119, 'eval_sickr_spearman': 0.7612857531288699, 'eval_avg_sts': 0.785674873692841, 'epoch': 0.72}\n","{'loss': 0.1002, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.73}\n","{'eval_stsb_spearman': 0.8106675327599252, 'eval_sickr_spearman': 0.7707890427661105, 'eval_avg_sts': 0.7907282877630178, 'epoch': 0.73}\n","{'loss': 0.1001, 'learning_rate': 1.2777777777777777e-05, 'epoch': 0.74}\n","{'eval_stsb_spearman': 0.8120593995466795, 'eval_sickr_spearman': 0.7680199537060005, 'eval_avg_sts': 0.79003967662634, 'epoch': 0.74}\n","{'loss': 0.0976, 'learning_rate': 1.2222222222222222e-05, 'epoch': 0.76}\n","{'eval_stsb_spearman': 0.8131686109984014, 'eval_sickr_spearman': 0.7679732194443013, 'eval_avg_sts': 0.7905709152213514, 'epoch': 0.76}\n","{'loss': 0.0936, 'learning_rate': 1.1666666666666668e-05, 'epoch': 0.77}\n","{'eval_stsb_spearman': 0.8156167649878171, 'eval_sickr_spearman': 0.7663197968083956, 'eval_avg_sts': 0.7909682808981063, 'epoch': 0.77}\n","{'loss': 0.0978, 'learning_rate': 1.1111111111111112e-05, 'epoch': 0.78}\n","{'eval_stsb_spearman': 0.8179237950476234, 'eval_sickr_spearman': 0.7676433418396242, 'eval_avg_sts': 0.7927835684436237, 'epoch': 0.78}\n"," 78% 35000/45000 [4:50:18<1:11:50,  2.32it/s][INFO|trainer.py:1344] 2021-11-27 19:23:58,213 >> Saving model checkpoint to ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch\n","[INFO|configuration_utils.py:300] 2021-11-27 19:23:58,220 >> Configuration saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/config.json\n","[INFO|modeling_utils.py:817] 2021-11-27 19:23:59,865 >> Model weights saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/pytorch_model.bin\n","{'loss': 0.0956, 'learning_rate': 1.0555555555555555e-05, 'epoch': 0.79}\n","{'eval_stsb_spearman': 0.8125663821025085, 'eval_sickr_spearman': 0.7624388357810946, 'eval_avg_sts': 0.7875026089418016, 'epoch': 0.79}\n","{'loss': 0.0878, 'learning_rate': 1e-05, 'epoch': 0.8}\n","{'eval_stsb_spearman': 0.8155100672405998, 'eval_sickr_spearman': 0.7647261728937804, 'eval_avg_sts': 0.7901181200671901, 'epoch': 0.8}\n","{'loss': 0.0884, 'learning_rate': 9.444444444444445e-06, 'epoch': 0.81}\n","{'eval_stsb_spearman': 0.8157545586770935, 'eval_sickr_spearman': 0.7678938720647255, 'eval_avg_sts': 0.7918242153709094, 'epoch': 0.81}\n","{'loss': 0.0832, 'learning_rate': 8.88888888888889e-06, 'epoch': 0.82}\n","{'eval_stsb_spearman': 0.8172874003176901, 'eval_sickr_spearman': 0.7678648612794569, 'eval_avg_sts': 0.7925761307985735, 'epoch': 0.82}\n","{'loss': 0.0843, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.83}\n","{'eval_stsb_spearman': 0.8160066182950187, 'eval_sickr_spearman': 0.7660610532649484, 'eval_avg_sts': 0.7910338357799835, 'epoch': 0.83}\n","{'loss': 0.09, 'learning_rate': 7.777777777777777e-06, 'epoch': 0.84}\n","{'eval_stsb_spearman': 0.8185867944528501, 'eval_sickr_spearman': 0.7674784030372858, 'eval_avg_sts': 0.7930325987450679, 'epoch': 0.84}\n"," 84% 38000/45000 [5:15:10<49:41,  2.35it/s][INFO|trainer.py:1344] 2021-11-27 19:48:50,657 >> Saving model checkpoint to ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch\n","[INFO|configuration_utils.py:300] 2021-11-27 19:48:50,674 >> Configuration saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/config.json\n","[INFO|modeling_utils.py:817] 2021-11-27 19:48:52,281 >> Model weights saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/pytorch_model.bin\n","{'loss': 0.08, 'learning_rate': 7.222222222222222e-06, 'epoch': 0.86}\n","{'eval_stsb_spearman': 0.8159948115117202, 'eval_sickr_spearman': 0.765409559405042, 'eval_avg_sts': 0.7907021854583811, 'epoch': 0.86}\n","{'loss': 0.0855, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.87}\n","{'eval_stsb_spearman': 0.8152212148931313, 'eval_sickr_spearman': 0.7622392665546193, 'eval_avg_sts': 0.7887302407238752, 'epoch': 0.87}\n","{'loss': 0.0814, 'learning_rate': 6.111111111111111e-06, 'epoch': 0.88}\n","{'eval_stsb_spearman': 0.8162985348665804, 'eval_sickr_spearman': 0.7647820033884933, 'eval_avg_sts': 0.7905402691275369, 'epoch': 0.88}\n","{'loss': 0.0828, 'learning_rate': 5.555555555555556e-06, 'epoch': 0.89}\n","{'eval_stsb_spearman': 0.8146249653718629, 'eval_sickr_spearman': 0.764093219039029, 'eval_avg_sts': 0.789359092205446, 'epoch': 0.89}\n","{'loss': 0.0815, 'learning_rate': 5e-06, 'epoch': 0.9}\n","{'eval_stsb_spearman': 0.8155152168751233, 'eval_sickr_spearman': 0.7650470686824885, 'eval_avg_sts': 0.7902811427788059, 'epoch': 0.9}\n","{'loss': 0.0791, 'learning_rate': 4.444444444444445e-06, 'epoch': 0.91}\n","{'eval_stsb_spearman': 0.8165178615303955, 'eval_sickr_spearman': 0.7671976132182785, 'eval_avg_sts': 0.791857737374337, 'epoch': 0.91}\n","{'loss': 0.0766, 'learning_rate': 3.888888888888889e-06, 'epoch': 0.92}\n","{'eval_stsb_spearman': 0.8173510811297648, 'eval_sickr_spearman': 0.76563693863925, 'eval_avg_sts': 0.7914940098845074, 'epoch': 0.92}\n","{'loss': 0.0802, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.93}\n","{'eval_stsb_spearman': 0.8172070621839562, 'eval_sickr_spearman': 0.7651540819764926, 'eval_avg_sts': 0.7911805720802244, 'epoch': 0.93}\n","{'loss': 0.0766, 'learning_rate': 2.777777777777778e-06, 'epoch': 0.94}\n","{'eval_stsb_spearman': 0.817759286037443, 'eval_sickr_spearman': 0.7654600881237549, 'eval_avg_sts': 0.7916096870805989, 'epoch': 0.94}\n","{'loss': 0.0756, 'learning_rate': 2.2222222222222225e-06, 'epoch': 0.96}\n","{'eval_stsb_spearman': 0.816555816182923, 'eval_sickr_spearman': 0.7638058969902263, 'eval_avg_sts': 0.7901808565865747, 'epoch': 0.96}\n","{'loss': 0.0771, 'learning_rate': 1.6666666666666667e-06, 'epoch': 0.97}\n","{'eval_stsb_spearman': 0.8165393777233458, 'eval_sickr_spearman': 0.7650194507991616, 'eval_avg_sts': 0.7907794142612536, 'epoch': 0.97}\n","{'loss': 0.0817, 'learning_rate': 1.1111111111111112e-06, 'epoch': 0.98}\n","{'eval_stsb_spearman': 0.8169196057434145, 'eval_sickr_spearman': 0.7646010999056356, 'eval_avg_sts': 0.7907603528245251, 'epoch': 0.98}\n","{'loss': 0.0772, 'learning_rate': 5.555555555555556e-07, 'epoch': 0.99}\n","{'eval_stsb_spearman': 0.8173083764739972, 'eval_sickr_spearman': 0.7651173381838925, 'eval_avg_sts': 0.7912128573289449, 'epoch': 0.99}\n","{'loss': 0.0738, 'learning_rate': 0.0, 'epoch': 1.0}\n","{'eval_stsb_spearman': 0.8173204092372671, 'eval_sickr_spearman': 0.7652925076108372, 'eval_avg_sts': 0.7913064584240521, 'epoch': 1.0}\n","{'eval_stsb_spearman': 0.8173204092372671, 'eval_sickr_spearman': 0.7652925076108372, 'eval_avg_sts': 0.7913064584240521, 'epoch': 1.0}\n","100% 45000/45000 [6:13:35<00:00,  2.36it/s]11/27/2021 20:47:15 - INFO - simcse.trainers -   \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","11/27/2021 20:47:15 - INFO - simcse.trainers -   Loading best model from ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch (score: 0.8185867944528501).\n","[INFO|configuration_utils.py:443] 2021-11-27 20:47:15,733 >> loading configuration file ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/config.json\n","[INFO|configuration_utils.py:481] 2021-11-27 20:47:15,734 >> Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForCL\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|modeling_utils.py:1025] 2021-11-27 20:47:15,734 >> loading weights file ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/pytorch_model.bin\n","[INFO|modeling_utils.py:1143] 2021-11-27 20:47:18,751 >> All model checkpoint weights were used when initializing BertForCL.\n","\n","[INFO|modeling_utils.py:1152] 2021-11-27 20:47:18,751 >> All the weights of BertForCL were initialized from the model checkpoint at ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForCL for predictions without further training.\n","{'train_runtime': 22418.8046, 'train_samples_per_second': 2.007, 'epoch': 1.0}\n","100% 45000/45000 [6:13:38<00:00,  2.01it/s]\n","[INFO|trainer.py:1344] 2021-11-27 20:47:18,887 >> Saving model checkpoint to ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch\n","[INFO|configuration_utils.py:300] 2021-11-27 20:47:18,895 >> Configuration saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/config.json\n","[INFO|modeling_utils.py:817] 2021-11-27 20:47:20,497 >> Model weights saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch/pytorch_model.bin\n","11/27/2021 20:47:20 - INFO - __main__ -   ***** Train results *****\n","11/27/2021 20:47:20 - INFO - __main__ -     epoch = 1.0\n","11/27/2021 20:47:20 - INFO - __main__ -     train_runtime = 22418.8046\n","11/27/2021 20:47:20 - INFO - __main__ -     train_samples_per_second = 2.007\n","11/27/2021 20:47:20 - INFO - __main__ -   *** Evaluate ***\n","11/27/2021 20:47:55 - INFO - root -   Generating sentence embeddings\n","11/27/2021 20:48:09 - INFO - root -   Generated sentence embeddings\n","11/27/2021 20:48:09 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/27/2021 20:48:25 - INFO - root -   Best param found at split 1: l2reg = 0.001                 with score 79.77\n","11/27/2021 20:48:41 - INFO - root -   Best param found at split 2: l2reg = 1e-05                 with score 78.9\n","11/27/2021 20:48:57 - INFO - root -   Best param found at split 3: l2reg = 0.01                 with score 79.11\n","11/27/2021 20:49:12 - INFO - root -   Best param found at split 4: l2reg = 1e-05                 with score 79.03\n","11/27/2021 20:49:28 - INFO - root -   Best param found at split 5: l2reg = 0.0001                 with score 78.99\n","11/27/2021 20:49:29 - INFO - root -   Generating sentence embeddings\n","11/27/2021 20:49:33 - INFO - root -   Generated sentence embeddings\n","11/27/2021 20:49:33 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/27/2021 20:49:38 - INFO - root -   Best param found at split 1: l2reg = 0.001                 with score 88.51\n","11/27/2021 20:49:43 - INFO - root -   Best param found at split 2: l2reg = 1e-05                 with score 87.35\n","11/27/2021 20:49:48 - INFO - root -   Best param found at split 3: l2reg = 0.001                 with score 87.91\n","11/27/2021 20:49:54 - INFO - root -   Best param found at split 4: l2reg = 0.01                 with score 87.42\n","11/27/2021 20:49:59 - INFO - root -   Best param found at split 5: l2reg = 1e-05                 with score 86.85\n","11/27/2021 20:50:00 - INFO - root -   Generating sentence embeddings\n","11/27/2021 20:50:14 - INFO - root -   Generated sentence embeddings\n","11/27/2021 20:50:14 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/27/2021 20:50:30 - INFO - root -   Best param found at split 1: l2reg = 1e-05                 with score 93.28\n","11/27/2021 20:50:46 - INFO - root -   Best param found at split 2: l2reg = 0.0001                 with score 93.78\n","11/27/2021 20:51:00 - INFO - root -   Best param found at split 3: l2reg = 1e-05                 with score 93.26\n","11/27/2021 20:51:17 - INFO - root -   Best param found at split 4: l2reg = 1e-05                 with score 93.22\n","11/27/2021 20:51:33 - INFO - root -   Best param found at split 5: l2reg = 1e-05                 with score 93.32\n","11/27/2021 20:51:34 - INFO - root -   Generating sentence embeddings\n","11/27/2021 20:51:37 - INFO - root -   Generated sentence embeddings\n","11/27/2021 20:51:37 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/27/2021 20:51:52 - INFO - root -   Best param found at split 1: l2reg = 0.001                 with score 88.77\n","11/27/2021 20:52:07 - INFO - root -   Best param found at split 2: l2reg = 0.0001                 with score 87.64\n","11/27/2021 20:52:24 - INFO - root -   Best param found at split 3: l2reg = 0.0001                 with score 89.03\n","11/27/2021 20:52:39 - INFO - root -   Best param found at split 4: l2reg = 1e-05                 with score 88.4\n","11/27/2021 20:52:57 - INFO - root -   Best param found at split 5: l2reg = 1e-05                 with score 88.32\n","11/27/2021 20:52:58 - INFO - root -   Computing embedding for train\n","11/27/2021 20:53:45 - INFO - root -   Computed train embeddings\n","11/27/2021 20:53:45 - INFO - root -   Computing embedding for dev\n","11/27/2021 20:53:46 - INFO - root -   Computed dev embeddings\n","11/27/2021 20:53:46 - INFO - root -   Computing embedding for test\n","11/27/2021 20:53:48 - INFO - root -   Computed test embeddings\n","11/27/2021 20:53:48 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..\n","11/27/2021 20:54:16 - INFO - root -   [('reg:1e-05', 84.4), ('reg:0.0001', 84.29), ('reg:0.001', 83.37), ('reg:0.01', 83.14)]\n","11/27/2021 20:54:16 - INFO - root -   Validation : best param found is reg = 1e-05 with score             84.4\n","11/27/2021 20:54:16 - INFO - root -   Evaluating...\n","11/27/2021 20:54:24 - INFO - root -   ***** Transfer task : TREC *****\n","\n","\n","11/27/2021 20:54:28 - INFO - root -   Computed train embeddings\n","11/27/2021 20:54:28 - INFO - root -   Computed test embeddings\n","11/27/2021 20:54:28 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation\n","11/27/2021 20:54:38 - INFO - root -   [('reg:1e-05', 69.37), ('reg:0.0001', 69.26), ('reg:0.001', 68.32), ('reg:0.01', 63.66)]\n","11/27/2021 20:54:38 - INFO - root -   Cross-validation : best param found is reg = 1e-05             with score 69.37\n","11/27/2021 20:54:38 - INFO - root -   Evaluating...\n","11/27/2021 20:54:39 - INFO - root -   ***** Transfer task : MRPC *****\n","\n","\n","11/27/2021 20:54:39 - INFO - root -   Computing embedding for train\n","11/27/2021 20:54:49 - INFO - root -   Computed train embeddings\n","11/27/2021 20:54:49 - INFO - root -   Computing embedding for test\n","11/27/2021 20:54:54 - INFO - root -   Computed test embeddings\n","11/27/2021 20:54:54 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation\n","11/27/2021 20:55:01 - INFO - root -   [('reg:1e-05', 75.02), ('reg:0.0001', 74.78), ('reg:0.001', 75.25), ('reg:0.01', 74.98)]\n","11/27/2021 20:55:01 - INFO - root -   Cross-validation : best param found is reg = 0.001             with score 75.25\n","11/27/2021 20:55:01 - INFO - root -   Evaluating...\n","11/27/2021 20:55:02 - INFO - __main__ -   ***** Eval results *****\n","11/27/2021 20:55:02 - INFO - __main__ -     epoch = 1.0\n","11/27/2021 20:55:02 - INFO - __main__ -     eval_CR = 87.61\n","11/27/2021 20:55:02 - INFO - __main__ -     eval_MPQA = 88.43\n","11/27/2021 20:55:02 - INFO - __main__ -     eval_MR = 79.16\n","11/27/2021 20:55:02 - INFO - __main__ -     eval_MRPC = 75.25\n","11/27/2021 20:55:02 - INFO - __main__ -     eval_SST2 = 84.4\n","11/27/2021 20:55:02 - INFO - __main__ -     eval_SUBJ = 93.37\n","11/27/2021 20:55:02 - INFO - __main__ -     eval_TREC = 69.37\n","11/27/2021 20:55:02 - INFO - __main__ -     eval_avg_sts = 0.7930325987450679\n","11/27/2021 20:55:02 - INFO - __main__ -     eval_avg_transfer = 82.51285714285714\n","11/27/2021 20:55:02 - INFO - __main__ -     eval_sickr_spearman = 0.7674784030372858\n","11/27/2021 20:55:02 - INFO - __main__ -     eval_stsb_spearman = 0.8185867944528501\n"]}]},{"cell_type":"markdown","metadata":{"id":"R-2PhweldGNz"},"source":["## Training with 360k TwiBot dataset built on similarity with metadata - no tags for uppercase - 1 epoch LR 5e-5\n","--model_name_or_path bert-base-uncased"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_BtyfMqPd63N","outputId":"ffafcf96-2ad6-406c-e545-60c3c5a4b410"},"source":["!cd ../SimCSE-main && python train.py --model_name_or_path bert-base-uncased \\\n","    --train_file ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/train_all_data_triplets_with_similarity_for_simcse.csv \\\n","    --output_dir ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch_LR5e-5_bert_base_uncased \\\n","    --num_train_epochs 1 \\\n","    --per_device_train_batch_size 32 \\\n","    --learning_rate 5e-5 \\\n","    --max_seq_length 48 \\\n","    --evaluation_strategy steps \\\n","    --metric_for_best_model stsb_spearman \\\n","    --load_best_model_at_end \\\n","    --overwrite_output_dir \\\n","    --temp 0.05 \\\n","    --do_train \\"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["11/28/2021 08:06:07 - INFO - __main__ -   PyTorch: setting up devices\n","11/28/2021 08:06:07 - INFO - __main__ -   Set device to CUDA\n","11/28/2021 08:06:07 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1 distributed training: False, 16-bits training: False\n","11/28/2021 08:06:07 - INFO - __main__ -   Training/evaluation parameters OurTrainingArguments(output_dir='../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch_LR5e-5_bert_base_uncased', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_steps=0, logging_dir='runs/Nov28_08-06-07_962ed8da78b7', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', fp16_backend='auto', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch_LR5e-5_bert_base_uncased', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model='stsb_spearman', greater_is_better=True, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, eval_transfer=False)\n","Downloading: 5.33kB [00:00, 5.99MB/s]       \n","Using custom data configuration default\n","Downloading and preparing dataset csv/default-57141a176798753d (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to ./data/csv/default-57141a176798753d/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2...\n","Dataset csv downloaded and prepared to ./data/csv/default-57141a176798753d/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2. Subsequent calls will reuse this data.\n","[INFO|file_utils.py:1272] 2021-11-28 08:06:28,366 >> https://huggingface.co/bert-base-uncased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp4dnzuxmo\n","Downloading: 100% 570/570 [00:00<00:00, 665kB/s]\n","[INFO|file_utils.py:1276] 2021-11-28 08:06:28,637 >> storing https://huggingface.co/bert-base-uncased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|file_utils.py:1279] 2021-11-28 08:06:28,637 >> creating metadata file for /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|configuration_utils.py:445] 2021-11-28 08:06:28,637 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|configuration_utils.py:481] 2021-11-28 08:06:28,638 >> Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|configuration_utils.py:445] 2021-11-28 08:06:28,909 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","[INFO|configuration_utils.py:481] 2021-11-28 08:06:28,909 >> Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","[INFO|file_utils.py:1272] 2021-11-28 08:06:29,183 >> https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpz2lfrk39\n","Downloading: 100% 232k/232k [00:00<00:00, 1.22MB/s]\n","[INFO|file_utils.py:1276] 2021-11-28 08:06:29,722 >> storing https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","[INFO|file_utils.py:1279] 2021-11-28 08:06:29,722 >> creating metadata file for /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","[INFO|file_utils.py:1272] 2021-11-28 08:06:29,990 >> https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpk49ex9n0\n","Downloading: 100% 466k/466k [00:00<00:00, 1.49MB/s]\n","[INFO|file_utils.py:1276] 2021-11-28 08:06:30,574 >> storing https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","[INFO|file_utils.py:1279] 2021-11-28 08:06:30,574 >> creating metadata file for /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","[INFO|tokenization_utils_base.py:1766] 2021-11-28 08:06:30,574 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","[INFO|tokenization_utils_base.py:1766] 2021-11-28 08:06:30,574 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n","[INFO|file_utils.py:1272] 2021-11-28 08:06:30,859 >> https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpmzqfmq5s\n","Downloading: 100% 440M/440M [00:06<00:00, 64.9MB/s]\n","[INFO|file_utils.py:1276] 2021-11-28 08:06:37,752 >> storing https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","[INFO|file_utils.py:1279] 2021-11-28 08:06:37,752 >> creating metadata file for /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","[INFO|modeling_utils.py:1027] 2021-11-28 08:06:37,752 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","[WARNING|modeling_utils.py:1135] 2021-11-28 08:06:41,403 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForCL: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n","- This IS expected if you are initializing BertForCL from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForCL from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[WARNING|modeling_utils.py:1146] 2021-11-28 08:06:41,403 >> Some weights of BertForCL were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['mlp.dense.weight', 'mlp.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 23% 330/1440 [01:22<04:16,  4.33ba/s]"]}]},{"cell_type":"markdown","metadata":{"id":"t1Btyx3_eNuO"},"source":["## Training with 360k TwiBot dataset built on similarity with metadata - no tags for uppercase - 1 epoch LR 5e-5\n","-model_name_or_path princeton-nlp/sup-simcse-roberta-base"]},{"cell_type":"code","metadata":{"id":"7KvfXEvpe-tZ"},"source":["!cd ../SimCSE-main && python train.py --model_name_or_path princeton-nlp/sup-simcse-roberta-base \\\n","    --train_file ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/train_all_data_triplets_with_similarity_for_simcse.csv \\\n","    --output_dir ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch_LR5e-5_roberta_base \\\n","    --num_train_epochs 1 \\\n","    --per_device_train_batch_size 32 \\\n","    --learning_rate 5e-5 \\\n","    --max_seq_length 48 \\\n","    --evaluation_strategy steps \\\n","    --metric_for_best_model stsb_spearman \\\n","    --load_best_model_at_end \\\n","    --overwrite_output_dir \\\n","    --temp 0.05 \\\n","    --do_train \\"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A-Dd95G6hZva"},"source":["## Training with 360k TwiBot dataset built on similarity with metadata - no tags for uppercase - 1 epoch LR 1e-5\n","--model_name_or_path bert-base-uncased"]},{"cell_type":"code","metadata":{"id":"6yjDtn_ehbmq"},"source":["!cd ../SimCSE-main && python train.py --model_name_or_path bert-base-uncased \\\n","    --train_file ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/train_all_data_triplets_with_similarity_for_simcse.csv \\\n","    --output_dir ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch_LR1e-5_bert_base_uncased \\\n","    --num_train_epochs 1 \\\n","    --per_device_train_batch_size 32 \\\n","    --learning_rate 1e-5 \\\n","    --max_seq_length 48 \\\n","    --evaluation_strategy steps \\\n","    --metric_for_best_model stsb_spearman \\\n","    --load_best_model_at_end \\\n","    --overwrite_output_dir \\\n","    --temp 0.05 \\\n","    --do_train \\"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_fdQQQtahmsd"},"source":["## Training with 360k TwiBot dataset built on similarity with metadata - no tags for uppercase - 1 epoch LR 1e-5\n","-model_name_or_path princeton-nlp/sup-simcse-roberta-base"]},{"cell_type":"code","metadata":{"id":"_bgs8fvihqz1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638258882256,"user_tz":480,"elapsed":1934757,"user":{"displayName":"Venkatesh Madi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjEBVZrlTFNDzPSl7eB4CL2YPLP-bfPlNxWSqr0tEc=s64","userId":"10204830288063877139"}},"outputId":"c24b5502-f036-48a3-bd97-6e297d92b57e"},"source":["!cd ../SimCSE-main && python train.py --model_name_or_path princeton-nlp/sup-simcse-roberta-base \\\n","    --train_file ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/train_all_data_triplets_with_similarity_for_simcse.csv \\\n","    --output_dir ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch_LR1e-5_roberta_base \\\n","    --num_train_epochs 1 \\\n","    --per_device_train_batch_size 32 \\\n","    --learning_rate 1e-5 \\\n","    --max_seq_length 48 \\\n","    --evaluation_strategy steps \\\n","    --metric_for_best_model stsb_spearman \\\n","    --load_best_model_at_end \\\n","    --overwrite_output_dir \\\n","    --temp 0.05 \\\n","    --do_train \\"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["11/30/2021 01:40:36 - INFO - __main__ -   PyTorch: setting up devices\n","11/30/2021 01:40:36 - INFO - __main__ -   Set device to CUDA\n","11/30/2021 01:40:36 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1 distributed training: False, 16-bits training: False\n","11/30/2021 01:40:36 - INFO - __main__ -   Training/evaluation parameters OurTrainingArguments(output_dir='../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch_LR1e-5_roberta_base', overwrite_output_dir=True, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=<EvaluationStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=32, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=1e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_steps=0, logging_dir='runs/Nov30_01-40-36_206bca73a784', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', fp16_backend='auto', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch_LR1e-5_roberta_base', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model='stsb_spearman', greater_is_better=True, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, eval_transfer=False)\n","Downloading: 5.33kB [00:00, 6.14MB/s]       \n","Using custom data configuration default\n","Reusing dataset csv (./data/csv/default-57141a176798753d/0.0.0/2960f95a26e85d40ca41a230ac88787f715ee3003edaacb8b1f0891e9f04dda2)\n","[INFO|file_utils.py:1272] 2021-11-30 01:41:28,833 >> https://huggingface.co/princeton-nlp/sup-simcse-roberta-base/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpaexa_nl6\n","Downloading: 100% 738/738 [00:00<00:00, 1.03MB/s]\n","[INFO|file_utils.py:1276] 2021-11-30 01:41:28,925 >> storing https://huggingface.co/princeton-nlp/sup-simcse-roberta-base/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/1480925a23f7db13cea1c830922dbd4173c2a1ccab8c57cbb36a1ea693164879.01dc297b74ef2153586ff6f1113a3309f339a11f1cef9d887ae2314924e8d17e\n","[INFO|file_utils.py:1279] 2021-11-30 01:41:28,926 >> creating metadata file for /root/.cache/huggingface/transformers/1480925a23f7db13cea1c830922dbd4173c2a1ccab8c57cbb36a1ea693164879.01dc297b74ef2153586ff6f1113a3309f339a11f1cef9d887ae2314924e8d17e\n","[INFO|configuration_utils.py:445] 2021-11-30 01:41:28,926 >> loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1480925a23f7db13cea1c830922dbd4173c2a1ccab8c57cbb36a1ea693164879.01dc297b74ef2153586ff6f1113a3309f339a11f1cef9d887ae2314924e8d17e\n","[INFO|configuration_utils.py:481] 2021-11-30 01:41:28,926 >> Model config RobertaConfig {\n","  \"_name_or_path\": \"result/roberta-base-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-cross_contra-norm0.05-l32\",\n","  \"architectures\": [\n","    \"RobertaModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","[INFO|configuration_utils.py:445] 2021-11-30 01:41:29,027 >> loading configuration file https://huggingface.co/princeton-nlp/sup-simcse-roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/1480925a23f7db13cea1c830922dbd4173c2a1ccab8c57cbb36a1ea693164879.01dc297b74ef2153586ff6f1113a3309f339a11f1cef9d887ae2314924e8d17e\n","[INFO|configuration_utils.py:481] 2021-11-30 01:41:29,027 >> Model config RobertaConfig {\n","  \"_name_or_path\": \"result/roberta-base-cls_before_pooler-sym_mlp-mlp_bert-bs64-gpu8-gs1-lr5e-5-m=stsb-cross_contra-norm0.05-l32\",\n","  \"architectures\": [\n","    \"RobertaModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","[INFO|tokenization_utils_base.py:1685] 2021-11-30 01:41:29,028 >> Model name 'princeton-nlp/sup-simcse-roberta-base' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming 'princeton-nlp/sup-simcse-roberta-base' is a path, a model identifier, or url to a directory containing tokenizer files.\n","[INFO|file_utils.py:1272] 2021-11-30 01:41:29,122 >> https://huggingface.co/princeton-nlp/sup-simcse-roberta-base/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpcohtd14w\n","Downloading: 100% 798k/798k [00:00<00:00, 7.91MB/s]\n","[INFO|file_utils.py:1276] 2021-11-30 01:41:29,322 >> storing https://huggingface.co/princeton-nlp/sup-simcse-roberta-base/resolve/main/vocab.json in cache at /root/.cache/huggingface/transformers/acc6631454b7d3d0bbc46e818921f775d72f6b99998a495f23fb1224a44eec3a.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n","[INFO|file_utils.py:1279] 2021-11-30 01:41:29,322 >> creating metadata file for /root/.cache/huggingface/transformers/acc6631454b7d3d0bbc46e818921f775d72f6b99998a495f23fb1224a44eec3a.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n","[INFO|file_utils.py:1272] 2021-11-30 01:41:29,423 >> https://huggingface.co/princeton-nlp/sup-simcse-roberta-base/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp88bylzgi\n","Downloading: 100% 456k/456k [00:00<00:00, 5.79MB/s]\n","[INFO|file_utils.py:1276] 2021-11-30 01:41:29,623 >> storing https://huggingface.co/princeton-nlp/sup-simcse-roberta-base/resolve/main/merges.txt in cache at /root/.cache/huggingface/transformers/c9064dc44d21fa2f7e3fc6f12933d957abc98c41af0bf1ac23c3696cbd07efa3.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n","[INFO|file_utils.py:1279] 2021-11-30 01:41:29,624 >> creating metadata file for /root/.cache/huggingface/transformers/c9064dc44d21fa2f7e3fc6f12933d957abc98c41af0bf1ac23c3696cbd07efa3.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n","[INFO|file_utils.py:1272] 2021-11-30 01:41:29,914 >> https://huggingface.co/princeton-nlp/sup-simcse-roberta-base/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp1lo567rn\n","Downloading: 100% 239/239 [00:00<00:00, 328kB/s]\n","[INFO|file_utils.py:1276] 2021-11-30 01:41:30,010 >> storing https://huggingface.co/princeton-nlp/sup-simcse-roberta-base/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/90ffa7c13d92d368876a3cde38912cf1fbe882d3b2ad0fc6b1ab5d11fa3f7753.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n","[INFO|file_utils.py:1279] 2021-11-30 01:41:30,010 >> creating metadata file for /root/.cache/huggingface/transformers/90ffa7c13d92d368876a3cde38912cf1fbe882d3b2ad0fc6b1ab5d11fa3f7753.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n","[INFO|file_utils.py:1272] 2021-11-30 01:41:30,107 >> https://huggingface.co/princeton-nlp/sup-simcse-roberta-base/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpv11zu9zx\n","Downloading: 100% 255/255 [00:00<00:00, 383kB/s]\n","[INFO|file_utils.py:1276] 2021-11-30 01:41:30,200 >> storing https://huggingface.co/princeton-nlp/sup-simcse-roberta-base/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/922c9b956361876b0f649952a01067c6f23c723b350b48b9c1097733b353fa2f.7798c29a2c53e319dac80a41f69e57b26872a2c22e75a2befcea7e1469067aa2\n","[INFO|file_utils.py:1279] 2021-11-30 01:41:30,200 >> creating metadata file for /root/.cache/huggingface/transformers/922c9b956361876b0f649952a01067c6f23c723b350b48b9c1097733b353fa2f.7798c29a2c53e319dac80a41f69e57b26872a2c22e75a2befcea7e1469067aa2\n","[INFO|tokenization_utils_base.py:1766] 2021-11-30 01:41:30,201 >> loading file https://huggingface.co/princeton-nlp/sup-simcse-roberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/acc6631454b7d3d0bbc46e818921f775d72f6b99998a495f23fb1224a44eec3a.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n","[INFO|tokenization_utils_base.py:1766] 2021-11-30 01:41:30,201 >> loading file https://huggingface.co/princeton-nlp/sup-simcse-roberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c9064dc44d21fa2f7e3fc6f12933d957abc98c41af0bf1ac23c3696cbd07efa3.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n","[INFO|tokenization_utils_base.py:1766] 2021-11-30 01:41:30,201 >> loading file https://huggingface.co/princeton-nlp/sup-simcse-roberta-base/resolve/main/tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:1766] 2021-11-30 01:41:30,201 >> loading file https://huggingface.co/princeton-nlp/sup-simcse-roberta-base/resolve/main/added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:1766] 2021-11-30 01:41:30,201 >> loading file https://huggingface.co/princeton-nlp/sup-simcse-roberta-base/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/90ffa7c13d92d368876a3cde38912cf1fbe882d3b2ad0fc6b1ab5d11fa3f7753.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n","[INFO|tokenization_utils_base.py:1766] 2021-11-30 01:41:30,201 >> loading file https://huggingface.co/princeton-nlp/sup-simcse-roberta-base/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/922c9b956361876b0f649952a01067c6f23c723b350b48b9c1097733b353fa2f.7798c29a2c53e319dac80a41f69e57b26872a2c22e75a2befcea7e1469067aa2\n","[INFO|file_utils.py:1272] 2021-11-30 01:41:30,427 >> https://huggingface.co/princeton-nlp/sup-simcse-roberta-base/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpm4_2i_ax\n","Downloading: 100% 499M/499M [00:19<00:00, 25.3MB/s]\n","[INFO|file_utils.py:1276] 2021-11-30 01:41:50,574 >> storing https://huggingface.co/princeton-nlp/sup-simcse-roberta-base/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/072770cb5e0bad3e369c669188384fba0743390527ab21b1aed9460c11591bb4.c306883c14178ac88d674b3ea52dee6d8e27c63ad7726e3bfc8431a53890cef8\n","[INFO|file_utils.py:1279] 2021-11-30 01:41:50,574 >> creating metadata file for /root/.cache/huggingface/transformers/072770cb5e0bad3e369c669188384fba0743390527ab21b1aed9460c11591bb4.c306883c14178ac88d674b3ea52dee6d8e27c63ad7726e3bfc8431a53890cef8\n","[INFO|modeling_utils.py:1027] 2021-11-30 01:41:50,575 >> loading weights file https://huggingface.co/princeton-nlp/sup-simcse-roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/072770cb5e0bad3e369c669188384fba0743390527ab21b1aed9460c11591bb4.c306883c14178ac88d674b3ea52dee6d8e27c63ad7726e3bfc8431a53890cef8\n","[WARNING|modeling_utils.py:1135] 2021-11-30 01:41:53,969 >> Some weights of the model checkpoint at princeton-nlp/sup-simcse-roberta-base were not used when initializing RobertaForCL: ['pooler.dense.weight', 'pooler.dense.bias']\n","- This IS expected if you are initializing RobertaForCL from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForCL from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[WARNING|modeling_utils.py:1146] 2021-11-30 01:41:53,969 >> Some weights of RobertaForCL were not initialized from the model checkpoint at princeton-nlp/sup-simcse-roberta-base and are newly initialized: ['mlp.dense.bias', 'mlp.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100% 1440/1440 [05:26<00:00,  4.41ba/s]\n","/usr/local/lib/python3.7/dist-packages/_distutils_hack/__init__.py:19: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n","  \"Distutils was imported before Setuptools. This usage is discouraged \"\n","[INFO|trainer.py:442] 2021-11-30 01:47:32,430 >> The following columns in the training set don't have a corresponding argument in `RobertaForCL.forward` and have been ignored: .\n","11/30/2021 01:47:32 - INFO - simcse.trainers -   ***** Running training *****\n","11/30/2021 01:47:32 - INFO - simcse.trainers -     Num examples = 1440000\n","11/30/2021 01:47:32 - INFO - simcse.trainers -     Num Epochs = 1\n","11/30/2021 01:47:32 - INFO - simcse.trainers -     Instantaneous batch size per device = 32\n","11/30/2021 01:47:32 - INFO - simcse.trainers -     Total train batch size (w. parallel, distributed & accumulation) = 32\n","11/30/2021 01:47:32 - INFO - simcse.trainers -     Gradient Accumulation steps = 1\n","11/30/2021 01:47:32 - INFO - simcse.trainers -     Total optimization steps = 45000\n","{'loss': 0.9987, 'learning_rate': 9.88888888888889e-06, 'epoch': 0.01}\n","{'eval_stsb_spearman': 0.853274842544008, 'eval_sickr_spearman': 0.8008502682231821, 'eval_avg_sts': 0.8270625553835951, 'epoch': 0.01}\n","  1% 500/45000 [04:05<5:08:25,  2.40it/s][INFO|trainer.py:1344] 2021-11-30 01:51:38,293 >> Saving model checkpoint to ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch_LR1e-5_roberta_base\n","[INFO|configuration_utils.py:300] 2021-11-30 01:51:38,441 >> Configuration saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch_LR1e-5_roberta_base/config.json\n","[INFO|modeling_utils.py:817] 2021-11-30 01:51:40,145 >> Model weights saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch_LR1e-5_roberta_base/pytorch_model.bin\n","{'loss': 0.8748, 'learning_rate': 9.777777777777779e-06, 'epoch': 0.02}\n","{'eval_stsb_spearman': 0.849904461217509, 'eval_sickr_spearman': 0.7936698587136914, 'eval_avg_sts': 0.8217871599656001, 'epoch': 0.02}\n","{'loss': 0.8192, 'learning_rate': 9.666666666666667e-06, 'epoch': 0.03}\n","{'eval_stsb_spearman': 0.8515577663619863, 'eval_sickr_spearman': 0.7949407136266425, 'eval_avg_sts': 0.8232492399943144, 'epoch': 0.03}\n","{'loss': 0.8065, 'learning_rate': 9.555555555555556e-06, 'epoch': 0.04}\n","{'eval_stsb_spearman': 0.8480737980340678, 'eval_sickr_spearman': 0.7851250777367498, 'eval_avg_sts': 0.8165994378854088, 'epoch': 0.04}\n","{'loss': 0.7881, 'learning_rate': 9.444444444444445e-06, 'epoch': 0.06}\n","{'eval_stsb_spearman': 0.8509637484244611, 'eval_sickr_spearman': 0.7989374296084092, 'eval_avg_sts': 0.8249505890164351, 'epoch': 0.06}\n","{'loss': 0.7427, 'learning_rate': 9.333333333333334e-06, 'epoch': 0.07}\n","{'eval_stsb_spearman': 0.8547857172508161, 'eval_sickr_spearman': 0.7911162852057342, 'eval_avg_sts': 0.8229510012282751, 'epoch': 0.07}\n","  7% 3000/45000 [24:15<4:47:44,  2.43it/s][INFO|trainer.py:1344] 2021-11-30 02:11:47,488 >> Saving model checkpoint to ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch_LR1e-5_roberta_base\n","[INFO|configuration_utils.py:300] 2021-11-30 02:11:47,493 >> Configuration saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch_LR1e-5_roberta_base/config.json\n","[INFO|modeling_utils.py:817] 2021-11-30 02:11:50,195 >> Model weights saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch_LR1e-5_roberta_base/pytorch_model.bin\n","{'loss': 0.727, 'learning_rate': 9.222222222222224e-06, 'epoch': 0.08}\n","{'eval_stsb_spearman': 0.8502856696652996, 'eval_sickr_spearman': 0.7960003277554687, 'eval_avg_sts': 0.8231429987103842, 'epoch': 0.08}\n","{'loss': 0.7371, 'learning_rate': 9.111111111111112e-06, 'epoch': 0.09}\n","{'eval_stsb_spearman': 0.8472056444108065, 'eval_sickr_spearman': 0.7950675157344392, 'eval_avg_sts': 0.8211365800726229, 'epoch': 0.09}\n","{'loss': 0.7073, 'learning_rate': 9e-06, 'epoch': 0.1}\n","{'eval_stsb_spearman': 0.847419370536759, 'eval_sickr_spearman': 0.7927253751350124, 'eval_avg_sts': 0.8200723728358856, 'epoch': 0.1}\n","{'loss': 0.6811, 'learning_rate': 8.888888888888888e-06, 'epoch': 0.11}\n","{'eval_stsb_spearman': 0.8468760470716508, 'eval_sickr_spearman': 0.8035127282380997, 'eval_avg_sts': 0.8251943876548753, 'epoch': 0.11}\n","{'loss': 0.6972, 'learning_rate': 8.777777777777778e-06, 'epoch': 0.12}\n","{'eval_stsb_spearman': 0.8490518467508651, 'eval_sickr_spearman': 0.7983635059773253, 'eval_avg_sts': 0.8237076763640951, 'epoch': 0.12}\n","{'loss': 0.6555, 'learning_rate': 8.666666666666668e-06, 'epoch': 0.13}\n","{'eval_stsb_spearman': 0.8485341959027897, 'eval_sickr_spearman': 0.7981202284485414, 'eval_avg_sts': 0.8233272121756655, 'epoch': 0.13}\n","{'loss': 0.6029, 'learning_rate': 8.555555555555556e-06, 'epoch': 0.14}\n","{'eval_stsb_spearman': 0.8468171004117538, 'eval_sickr_spearman': 0.8057465106726819, 'eval_avg_sts': 0.8262818055422179, 'epoch': 0.14}\n","{'loss': 0.5742, 'learning_rate': 8.444444444444446e-06, 'epoch': 0.16}\n","{'eval_stsb_spearman': 0.8480512446377407, 'eval_sickr_spearman': 0.808410459651744, 'eval_avg_sts': 0.8282308521447423, 'epoch': 0.16}\n","{'loss': 0.5587, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.17}\n","{'eval_stsb_spearman': 0.8496255962566259, 'eval_sickr_spearman': 0.81061230140387, 'eval_avg_sts': 0.830118948830248, 'epoch': 0.17}\n","{'loss': 0.495, 'learning_rate': 8.222222222222222e-06, 'epoch': 0.18}\n","{'eval_stsb_spearman': 0.8471704379808475, 'eval_sickr_spearman': 0.8056614475920348, 'eval_avg_sts': 0.8264159427864411, 'epoch': 0.18}\n","{'loss': 0.4879, 'learning_rate': 8.111111111111112e-06, 'epoch': 0.19}\n","{'eval_stsb_spearman': 0.8511029638229025, 'eval_sickr_spearman': 0.7999462268319141, 'eval_avg_sts': 0.8255245953274083, 'epoch': 0.19}\n","{'loss': 0.4691, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.2}\n","{'eval_stsb_spearman': 0.8471446283545179, 'eval_sickr_spearman': 0.8015777472855639, 'eval_avg_sts': 0.8243611878200409, 'epoch': 0.2}\n","{'loss': 0.4516, 'learning_rate': 7.88888888888889e-06, 'epoch': 0.21}\n","{'eval_stsb_spearman': 0.8483344316656596, 'eval_sickr_spearman': 0.7996335443615519, 'eval_avg_sts': 0.8239839880136057, 'epoch': 0.21}\n","{'loss': 0.4558, 'learning_rate': 7.77777777777778e-06, 'epoch': 0.22}\n","{'eval_stsb_spearman': 0.8483555196228996, 'eval_sickr_spearman': 0.7965617152690773, 'eval_avg_sts': 0.8224586174459885, 'epoch': 0.22}\n","{'loss': 0.4365, 'learning_rate': 7.666666666666667e-06, 'epoch': 0.23}\n","{'eval_stsb_spearman': 0.8460820190812192, 'eval_sickr_spearman': 0.7979732532781405, 'eval_avg_sts': 0.8220276361796799, 'epoch': 0.23}\n","{'loss': 0.4133, 'learning_rate': 7.555555555555556e-06, 'epoch': 0.24}\n","{'eval_stsb_spearman': 0.8470122118931469, 'eval_sickr_spearman': 0.7973218074493356, 'eval_avg_sts': 0.8221670096712412, 'epoch': 0.24}\n","{'loss': 0.4147, 'learning_rate': 7.444444444444445e-06, 'epoch': 0.26}\n","{'eval_stsb_spearman': 0.8489623840557534, 'eval_sickr_spearman': 0.7954047420976361, 'eval_avg_sts': 0.8221835630766947, 'epoch': 0.26}\n","{'loss': 0.405, 'learning_rate': 7.333333333333333e-06, 'epoch': 0.27}\n","{'eval_stsb_spearman': 0.8486507982964255, 'eval_sickr_spearman': 0.795080772318436, 'eval_avg_sts': 0.8218657853074307, 'epoch': 0.27}\n","{'loss': 0.3993, 'learning_rate': 7.222222222222223e-06, 'epoch': 0.28}\n","{'eval_stsb_spearman': 0.848526059911613, 'eval_sickr_spearman': 0.797032227938765, 'eval_avg_sts': 0.822779143925189, 'epoch': 0.28}\n","{'loss': 0.3941, 'learning_rate': 7.111111111111112e-06, 'epoch': 0.29}\n","{'eval_stsb_spearman': 0.8459600794953965, 'eval_sickr_spearman': 0.7964612342048688, 'eval_avg_sts': 0.8212106568501327, 'epoch': 0.29}\n","{'loss': 0.3908, 'learning_rate': 7e-06, 'epoch': 0.3}\n","{'eval_stsb_spearman': 0.8435137913324932, 'eval_sickr_spearman': 0.7994431971065525, 'eval_avg_sts': 0.8214784942195228, 'epoch': 0.3}\n","{'loss': 0.414, 'learning_rate': 6.88888888888889e-06, 'epoch': 0.31}\n","{'eval_stsb_spearman': 0.8466840052612458, 'eval_sickr_spearman': 0.7945478192168787, 'eval_avg_sts': 0.8206159122390622, 'epoch': 0.31}\n","{'loss': 0.3758, 'learning_rate': 6.777777777777779e-06, 'epoch': 0.32}\n","{'eval_stsb_spearman': 0.8439287364583399, 'eval_sickr_spearman': 0.7952147310603469, 'eval_avg_sts': 0.8195717337593433, 'epoch': 0.32}\n","{'loss': 0.3758, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.33}\n","{'eval_stsb_spearman': 0.8452494463049881, 'eval_sickr_spearman': 0.7949915255962864, 'eval_avg_sts': 0.8201204859506372, 'epoch': 0.33}\n","{'loss': 0.3606, 'learning_rate': 6.555555555555556e-06, 'epoch': 0.34}\n","{'eval_stsb_spearman': 0.8483509992927366, 'eval_sickr_spearman': 0.7956000845871849, 'eval_avg_sts': 0.8219755419399608, 'epoch': 0.34}\n","{'loss': 0.3746, 'learning_rate': 6.444444444444445e-06, 'epoch': 0.36}\n","{'eval_stsb_spearman': 0.8480074741449396, 'eval_sickr_spearman': 0.7964026362611143, 'eval_avg_sts': 0.8222050552030269, 'epoch': 0.36}\n","{'loss': 0.3543, 'learning_rate': 6.333333333333333e-06, 'epoch': 0.37}\n","{'eval_stsb_spearman': 0.8469517045971724, 'eval_sickr_spearman': 0.7951349514008583, 'eval_avg_sts': 0.8210433279990154, 'epoch': 0.37}\n","{'loss': 0.3543, 'learning_rate': 6.222222222222223e-06, 'epoch': 0.38}\n","{'eval_stsb_spearman': 0.8497761283888458, 'eval_sickr_spearman': 0.7981027931587192, 'eval_avg_sts': 0.8239394607737824, 'epoch': 0.38}\n","{'loss': 0.3501, 'learning_rate': 6.111111111111112e-06, 'epoch': 0.39}\n","{'eval_stsb_spearman': 0.8452238014078663, 'eval_sickr_spearman': 0.7969336681186141, 'eval_avg_sts': 0.8210787347632402, 'epoch': 0.39}\n","{'loss': 0.3491, 'learning_rate': 6e-06, 'epoch': 0.4}\n","{'eval_stsb_spearman': 0.8469403844415065, 'eval_sickr_spearman': 0.7954336087896003, 'eval_avg_sts': 0.8211869966155534, 'epoch': 0.4}\n","{'loss': 0.3535, 'learning_rate': 5.88888888888889e-06, 'epoch': 0.41}\n","{'eval_stsb_spearman': 0.8473254612193655, 'eval_sickr_spearman': 0.8011654963419205, 'eval_avg_sts': 0.824245478780643, 'epoch': 0.41}\n","{'loss': 0.3417, 'learning_rate': 5.777777777777778e-06, 'epoch': 0.42}\n","{'eval_stsb_spearman': 0.8476831749890412, 'eval_sickr_spearman': 0.8007834569610817, 'eval_avg_sts': 0.8242333159750614, 'epoch': 0.42}\n","{'loss': 0.3416, 'learning_rate': 5.666666666666667e-06, 'epoch': 0.43}\n","{'eval_stsb_spearman': 0.8491204464422735, 'eval_sickr_spearman': 0.7960790507307258, 'eval_avg_sts': 0.8225997485864996, 'epoch': 0.43}\n","{'loss': 0.3451, 'learning_rate': 5.555555555555557e-06, 'epoch': 0.44}\n","{'eval_stsb_spearman': 0.8455099393673193, 'eval_sickr_spearman': 0.7978524550580238, 'eval_avg_sts': 0.8216811972126716, 'epoch': 0.44}\n","{'loss': 0.3419, 'learning_rate': 5.444444444444445e-06, 'epoch': 0.46}\n","{'eval_stsb_spearman': 0.8450833244427192, 'eval_sickr_spearman': 0.7970501915707029, 'eval_avg_sts': 0.821066758006711, 'epoch': 0.46}\n","{'loss': 0.3352, 'learning_rate': 5.333333333333334e-06, 'epoch': 0.47}\n","{'eval_stsb_spearman': 0.846058008388514, 'eval_sickr_spearman': 0.7964798222411253, 'eval_avg_sts': 0.8212689153148196, 'epoch': 0.47}\n","{'loss': 0.3439, 'learning_rate': 5.2222222222222226e-06, 'epoch': 0.48}\n","{'eval_stsb_spearman': 0.8489754392248936, 'eval_sickr_spearman': 0.7957293362811548, 'eval_avg_sts': 0.8223523877530242, 'epoch': 0.48}\n","{'loss': 0.3517, 'learning_rate': 5.1111111111111115e-06, 'epoch': 0.49}\n","{'eval_stsb_spearman': 0.846330281570457, 'eval_sickr_spearman': 0.7984580311849555, 'eval_avg_sts': 0.8223941563777062, 'epoch': 0.49}\n","{'loss': 0.3261, 'learning_rate': 5e-06, 'epoch': 0.5}\n","{'eval_stsb_spearman': 0.8479825132736435, 'eval_sickr_spearman': 0.7988167274504954, 'eval_avg_sts': 0.8233996203620695, 'epoch': 0.5}\n","{'loss': 0.3278, 'learning_rate': 4.888888888888889e-06, 'epoch': 0.51}\n","{'eval_stsb_spearman': 0.847148710207865, 'eval_sickr_spearman': 0.7961056599609225, 'eval_avg_sts': 0.8216271850843937, 'epoch': 0.51}\n","{'loss': 0.315, 'learning_rate': 4.777777777777778e-06, 'epoch': 0.52}\n","{'eval_stsb_spearman': 0.8482633604422986, 'eval_sickr_spearman': 0.7975719534256253, 'eval_avg_sts': 0.8229176569339619, 'epoch': 0.52}\n","{'loss': 0.3187, 'learning_rate': 4.666666666666667e-06, 'epoch': 0.53}\n","{'eval_stsb_spearman': 0.8483761121638012, 'eval_sickr_spearman': 0.7967883260056624, 'eval_avg_sts': 0.8225822190847318, 'epoch': 0.53}\n","{'loss': 0.3231, 'learning_rate': 4.555555555555556e-06, 'epoch': 0.54}\n","{'eval_stsb_spearman': 0.8478173751234064, 'eval_sickr_spearman': 0.7987563523559875, 'eval_avg_sts': 0.823286863739697, 'epoch': 0.54}\n","{'loss': 0.3119, 'learning_rate': 4.444444444444444e-06, 'epoch': 0.56}\n","{'eval_stsb_spearman': 0.8460801586220438, 'eval_sickr_spearman': 0.7954353379092521, 'eval_avg_sts': 0.820757748265648, 'epoch': 0.56}\n","{'loss': 0.3155, 'learning_rate': 4.333333333333334e-06, 'epoch': 0.57}\n","{'eval_stsb_spearman': 0.8468679652155395, 'eval_sickr_spearman': 0.7960001836621643, 'eval_avg_sts': 0.821434074438852, 'epoch': 0.57}\n","{'loss': 0.3177, 'learning_rate': 4.222222222222223e-06, 'epoch': 0.58}\n","{'eval_stsb_spearman': 0.8475768144591723, 'eval_sickr_spearman': 0.7983828625112048, 'eval_avg_sts': 0.8229798384851885, 'epoch': 0.58}\n","{'loss': 0.3034, 'learning_rate': 4.111111111111111e-06, 'epoch': 0.59}\n","{'eval_stsb_spearman': 0.8472031398240712, 'eval_sickr_spearman': 0.7956919680842359, 'eval_avg_sts': 0.8214475539541536, 'epoch': 0.59}\n","{'loss': 0.3118, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.6}\n","{'eval_stsb_spearman': 0.8482130685926895, 'eval_sickr_spearman': 0.7960021529373235, 'eval_avg_sts': 0.8221076107650065, 'epoch': 0.6}\n","{'loss': 0.3143, 'learning_rate': 3.88888888888889e-06, 'epoch': 0.61}\n","{'eval_stsb_spearman': 0.8494165445111195, 'eval_sickr_spearman': 0.7962986969576024, 'eval_avg_sts': 0.822857620734361, 'epoch': 0.61}\n","{'loss': 0.3063, 'learning_rate': 3.777777777777778e-06, 'epoch': 0.62}\n","{'eval_stsb_spearman': 0.8470708799463205, 'eval_sickr_spearman': 0.7972299719833859, 'eval_avg_sts': 0.8221504259648531, 'epoch': 0.62}\n","{'loss': 0.3106, 'learning_rate': 3.6666666666666666e-06, 'epoch': 0.63}\n","{'eval_stsb_spearman': 0.848006471339313, 'eval_sickr_spearman': 0.7986811356511355, 'eval_avg_sts': 0.8233438034952243, 'epoch': 0.63}\n","{'loss': 0.3044, 'learning_rate': 3.555555555555556e-06, 'epoch': 0.64}\n","{'eval_stsb_spearman': 0.8483362288199231, 'eval_sickr_spearman': 0.7955391811505614, 'eval_avg_sts': 0.8219377049852423, 'epoch': 0.64}\n","{'loss': 0.3115, 'learning_rate': 3.444444444444445e-06, 'epoch': 0.66}\n","{'eval_stsb_spearman': 0.8478588156794916, 'eval_sickr_spearman': 0.796813494302816, 'eval_avg_sts': 0.8223361549911539, 'epoch': 0.66}\n","{'loss': 0.3027, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.67}\n","{'eval_stsb_spearman': 0.8481257525604203, 'eval_sickr_spearman': 0.7984028434494029, 'eval_avg_sts': 0.8232642980049116, 'epoch': 0.67}\n","{'loss': 0.2983, 'learning_rate': 3.2222222222222227e-06, 'epoch': 0.68}\n","{'eval_stsb_spearman': 0.8486072628145548, 'eval_sickr_spearman': 0.7992990077400355, 'eval_avg_sts': 0.8239531352772951, 'epoch': 0.68}\n","{'loss': 0.2922, 'learning_rate': 3.1111111111111116e-06, 'epoch': 0.69}\n","{'eval_stsb_spearman': 0.8485942467913491, 'eval_sickr_spearman': 0.7988171597304082, 'eval_avg_sts': 0.8237057032608787, 'epoch': 0.69}\n","{'loss': 0.2914, 'learning_rate': 3e-06, 'epoch': 0.7}\n","{'eval_stsb_spearman': 0.8473850029389007, 'eval_sickr_spearman': 0.7998366678895337, 'eval_avg_sts': 0.8236108354142172, 'epoch': 0.7}\n","{'loss': 0.3045, 'learning_rate': 2.888888888888889e-06, 'epoch': 0.71}\n","{'eval_stsb_spearman': 0.8472232590550376, 'eval_sickr_spearman': 0.7988057763593674, 'eval_avg_sts': 0.8230145177072026, 'epoch': 0.71}\n","{'loss': 0.2988, 'learning_rate': 2.7777777777777783e-06, 'epoch': 0.72}\n","{'eval_stsb_spearman': 0.8455752109027345, 'eval_sickr_spearman': 0.7963131543191352, 'eval_avg_sts': 0.8209441826109348, 'epoch': 0.72}\n","{'loss': 0.291, 'learning_rate': 2.666666666666667e-06, 'epoch': 0.73}\n","{'eval_stsb_spearman': 0.8474217032785801, 'eval_sickr_spearman': 0.7976943847031909, 'eval_avg_sts': 0.8225580439908855, 'epoch': 0.73}\n","{'loss': 0.2935, 'learning_rate': 2.5555555555555557e-06, 'epoch': 0.74}\n","{'eval_stsb_spearman': 0.8488512967905775, 'eval_sickr_spearman': 0.797509224807147, 'eval_avg_sts': 0.8231802607988623, 'epoch': 0.74}\n","{'loss': 0.2906, 'learning_rate': 2.4444444444444447e-06, 'epoch': 0.76}\n","{'eval_stsb_spearman': 0.8473333402283546, 'eval_sickr_spearman': 0.7976983712846103, 'eval_avg_sts': 0.8225158557564825, 'epoch': 0.76}\n","{'loss': 0.291, 'learning_rate': 2.3333333333333336e-06, 'epoch': 0.77}\n","{'eval_stsb_spearman': 0.8469381406677182, 'eval_sickr_spearman': 0.7978011098105864, 'eval_avg_sts': 0.8223696252391524, 'epoch': 0.77}\n","{'loss': 0.2829, 'learning_rate': 2.222222222222222e-06, 'epoch': 0.78}\n","{'eval_stsb_spearman': 0.8480073745007429, 'eval_sickr_spearman': 0.799410583988676, 'eval_avg_sts': 0.8237089792447094, 'epoch': 0.78}\n","{'loss': 0.2874, 'learning_rate': 2.1111111111111114e-06, 'epoch': 0.79}\n","{'eval_stsb_spearman': 0.8478143760110165, 'eval_sickr_spearman': 0.7976686400328201, 'eval_avg_sts': 0.8227415080219183, 'epoch': 0.79}\n","{'loss': 0.2862, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.8}\n","{'eval_stsb_spearman': 0.8479029516949194, 'eval_sickr_spearman': 0.7983297401130144, 'eval_avg_sts': 0.8231163459039669, 'epoch': 0.8}\n","{'loss': 0.2913, 'learning_rate': 1.888888888888889e-06, 'epoch': 0.81}\n","{'eval_stsb_spearman': 0.8475669852708945, 'eval_sickr_spearman': 0.7968140226449317, 'eval_avg_sts': 0.8221905039579132, 'epoch': 0.81}\n","{'loss': 0.3005, 'learning_rate': 1.777777777777778e-06, 'epoch': 0.82}\n","{'eval_stsb_spearman': 0.8480345300775378, 'eval_sickr_spearman': 0.798850349221502, 'eval_avg_sts': 0.8234424396495199, 'epoch': 0.82}\n","{'loss': 0.2951, 'learning_rate': 1.6666666666666667e-06, 'epoch': 0.83}\n","{'eval_stsb_spearman': 0.8471189628564016, 'eval_sickr_spearman': 0.7992472782437865, 'eval_avg_sts': 0.8231831205500941, 'epoch': 0.83}\n","{'loss': 0.2795, 'learning_rate': 1.5555555555555558e-06, 'epoch': 0.84}\n","{'eval_stsb_spearman': 0.8471738596913908, 'eval_sickr_spearman': 0.7989230683090793, 'eval_avg_sts': 0.8230484640002351, 'epoch': 0.84}\n","{'loss': 0.2821, 'learning_rate': 1.4444444444444445e-06, 'epoch': 0.86}\n","{'eval_stsb_spearman': 0.8470476176114994, 'eval_sickr_spearman': 0.7984708554890394, 'eval_avg_sts': 0.8227592365502694, 'epoch': 0.86}\n","{'loss': 0.2842, 'learning_rate': 1.3333333333333334e-06, 'epoch': 0.87}\n","{'eval_stsb_spearman': 0.8469246566726596, 'eval_sickr_spearman': 0.7974353049420337, 'eval_avg_sts': 0.8221799808073467, 'epoch': 0.87}\n","{'loss': 0.2862, 'learning_rate': 1.2222222222222223e-06, 'epoch': 0.88}\n","{'eval_stsb_spearman': 0.8466353628789659, 'eval_sickr_spearman': 0.7967021582096824, 'eval_avg_sts': 0.8216687605443241, 'epoch': 0.88}\n","{'loss': 0.2719, 'learning_rate': 1.111111111111111e-06, 'epoch': 0.89}\n","{'eval_stsb_spearman': 0.8469906005314882, 'eval_sickr_spearman': 0.7972836707547936, 'eval_avg_sts': 0.8221371356431408, 'epoch': 0.89}\n","{'loss': 0.3031, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.9}\n","{'eval_stsb_spearman': 0.8478717605282712, 'eval_sickr_spearman': 0.7974193586163562, 'eval_avg_sts': 0.8226455595723137, 'epoch': 0.9}\n","{'loss': 0.2972, 'learning_rate': 8.88888888888889e-07, 'epoch': 0.91}\n","{'eval_stsb_spearman': 0.8471108372692691, 'eval_sickr_spearman': 0.7966692569051973, 'eval_avg_sts': 0.8218900470872332, 'epoch': 0.91}\n","{'loss': 0.2709, 'learning_rate': 7.777777777777779e-07, 'epoch': 0.92}\n","{'eval_stsb_spearman': 0.8472412298445855, 'eval_sickr_spearman': 0.7978070656671647, 'eval_avg_sts': 0.8225241477558751, 'epoch': 0.92}\n","{'loss': 0.2772, 'learning_rate': 6.666666666666667e-07, 'epoch': 0.93}\n","{'eval_stsb_spearman': 0.8474927887368263, 'eval_sickr_spearman': 0.7973639787563982, 'eval_avg_sts': 0.8224283837466122, 'epoch': 0.93}\n","{'loss': 0.2798, 'learning_rate': 5.555555555555555e-07, 'epoch': 0.94}\n","{'eval_stsb_spearman': 0.8479140292406776, 'eval_sickr_spearman': 0.7975939997011853, 'eval_avg_sts': 0.8227540144709314, 'epoch': 0.94}\n","{'loss': 0.2773, 'learning_rate': 4.444444444444445e-07, 'epoch': 0.96}\n","{'eval_stsb_spearman': 0.8478215672971181, 'eval_sickr_spearman': 0.7981718618825873, 'eval_avg_sts': 0.8229967145898527, 'epoch': 0.96}\n","{'loss': 0.2839, 'learning_rate': 3.3333333333333335e-07, 'epoch': 0.97}\n","{'eval_stsb_spearman': 0.8479363566582014, 'eval_sickr_spearman': 0.7984233527297171, 'eval_avg_sts': 0.8231798546939593, 'epoch': 0.97}\n","{'loss': 0.2797, 'learning_rate': 2.2222222222222224e-07, 'epoch': 0.98}\n","{'eval_stsb_spearman': 0.8480304777195131, 'eval_sickr_spearman': 0.7982957821242974, 'eval_avg_sts': 0.8231631299219053, 'epoch': 0.98}\n","{'loss': 0.2813, 'learning_rate': 1.1111111111111112e-07, 'epoch': 0.99}\n","{'eval_stsb_spearman': 0.8479948912601473, 'eval_sickr_spearman': 0.79821504184278, 'eval_avg_sts': 0.8231049665514636, 'epoch': 0.99}\n","{'loss': 0.2673, 'learning_rate': 0.0, 'epoch': 1.0}\n","{'eval_stsb_spearman': 0.8479912801836004, 'eval_sickr_spearman': 0.7981920829762926, 'eval_avg_sts': 0.8230916815799465, 'epoch': 1.0}\n","{'eval_stsb_spearman': 0.8479912801836004, 'eval_sickr_spearman': 0.7981920829762926, 'eval_avg_sts': 0.8230916815799465, 'epoch': 1.0}\n","100% 45000/45000 [6:01:04<00:00,  2.42it/s]11/30/2021 07:48:37 - INFO - simcse.trainers -   \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","11/30/2021 07:48:37 - INFO - simcse.trainers -   Loading best model from ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch_LR1e-5_roberta_base (score: 0.8547857172508161).\n","[INFO|configuration_utils.py:443] 2021-11-30 07:48:37,208 >> loading configuration file ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch_LR1e-5_roberta_base/config.json\n","[INFO|configuration_utils.py:481] 2021-11-30 07:48:37,209 >> Model config RobertaConfig {\n","  \"_name_or_path\": \"princeton-nlp/sup-simcse-roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForCL\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.2.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","[INFO|modeling_utils.py:1025] 2021-11-30 07:48:37,209 >> loading weights file ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch_LR1e-5_roberta_base/pytorch_model.bin\n","[INFO|modeling_utils.py:1143] 2021-11-30 07:48:40,197 >> All model checkpoint weights were used when initializing RobertaForCL.\n","\n","[INFO|modeling_utils.py:1152] 2021-11-30 07:48:40,198 >> All the weights of RobertaForCL were initialized from the model checkpoint at ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch_LR1e-5_roberta_base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForCL for predictions without further training.\n","{'train_runtime': 21667.9419, 'train_samples_per_second': 2.077, 'epoch': 1.0}\n","100% 45000/45000 [6:01:07<00:00,  2.08it/s]\n","[INFO|trainer.py:1344] 2021-11-30 07:48:40,394 >> Saving model checkpoint to ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch_LR1e-5_roberta_base\n","[INFO|configuration_utils.py:300] 2021-11-30 07:48:40,414 >> Configuration saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch_LR1e-5_roberta_base/config.json\n","[INFO|modeling_utils.py:817] 2021-11-30 07:48:42,046 >> Model weights saved in ../Model_TwiBot_Similarity_With_Metadata_360k_Tweets/twiBot-360k-similarity-metadata-1epoch_LR1e-5_roberta_base/pytorch_model.bin\n","11/30/2021 07:48:42 - INFO - __main__ -   ***** Train results *****\n","11/30/2021 07:48:42 - INFO - __main__ -     epoch = 1.0\n","11/30/2021 07:48:42 - INFO - __main__ -     train_runtime = 21667.9419\n","11/30/2021 07:48:42 - INFO - __main__ -     train_samples_per_second = 2.077\n","11/30/2021 07:48:42 - INFO - __main__ -   *** Evaluate ***\n","11/30/2021 07:49:17 - INFO - root -   Generating sentence embeddings\n","11/30/2021 07:49:31 - INFO - root -   Generated sentence embeddings\n","11/30/2021 07:49:31 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/30/2021 07:49:42 - INFO - root -   Best param found at split 1: l2reg = 0.001                 with score 85.19\n","11/30/2021 07:49:53 - INFO - root -   Best param found at split 2: l2reg = 0.0001                 with score 84.77\n","11/30/2021 07:50:03 - INFO - root -   Best param found at split 3: l2reg = 0.0001                 with score 84.82\n","11/30/2021 07:50:14 - INFO - root -   Best param found at split 4: l2reg = 1e-05                 with score 85.04\n","11/30/2021 07:50:25 - INFO - root -   Best param found at split 5: l2reg = 0.0001                 with score 84.72\n","11/30/2021 07:50:26 - INFO - root -   Generating sentence embeddings\n","11/30/2021 07:50:30 - INFO - root -   Generated sentence embeddings\n","11/30/2021 07:50:30 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/30/2021 07:50:34 - INFO - root -   Best param found at split 1: l2reg = 0.001                 with score 91.69\n","11/30/2021 07:50:37 - INFO - root -   Best param found at split 2: l2reg = 0.01                 with score 91.75\n","11/30/2021 07:50:41 - INFO - root -   Best param found at split 3: l2reg = 0.001                 with score 91.49\n","11/30/2021 07:50:44 - INFO - root -   Best param found at split 4: l2reg = 0.01                 with score 91.59\n","11/30/2021 07:50:48 - INFO - root -   Best param found at split 5: l2reg = 0.001                 with score 91.62\n","11/30/2021 07:50:49 - INFO - root -   Generating sentence embeddings\n","11/30/2021 07:51:03 - INFO - root -   Generated sentence embeddings\n","11/30/2021 07:51:03 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/30/2021 07:51:12 - INFO - root -   Best param found at split 1: l2reg = 0.001                 with score 94.15\n","11/30/2021 07:51:23 - INFO - root -   Best param found at split 2: l2reg = 0.0001                 with score 94.25\n","11/30/2021 07:51:35 - INFO - root -   Best param found at split 3: l2reg = 0.0001                 with score 94.52\n","11/30/2021 07:51:47 - INFO - root -   Best param found at split 4: l2reg = 0.0001                 with score 94.25\n","11/30/2021 07:51:57 - INFO - root -   Best param found at split 5: l2reg = 0.001                 with score 94.29\n","11/30/2021 07:51:58 - INFO - root -   Generating sentence embeddings\n","11/30/2021 07:52:02 - INFO - root -   Generated sentence embeddings\n","11/30/2021 07:52:02 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with (inner) 5-fold cross-validation\n","11/30/2021 07:52:13 - INFO - root -   Best param found at split 1: l2reg = 1e-05                 with score 89.16\n","11/30/2021 07:52:23 - INFO - root -   Best param found at split 2: l2reg = 0.001                 with score 88.12\n","11/30/2021 07:52:34 - INFO - root -   Best param found at split 3: l2reg = 0.001                 with score 89.22\n","11/30/2021 07:52:45 - INFO - root -   Best param found at split 4: l2reg = 1e-05                 with score 88.95\n","11/30/2021 07:52:55 - INFO - root -   Best param found at split 5: l2reg = 0.001                 with score 89.11\n","11/30/2021 07:52:57 - INFO - root -   Computing embedding for train\n","11/30/2021 07:53:43 - INFO - root -   Computed train embeddings\n","11/30/2021 07:53:43 - INFO - root -   Computing embedding for dev\n","11/30/2021 07:53:44 - INFO - root -   Computed dev embeddings\n","11/30/2021 07:53:44 - INFO - root -   Computing embedding for test\n","11/30/2021 07:53:46 - INFO - root -   Computed test embeddings\n","11/30/2021 07:53:46 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with standard validation..\n","11/30/2021 07:54:03 - INFO - root -   [('reg:1e-05', 89.56), ('reg:0.0001', 89.68), ('reg:0.001', 89.22), ('reg:0.01', 88.3)]\n","11/30/2021 07:54:03 - INFO - root -   Validation : best param found is reg = 0.0001 with score             89.68\n","11/30/2021 07:54:03 - INFO - root -   Evaluating...\n","11/30/2021 07:54:07 - INFO - root -   ***** Transfer task : TREC *****\n","\n","\n","11/30/2021 07:54:11 - INFO - root -   Computed train embeddings\n","11/30/2021 07:54:12 - INFO - root -   Computed test embeddings\n","11/30/2021 07:54:12 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation\n","11/30/2021 07:54:19 - INFO - root -   [('reg:1e-05', 76.71), ('reg:0.0001', 76.17), ('reg:0.001', 75.06), ('reg:0.01', 68.43)]\n","11/30/2021 07:54:19 - INFO - root -   Cross-validation : best param found is reg = 1e-05             with score 76.71\n","11/30/2021 07:54:19 - INFO - root -   Evaluating...\n","11/30/2021 07:54:19 - INFO - root -   ***** Transfer task : MRPC *****\n","\n","\n","11/30/2021 07:54:20 - INFO - root -   Computing embedding for train\n","11/30/2021 07:54:30 - INFO - root -   Computed train embeddings\n","11/30/2021 07:54:30 - INFO - root -   Computing embedding for test\n","11/30/2021 07:54:34 - INFO - root -   Computed test embeddings\n","11/30/2021 07:54:34 - INFO - root -   Training pytorch-MLP-nhid0-rmsprop-bs128 with 5-fold cross-validation\n","11/30/2021 07:54:39 - INFO - root -   [('reg:1e-05', 76.05), ('reg:0.0001', 76.23), ('reg:0.001', 75.74), ('reg:0.01', 74.95)]\n","11/30/2021 07:54:39 - INFO - root -   Cross-validation : best param found is reg = 0.0001             with score 76.23\n","11/30/2021 07:54:39 - INFO - root -   Evaluating...\n","11/30/2021 07:54:40 - INFO - __main__ -   ***** Eval results *****\n","11/30/2021 07:54:40 - INFO - __main__ -     epoch = 1.0\n","11/30/2021 07:54:40 - INFO - __main__ -     eval_CR = 91.63\n","11/30/2021 07:54:40 - INFO - __main__ -     eval_MPQA = 88.91\n","11/30/2021 07:54:40 - INFO - __main__ -     eval_MR = 84.91\n","11/30/2021 07:54:40 - INFO - __main__ -     eval_MRPC = 76.23\n","11/30/2021 07:54:40 - INFO - __main__ -     eval_SST2 = 89.68\n","11/30/2021 07:54:40 - INFO - __main__ -     eval_SUBJ = 94.29\n","11/30/2021 07:54:40 - INFO - __main__ -     eval_TREC = 76.71\n","11/30/2021 07:54:40 - INFO - __main__ -     eval_avg_sts = 0.8229510012282751\n","11/30/2021 07:54:40 - INFO - __main__ -     eval_avg_transfer = 86.05142857142857\n","11/30/2021 07:54:40 - INFO - __main__ -     eval_sickr_spearman = 0.7911162852057342\n","11/30/2021 07:54:40 - INFO - __main__ -     eval_stsb_spearman = 0.8547857172508161\n"]}]},{"cell_type":"markdown","metadata":{"id":"vSLsgReEHZ1h"},"source":["# Load model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DPGmWLphHdUF","executionInfo":{"status":"ok","timestamp":1637785450167,"user_tz":480,"elapsed":189,"user":{"displayName":"zeeshan ahmad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15348670853435150367"}},"outputId":"47f18467-fd02-4a5e-f63a-6af0eeea30cc"},"source":["ls drive/MyDrive/twiBot-20epochs-sup-simcse-bert-base-uncased"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ls: cannot access 'drive/MyDrive/twiBot-20epochs-sup-simcse-bert-base-uncased': No such file or directory\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yolrrFafZNsF","executionInfo":{"status":"ok","timestamp":1637785451207,"user_tz":480,"elapsed":236,"user":{"displayName":"zeeshan ahmad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15348670853435150367"}},"outputId":"d57b08f7-7fd6-4d79-fee0-25612da17ad9"},"source":["!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1ygEmNCP-_htwwx_sBJE2NdJ3Nb7aJhr3/CSCI_544_NLP_Project/Twitter_Bot_Detection/Data\n"]}]},{"cell_type":"code","metadata":{"id":"c21Jts0-eKJf"},"source":["sent1 = ['the butlers visitor experience will leave you with cherished memories and your tastebuds longing for more butlers chocolate . check availability here <_url_> <_url_>']\n","sent2 = ['angel food cake hack to satisfy your cravings <_url_>']\n","sen_neg = ['adding seasonal words to search terms can help your items surface in search results . <_url_> ( seller central login required )']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9B4zOVkcTk14","executionInfo":{"status":"ok","timestamp":1637785500858,"user_tz":480,"elapsed":5222,"user":{"displayName":"zeeshan ahmad","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15348670853435150367"}},"outputId":"c8e4286c-4c3e-4585-982b-55c50e0e21c8"},"source":["# Trained on the twibot-similarity-based dataset - 20 epoch\n","model_twi = model = SimCSE(\"/content/drive/MyDrive/CSCI_544_NLP_Project/Twitter_Bot_Detection/Data/twiBot-similarity-20epochs-sup-simcse-bert-base-uncased\")\n","# model_twi\n","\n","sim1= model_twi.similarity(sent1, sent2)\n","sim2 = model_twi.similarity(sent1, sen_neg)\n","print(\"\\nPos:\",sim1)\n","print(\"\\nNeg:\",sim2)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertModel were not initialized from the model checkpoint at /content/drive/MyDrive/CSCI_544_NLP_Project/Twitter_Bot_Detection/Data/twiBot-similarity-20epochs-sup-simcse-bert-base-uncased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100%|██████████| 1/1 [00:00<00:00, 71.59it/s]\n","100%|██████████| 1/1 [00:00<00:00, 93.03it/s]\n","100%|██████████| 1/1 [00:00<00:00, 107.22it/s]\n","100%|██████████| 1/1 [00:00<00:00, 105.35it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Pos: [[0.8136509]]\n","\n","Neg: [[0.5301692]]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}